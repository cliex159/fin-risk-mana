[{"path":"index.html","id":"course-descripition","chapter":"Course Descripition","heading":"Course Descripition","text":"course provides students notions advanced tools statistics\nMathematics financial risk management e.g., time series\nmodels, copula theory Extreme Value Theory.","code":""},{"path":"index.html","id":"dr.-ta-quoc-bao","chapter":"Course Descripition","heading":"Dr. Ta Quoc Bao","text":"𝐇𝐮𝐦𝐚𝐧𝐬 𝐨𝐟 𝐌𝐀 |\n\n\n Dr. Ta Quoc Bao\n\n\n\n\n Academic Education BackgroundPh.D. Applied Mathematics, Åbo Akademi University, FinlandM.Sc. Probability Statistics, University Science, VNU-Hanoi, VietnamB.Sc. Probability Statistics, University Science, VNU-Hanoi, Vietnam\n Subjects InterestProbability, statistics & random processDifferential equationsFinancial risk management\nFun Facts️️\n\nbeloved teacher instructing students write academic publications related Econometrics.\nSince 2020, major medals\n\nFirst Price ️\n\nConsolation Price Olympic Econometrics.\ndetails right :\n\nhttps://www.facebook.com/fermyouthunion/posts/5965881330152078\n\n\ngentle approachableRemember awkward silence beginning lectures, Dr. Bao just like keeps asking students anything new. class, stories just easily start diets & fitness end international public health.\nyoungsters MA K21, even Zalo group chat. Somehow manages update news , share job opportunities , even closely interact within beloved FERMers.\nYes , just giving proper guidance quite sure career path.FERMers dude, usually come across education online courses, outdoor summer camps, quantitative trading competitions…\n\nExperienced Financial Bankings, colleagues just well likely data analyst, quantitative analyst, credit analyst explains numerous available employment possibility fast-forwarding career advice.can explore even funnier facts :\n\nhttps://math.hcmiu.edu.vn/user/tqbao/\n\ncan contact Dr. Ta Quoc Bao :\n Office: Room A2.606, International University, Thu Duc City, Ho Chi Minh City\n Email: baotq@hcmiu.edu.vn","code":""},{"path":"index.html","id":"course-references","chapter":"Course Descripition","heading":"Course References","text":".J. MacNeil, R. Frey P. Embrechts. Quantitative risk\nmanagement. Princeton University press. 2015J. Danielsson. Financial Risk Forecasting. Wiley Finance. 2011Allan M. Malz, Financial Risk Management: Models, History, \nInstitutions, Willey, 2011.","code":""},{"path":"returns.html","id":"returns","chapter":"1 Returns","heading":"1 Returns","text":"Let \\(P_t\\) denote price stock time \\(t\\). return relative change price financial asset given time interval, often represented percentage.","code":""},{"path":"returns.html","id":"simple-return","chapter":"1 Returns","heading":"1.1 Simple return","text":"simple return percentage change prices indicated R\n\\[ R_t=\\frac{P_t-P_{t-1}}{P_{t-1}}=\\frac{\\Delta P_t}{P_{t-1}} \\]n-period return given \n\\[\\begin{align*} R_t(n)&=\\frac{P_t}{P_{t-n}}-1\\\\\n&=\\frac{P_t}{P_{t-1}} \\cdot \\frac{P_{t-1}}{P_{t-2}} \\cdot ... \\cdot \\frac{P_{t-n+1}}{P_{t-n+2}}-1\\\\\n&=(1+R_t)(1+R_{t-1})(1+R_{t-2})...(1+R_{t-n+1})-1\n\\end{align*}\\]","code":""},{"path":"returns.html","id":"logarithm-return","chapter":"1 Returns","heading":"1.2 Logarithm return","text":"logarithm gross return called continuously compounded return\\[ Y_t(1)=\\ln(1+R_t)=\\ln \\left( \\frac{P_t}{P_{t-1}} \\right)=\\ln(P_t)-\\ln(P_{t-1}) \\]\\(n-period\\) return given \n\\[\\begin{align*}\nY_t(n)&=\\ln(1+R_t(n)) \\\\\n&=\\ln((1+R_t)(1+R_{t-1})(1+R_{t-2})...(1+R_{t-n+1})) \\\\\n&=\\ln(1+R_t)+\\ln(1+R_{t-1})+\\ln(1+R_{t-2})...+\\ln(1+R_{t-n+1})) \\\\\n&=Y_t+Y_{t-1}+Y_{t-2}+...+Y_{t-n+1}\n\\end{align*}\\]","code":""},{"path":"returns.html","id":"remark","chapter":"1 Returns","heading":"1.3 Remark","text":"","code":""},{"path":"returns.html","id":"approximation","chapter":"1 Returns","heading":"1.3.1 Approximation","text":"small price changes difference simple return log return small (negligible). Indeed, Taylor approximation \n\\[ \\ln(1+x)=x-\\frac{x^2}{2}+\\frac{x^3}{3}+... \\approx x \\]Simple log-return approximately equal returns 10% since large difference \\(R_t\\) \\(Y_t\\) time observations goes zero \\(\\lim_{\\Delta t \\0} Y_t = R_t\\).\\[\\ln(1000) − \\ln(995) = 0.005012 \\approx \\frac{1000}{995} − 1 = 0.005025 \\\\\n\\ln(1000) − \\ln(885) = 0.12216 \\neq \\frac{1000}{885} − 1 = 0.12994\\]","code":""},{"path":"returns.html","id":"symmetry-property","chapter":"1 Returns","heading":"1.3.2 Symmetry property","text":"Continuous compounded return symmetry, Simple return . example\\[\\begin{align*}\n\\ln \\left( \\frac{1000}{500} \\right) &=-\\ln \\left( \\frac{500}{1000} \\right) \\\\\n\\frac{1000}{500}-1 &\\neq - \\left( \\frac{500}{1000}-1 \\right)\n\\end{align*}\\]","code":""},{"path":"returns.html","id":"portfolio-return","chapter":"1 Returns","heading":"1.3.3 Portfolio Return","text":"Consider portfolio \\(N\\) stocks simple returns \\(R_t\\),\\(\\) time \\(t\\), respectively. Denote \\(R_{t,p}\\) return portfolio time \\(t\\), \\(Y_t\\),\\(p\\) continuously compounded return portfolio time \\(t\\).simple return portfolio (proof!!!)\\[ R_{,p}=\\sum_{=1}^{N} \\omega_i R_{t,} \\]continuously compounded returns equality\\[\nY_{t,p}= \\ln \\left( \\frac{P_{t,p}}{P_{t-1,p}} \\right) \\neq \\sum_{=1}^{n} \\omega_i \\left( \\frac{P_{t,}}{P_{t-1,}} \\right) =\\sum_{=1}^{n} \\omega_i Y_{t,}\n\\]However, difference compounded simple returns may significant small returns, e.g., daily return\n\\[Y_p=\\sum_{=1}^N \\omega_i R_i \\]\ntime observations goes 0, \n\\[\\lim_{\\Delta t \\0} Y_{t,p} = R_{t,p}\\], practice note thatSimple returns \n\nUsed accounting purposes.\n\n\nInvestors usually concerned simple returns.\n\n\nUsed accounting purposes.\n\nInvestors usually concerned simple returns.\nContinuously compounded returns advantages\n\nMathematics easier, see later.\n\n\nUsed derivatives pricing, e.g. Black–Scholes model.\n\n\nMathematics easier, see later.\n\nUsed derivatives pricing, e.g. Black–Scholes model.\n","code":""},{"path":"random-walk.html","id":"random-walk","chapter":"2 Random Walk","heading":"2 Random Walk","text":"Let sequence \\(X_1, X_2, ...,X_t\\) ..d random variables \\(S_0\\) arbitrary starting point \n\\[S_t=S_0+X_1+X_2+...+X_t \\]\nseries \\((S_t)_{t \\geq 0}\\) called random walk \\(X_1, X_2, ...,X_t\\) steps.","code":""},{"path":"random-walk.html","id":"simple-random-walk","chapter":"2 Random Walk","heading":"2.1 Simple random walk","text":"Let series \\((S_t)_{t \\geq 0}\\) random walk\n\\[S_t=S_0+X_1+X_2+...+X_t \\]\nsteps either \\(1\\) \\(-1\\) \\(50\\%\\) probability either value, set \\(S_{0}=0\\) random walk called simple random walk.","code":"\nlibrary(tidyverse)\nsimple=map(1:9,\n              ~sample(c(1,-1), \n                 size=250, \n                 replace=T,\n                 prob=c(0.5,0.5)) %>% \n              cumsum)\npar(mfrow=c(3,3))\nplots=simple %>% \n  map(\n      plot,         \n      type=\"l\", \n      col=\"blue\",\n      ylab=\"the accumulated money\")\npar(mfrow=c(3,3))\nplots=simple %>%\n  map(acf)"},{"path":"random-walk.html","id":"normal-random-walk","chapter":"2 Random Walk","heading":"2.2 Normal random walk","text":"Let series \\((S_t)_{t \\geq 0}\\) random walk\n\\[S_t=S_0+Z_1+Z_2+...+Z_t \\]\nsteps follow standard normal distribution, .e. \\(Z \\sim \\mathcal{N}(0,1)\\), random walk called normal random walk. \\(E[S_t|S_0]=S_0\\) \\(\\mathbb{Var}(S_t|S_0)=\\sigma_t^2=\\sigma^2 t\\).","code":"\nlibrary(tidyverse)\nnormal=map(1:9,\n              ~rnorm(250,0,1) %>% \n              cumsum) \npar(mfrow=c(3,3))\nplots=normal %>% \n  map(\n      plot,         \n      type=\"l\", \n      col=\"blue\",\n      ylab=\"the accumulated money\")\npar(mfrow=c(3,3))\nplots=normal %>% \n  map(acf)"},{"path":"random-walk.html","id":"random-walk-with-drift","chapter":"2 Random Walk","heading":"2.3 Random walk with drift","text":"Let series \\((S_t)_{t \\geq 0}\\) random walk\n\\[\\begin{align*}\nS_t&=S_0+X_1+X_2+...+X_t \\\\\n&=S_{t-1}+X_t \\\\\n&= \\mu + S_{t-1}+ Z_t\n\\end{align*}\\]\nsteps normally distributed, .e. \\(X \\sim \\mathcal{N}(\\mu,\\sigma)\\), random walk called random walk drift. \\(E[S_t|S_0]=S_0+ \\mu t\\) \\(\\mathbb{Var}(S_t|S_0)=\\sigma_t^2=\\sigma^2 t\\).","code":"\nlibrary(tidyverse)\ndrift=map(1:9,\n              ~rnorm(250,1,5) %>% \n              cumsum)\n\npar(mfrow=c(3,3))\nplots= drift %>% \n  map(\n      plot,         \n      type=\"l\", \n      col=\"blue\",\n      ylab=\"the accumulated money\")\npar(mfrow=c(3,3))\nplots=drift %>% \n  map(acf)"},{"path":"random-walk.html","id":"geometric-random-walk","chapter":"2 Random Walk","heading":"2.4 Geometric random walk","text":"Let series \\((Y_t(t))_{t \\geq 0}\\) random walk\n\\[\\begin{align*}\nY_t(t)&=Y_1+Y_2+...+Y_t \\\\\n\\ln \\left( \\frac{P_t}{P_0}\\right)&=Y_1+Y_2+...+Y_t \\\\\nP_t&=P_0e^{Y_1+Y_2+...+Y_t}\n\\end{align*}\\]\n\\((P_t)_{t \\geq0}\\) called geometric random walks exponential random walk. \\(Y_1,Y_2,...,Y_t\\) ..d \\(Y \\sim \\mathcal{N}(\\mu,\\sigma^2)\\), \\(P_t\\) lognormal random walk.RemarkThe lognormal geometric random walk needs two assumptions: log returns normally distributed log returns mutually independent. general, prices usually follow lognormal geometric random walk continuous-time analog, geometric Brownian. independence assumption can also violated since returns exhibit volatility clustering, .e., see high volatility current returns can expect higher volatility continue, least motion.","code":"\nlibrary(tidyverse)\ngeometric=map(1:9,\n          ~ exp(log(120)+\n                cumsum(rnorm(250,\n                        0/250,\n                        1/sqrt(250))))) \n\npar(mfrow=c(3,3))\nplots=geometric %>% \n  map(\n      plot, \n      type=\"l\", \n      col=\"blue\",\n      ylab=\"the accumulated money\")\npar(mfrow=c(3,3))\nplots=geometric %>% \n  map(acf)"},{"path":"volatility.html","id":"volatility","chapter":"3 Volatility","heading":"3 Volatility","text":"Unconditional volatility, volatility short, volatility \nentire time period, denoted \\(\\sigma\\).Conditional volatility volatility given time period, conditional\nhappened , denoted \\(\\sigma_t\\).subscript t means volatility particular time period, usually day.Clear evidence cyclical patterns volatility time, short run long run.","code":""},{"path":"volatility.html","id":"calculations","chapter":"3 Volatility","heading":"3.1 Calculations","text":"Consider sample \\(x_i\\) mean \\(\\mu\\) sample size \\(N\\). estimation volatility:daily volatility\n\\[\\sigma=\\sqrt{\\frac{1}{N}\\sum_{n=1}^{\\infty} (x_i-\\mu)^2}\\]annualy volatility\n\\[\\sigma=\\sqrt{250}\\sqrt{\\frac{1}{N}\\sum_{n=1}^{\\infty} (x_i-\\mu)^2}\\]","code":""},{"path":"volatility.html","id":"volatility-cluster","chapter":"3 Volatility","heading":"3.2 Volatility cluster","text":"volatility decade, year month, see comes many cycles called volatility clusters. following figure describes daily volatility McDonald’s stock 2010-2014.","code":"\nlibrary(tidyquant)\nmcd = tq_get('MCD', \n               from=as.Date(\"2010-01-01\"),\n               to=as.Date(\"2014-01-01\"),\n               get = \"stock.prices\")\n\nmcd_logret=mcd$adjusted %>% \n  log %>% \n  diff\n\nplot(mcd$date[-1],mcd_logret,type=\"l\",col=\"blue\")"},{"path":"skewness-kurtosis.html","id":"skewness-kurtosis","chapter":"4 Skewness & Kurtosis","heading":"4 Skewness & Kurtosis","text":"Note Random Walk model, assuming independent Gaussian single-period returns, distribution multi-period returns prices derived. However, log returns typically heavy tailed thus results question.Skewness, kurtosis important descriptive statistics data distribution answer question. skewness essentially measures symmetry distribution, kurtosis determines heaviness distribution tails.","code":""},{"path":"skewness-kurtosis.html","id":"skewness","chapter":"4 Skewness & Kurtosis","heading":"4.1 Skewness","text":"","code":""},{"path":"skewness-kurtosis.html","id":"definition","chapter":"4 Skewness & Kurtosis","heading":"Definition","text":"skewness random variable X \n\\[S_k= \\mathbb{E}  \\left\\{ \\frac{X-\\mathbb{E}[X]}{\\sigma} \\right\\}^3=\\frac{\\mathbb{E}[(X-\\mathbb{E}[X])^3]}{\\sigma^3} \\]\nSkewness measures degree asymmetry.","code":""},{"path":"skewness-kurtosis.html","id":"types-of-skewness","chapter":"4 Skewness & Kurtosis","heading":"Types of skewness","text":"","code":""},{"path":"skewness-kurtosis.html","id":"symmetric-distribution","chapter":"4 Skewness & Kurtosis","heading":"4.1.1 Symmetric distribution","text":"\\(S_k=0\\) indicated symmetric distribution, .e., normal distribution t distribution.Since \\(skewness=0.12\\) approximately equal \\(0\\), distribution skew \\(mean=0.01\\) approximately equal \\(median=-0.03\\).Since \\(skewness=-0.22\\) approximately equal \\(0\\), distribution skew \\(mean=0\\) approximately equal \\(median=0.01\\).","code":"\nlibrary(moments)\nn=rnorm(n=1000, mean = 0, sd = 1)\nhist(n)\nprint(c(skewness(n),mean(n),median(n)))#> [1]  0.123033744  0.005668913 -0.030938984\nlibrary(moments)\nt=rt(n=1000,df=10)\nhist(t)\nprint(c(skewness(t),mean(t),median(t)))#> [1] -0.220824355 -0.002900342  0.014011103"},{"path":"skewness-kurtosis.html","id":"right-skewed","chapter":"4 Skewness & Kurtosis","heading":"4.1.2 Right-skewed","text":"\\(S_k>0\\) indicates relatively long right tail compared left tail, .e., distribution heavy tail right hand side.Since \\(skewness=0.87\\) greater \\(0\\), distribution right-skew \\(mean=-0.05\\) greater \\(median=-0.24\\).","code":"\nlibrary(moments)\nlibrary(fGarch)\nsr=rsnorm(n=1000, mean = 0, sd = 1, xi = 5)\nhist(sr)\nprint(c(skewness(sr),mean(sr),median(sr)))#> [1]  0.86929586 -0.05052421 -0.24136543"},{"path":"skewness-kurtosis.html","id":"left-skewed","chapter":"4 Skewness & Kurtosis","heading":"4.1.3 Left-skewed","text":"\\(S_k<0\\) (left-skewed) indicates relatively long left tail compared right tail, .e., distribution heavy tail left hand side.Since \\(skewness=-0.89\\) less \\(0\\), distribution left-skew \\(mean=0.01\\) less \\(median=0.19\\).","code":"\nlibrary(moments)\nlibrary(fGarch)\nsl=rsnorm(n=1000, mean = 0, sd = 1, xi = -2)\nhist(sl)\nprint(c(skewness(sl),mean(sl),median(sl)))#> [1] -0.88597146  0.01390576  0.19383722"},{"path":"skewness-kurtosis.html","id":"kurtosis","chapter":"4 Skewness & Kurtosis","heading":"4.2 Kurtosis","text":"","code":""},{"path":"skewness-kurtosis.html","id":"definition-1","chapter":"4 Skewness & Kurtosis","heading":"Definition","text":"Kurtosis random variable X \n\\[S_k= \\mathbb{E}  \\left\\{ \\frac{X-\\mathbb{E}[X]}{\\sigma} \\right\\}^4=\\frac{\\mathbb{E}[(X-\\mathbb{E}[X])^4]}{\\sigma^4} \\]\nKurtosis statistical measure defines heavily tails distribution differ tails normal distribution. words, kurtosis identifies whether tails given distribution contain extreme values.finance, kurtosis used measure financial risk. large kurtosis associated high level risk investment indicates high probabilities extremely large extremely small returns. hand, small kurtosis signals moderate level risk probabilities extreme returns relatively low.","code":""},{"path":"skewness-kurtosis.html","id":"example","chapter":"4 Skewness & Kurtosis","heading":"Example","text":"Let X follow normal distribution \\(N(0, 1)\\). \\[Kur(X)=3\\]Let X follow binomial distribution \\(B(p, n)\\). \\[Kur(X)=3+\\frac{1-6p(1-p)}{np(1-p)}\\]Let X follow t distribution \\(t(df=\\nu)\\). \\[Kur(X)=3+\\frac{6}{\\nu-4}\\]","code":""},{"path":"skewness-kurtosis.html","id":"types-of-kurtosis","chapter":"4 Skewness & Kurtosis","heading":"Types of Kurtosis","text":"Let excess kurtosis \\(\\kappa(X)=Kur(X)-3\\), following definitions:","code":""},{"path":"skewness-kurtosis.html","id":"mesokurtic","chapter":"4 Skewness & Kurtosis","heading":"4.2.1 Mesokurtic","text":"","code":"\nlibrary(moments)\nn=rnorm(n=10000, mean = 0, sd = 1)\nhist(n)\nkurtosis(n)#> [1] -0.1081596\n#> attr(,\"method\")\n#> [1] \"excess\""},{"path":"skewness-kurtosis.html","id":"leptokurtic","chapter":"4 Skewness & Kurtosis","heading":"4.2.2 Leptokurtic","text":"Leptokurtic distribution shows positive excess kurtosis \\((\\kappa > 0)\\). leptokurtic distribution shows heavy tails either side, indicating large outliers. t distribution low degree freedom typical example mesokurtic.finance, leptokurtic distribution shows investment returns may prone extreme values either side. Therefore, investment whose returns follow leptokurtic distribution considered risky. means big losses (well big gains) can occur.","code":"\nlibrary(moments)\nt=rt(n=1000,df=2)\nhist(t)\nkurtosis(t)#> [1] 26.44623\n#> attr(,\"method\")\n#> [1] \"excess\""},{"path":"skewness-kurtosis.html","id":"platykurtic","chapter":"4 Skewness & Kurtosis","heading":"4.2.3 Platykurtic","text":"platykurtic distribution shows negative excess kurtosis \\((\\kappa < 0)\\). kurtosis reveals distribution flat tails. flat tails indicate small outliers distribution.finance context, platykurtic distribution investment returns desirable investors small probability investment experience extreme returns.","code":"\nlibrary(moments)\nlibrary(e1071)                    \nduration = faithful$eruptions     \nhist(duration)\nkurtosis(duration)#> [1] -1.511605\n#> attr(,\"method\")\n#> [1] \"excess\""},{"path":"skewness-kurtosis.html","id":"financial-situation","chapter":"4 Skewness & Kurtosis","heading":"4.3 Financial situation","text":"two investments’ return distributions identical mean variance, different skewness parameters. one prefer?Typically, risk managers wary negative skew, situation, small gains norm, big losses can occur, carrying risk going bankruptcy.return distribution shows positive skew, investors can expect recurrent small losses large returns investment. Conversely, negatively skewed distribution implies many small wins large losses investment.Hence, positively skewed investment return distribution preferred negatively skewed return distribution since huge gains may cover frequent – small – losses. However, investors may prefer investments negatively skewed return distribution. may prefer frequent small wins huge losses frequent small losses large gains.","code":""},{"path":"skewness-kurtosis.html","id":"moments","chapter":"4 Skewness & Kurtosis","heading":"4.4 Moments","text":"basic statistic probability theory, almost exclusively deal first second center moment random variable, namely expectation variance \\(\\mathbb{E}[X]\\) \\(\\mathbb{E}[(X-\\mu)^2]\\). concept can generalized tok−th moment X: \\(m_k :=\\mathbb{E}(X_k)\\)k−th center moment X:\\(\\mu_k :=\\mathbb{E}[(X−\\mu)^k]\\)Using notation, population skewness kurtosis can rewritten :\n\\[\\begin{align*}\nSk(X)&=\\frac{\\mu_3}{\\mu_2^{3/2}}  \\\\\nKur(X)&=\\frac{\\mu_4}{\\mu_2^{2}}\n\\end{align*}\\]Let \\(X_1, X_2, ..., X_n\\) observations X sample mean \\(\\bar{X}\\) sample standard deviation \\(s\\).\nsample skewness denoted \\(\\widehat {Sk}\\) \n\\[ \\widehat {Sk}=\\frac{1}{n} \\sum_{=1}^{n} \\left( \\frac{X_i-\\bar{X}}{s} \\right)^3 \\]\nsample kurtosis denoted \\(\\widehat {Kur}\\) \n\\[ \\widehat {Kur}=\\frac{1}{n} \\sum_{=1}^{n} \\left( \\frac{X_i-\\bar{X}}{s} \\right)^4 \\]","code":""},{"path":"fat-tails.html","id":"fat-tails","chapter":"5 Fat tails","heading":"5 Fat tails","text":"","code":""},{"path":"fat-tails.html","id":"definition-2","chapter":"5 Fat tails","heading":"5.1 Definition","text":"tails extreme left right parts distribution. random variable said fat tails (also known heavy tails) exposes extreme outcomes normal distributed random variable mean variance. words, fat tails describe greater--expected probabilities extreme values.Financial advisors used mean–variance method model distribution probabilities values quantity, price returns. mean–variance model assumes normality fat tails present data.","code":""},{"path":"fat-tails.html","id":"example-1","chapter":"5 Fat tails","heading":"Example","text":"t-Student distribution convenient modeling fat tailed distribution. Consider t-distribution X degrees freedom \\(\\nu\\). values \\(\\nu\\) indicate fat tails areIf \\(\\nu=\\infty\\) X normal random variable.\\(\\nu<2\\) X follows fat tail distribution.typical stock \\(3<\\nu<5\\).","code":""},{"path":"fat-tails.html","id":"identification-of-fat-tails","chapter":"5 Fat tails","heading":"5.2 Identification of fat tails","text":"Two main approaches identifying analyzing tails financial returns including statistical methods: Jarque-Bera Test graphical methods: QQ plots.","code":""},{"path":"fat-tails.html","id":"statistical-methods","chapter":"5 Fat tails","heading":"5.2.1 Statistical methods","text":"Jarque-Bera (JB) tests popular statistical methods test fat tails\n\\[ JB=n \\left(\\frac{\\widehat{Sk}}{6}+\\frac{(\\widehat{Kur}-3)^2}{24} \\right) \\sim \\chi^2 \\]\nhypothesis normality, data symmetrical, .e. skewness equal zero skewness chose three.","code":""},{"path":"fat-tails.html","id":"graphical-methods","chapter":"5 Fat tails","heading":"5.2.2 Graphical methods","text":"general, Q-Q plot compares quantiles data quantiles reference distribution; data distribution type, reasonably straight line observed.QQ plot (quantile-quantile plot) compares quantiles sample data quantiles reference distribution, like normal.Used assess whether set observations particular distribution.Can also used determine whether two datasets distribution.","code":""},{"path":"fat-tails.html","id":"quantile","chapter":"5 Fat tails","heading":"5.2.2.1 Quantile","text":"pth quantile CDF F random variable X value \\(x_p\\) \\[F(x_p) = p \\quad \\text{} \\quad x_p = F^{−1}(p)\\]","code":""},{"path":"fat-tails.html","id":"q-q-plot","chapter":"5 Fat tails","heading":"5.2.2.2 Q-Q plot","text":"theoretical Q-Q plot graph quantiles CDF \\(F(x_p)=p\\) \\(x_p = F^{−1}(p)\\), versus corresponding quantiles CDF, \\(G(y_p)=p\\) \\(y_p = G^{−1}(p)\\) graph \\((F^{−1}(p), G^{−1}(p))\\) \\(p \\(0, 1)\\).\\(G(x) = F \\left(\\frac{x−\\mu}{\\sigma} \\right)\\) constants \\(\\mu\\) \\(\\sigma \\neq 0\\) \n\\[y_p = \\mu + \\sigma x_p\\]","code":""},{"path":"fat-tails.html","id":"example-2","chapter":"5 Fat tails","heading":"Example","text":"Let \\(F \\sim \\mathcal{N}(0,1)\\) \\(G(x) = F\\left(\\frac{x−1}{\\sqrt{2}} \\right) ∼ N(1,2)\\). Now choose \\(x_p = −3\\) corresponds \\(p = 0.001349898\\). probability obtain quantile distribution \\(G\\) \\(y_p = −3.242641\\). Now property Q-Q plots \n\\[y_p=1+\\sqrt{2} \\cdot (-3)=-3.242641\\]Generate standard normal distribution \\(-10\\) \\(10\\). compare \\(N(0, 1)\\), get","code":""},{"path":"fat-tails.html","id":"empirical-q-q-plots","chapter":"5 Fat tails","heading":"5.2.2.3 Empirical Q-Q plots","text":"Denote \\(F\\) specified CDF (e.g., normal) model. \\(G\\) empirical CDF observations \\(x_1, x_2, .., x_n\\) random sample \\(X_1, X_2, ..., X_n\\). compare observation \\(G\\) model \\(F\\)Plot \\(F^{−1} \\left( \\frac{1}{n} \\right)\\) horizonal axis versus.Plot \\(G^{−1} \\left( \\frac{1}{n} \\right) = x_()\\) vertical axis, \\(= 1, ..., n\\).\\(G\\) follows model \\(F\\) observed data close line \\(y = \\mu + \\sigma x\\).","code":""},{"path":"fat-tails.html","id":"example-3","chapter":"5 Fat tails","heading":"Example","text":"\\(F = \\mathcal{N}(0, 1)\\), model \\(X_1, X_2, ...X_{20} \\sim U(0, 1)\\) get Q-Q plot samples","code":""},{"path":"mixture-distributions.html","id":"mixture-distributions","chapter":"6 Mixture Distributions","heading":"6 Mixture Distributions","text":"Another class heavy-tailed models set mixture distributions. Consider simple example made \\(90\\%\\) \\(N(0,1)\\) \\(10\\%\\) \\(N(0, 25)\\), density function construct can written \n\\[f_{mix}(x) = 0.9f_{N(0,1)}(x) + 0.1f_{N(0,25)}(x)\\]generate random variable Y according distribution, can two-step process:First, draw uniform \\((0.1)\\) random variable \\(U\\) normal random variable \\(X \\sim \\mathcal{N}(0, 1)\\).Second, \\(U<0.9\\), \\(Y=X\\). \\(U>0.9\\) \\(Y=5X\\). Note model appropriate stock time shows little variability, occasionally, e.g., earning announcement events, make much bigger movements.Note model appropriate stock time shows little variability, occasionally, e.g., earning announcement events, make much bigger movements.Next use rule 3 sigma find numbers outlier ratio outlier mixture distribution \\(\\mathcal{N}(0,3.4)\\).Result show mixture distribution produces 10 times extrem events.","code":"\nu=runif(100000,0,1)\nx=rnorm(100000,0,1)\ny=ifelse(u<0.9,x,5*x)\nhist(y,xlim=c(-10,10))\nxx=seq(-9,9, length=701)\nyy=dnorm(xx, 0, sqrt(3.4))\nmm=0.9*dnorm(xx, 0, 1)+0.1*dnorm(xx, 0,5)\nplot(xx, yy, type=\"l\", ylim=c(0,0.4), ylab=\"Density\",xlab=\"x\", col=\"blue\")\nlines(xx, mm, col=\"red\", legend=c)\ntitle(\"Gaussian distribution and Normal Mixture\")\nbox()\nlegend(\"bottomright\",\n       legend = c(\"N(0, 3.4)\", \"Mixture\"),\n       col = c(\"red\",\"blue\"),lwd = 1)\nsdev=sqrt(3.4)\ngauss=2*pnorm(-3*sdev, 0, sdev)\nmixt=2*0.9*pnorm(-3*sdev,0,1)+2*0.1*pnorm(-3*sdev, 0,5)\n\nmixt/gauss#> [1] 9.948061"},{"path":"in-class-exercise.html","id":"in-class-exercise","chapter":"7 In-class exercise","heading":"7 In-class exercise","text":"","code":""},{"path":"in-class-exercise.html","id":"daily-log-return","chapter":"7 In-class exercise","heading":"7.1 Daily log-return","text":"Suppose daily log-return stock independent normally distributed mean \\(0.001\\) standard deviation \\(0.015\\). Suppose buy \\(1000\\$\\) worth stock.prbability one trading day investment worth less \\(990\\$\\)?Let \\(\\mathcal{P}_1\\) probability one trading day investment worth \\(X\\) standard normal random variable.daily log-return stock independent normally distributed mean \\(0.001\\) standard deviation \\(0.015\\): \\(r_t=\\ln \\left( \\frac{P_t}{P_{t-1}} \\right) \\sim \\mathcal{N}(0.001,0.015)\\).\\[\\begin{align*}\n\\mathcal{P}_1&=\\mathcal{P}(1000P_t \\leq 990 P_{t-1}) \\\\\n&=\\mathcal{P} \\left(r_t \\leq \\ln \\left( \\frac{990}{1000} \\right) \\right) \\\\\n&=\\mathcal{P} \\left(\\frac{r_t-0.001}{0.015}  \\leq \\frac{\\ln\\left(  \\frac{990}{1000} \\right)-0.001}{0.015} \\right) \\\\\n&=\\mathcal{P} \\left(X  \\leq -0.7366 \\right) \\\\\n&=0.23066\n\\end{align*}\\]Answer: probability one trading day investment worth less 990$ \\(23.066\\%\\).probability five trading days investment worth less \\(990\\$\\)?Let \\(\\mathcal{P}_5\\) probability five trading day investment worth.five day log-return stock independent normally distributed mean \\(0.001 \\cdot 5\\) standard deviation \\(0.015 \\cdot \\sqrt{5}\\): \\(r_t=\\ln \\left( \\frac{P_t}{P_{t-1}} \\right) \\sim \\mathcal{N}(0.001 \\cdot 5,0.015 \\cdot \\sqrt{5})\\).\\[\\begin{align*}\n\\mathcal{P}_5&=\\mathcal{P}(1000P_t \\leq 990 P_{t-5}) \\\\\n&=\\mathcal{P} \\left(r_t \\leq \\ln \\left( \\frac{990}{1000} \\right) \\right) \\\\\n&=\\mathcal{P} \\left(\\frac{r_t-0.001 \\cdot 5}{0.015 \\cdot \\sqrt{5}}  \\leq \\frac{\\ln\\left(  \\frac{990}{1000} \\right)-0.001 \\cdot 5}{0.015 \\cdot \\sqrt{5}} \\right) \\\\\n&=\\mathcal{P} \\left(X  \\leq -0.4487 \\right) \\\\\n&=0.32682\n\\end{align*}\\]Answer: probability five trading day investment worth less \\(990\\$\\) \\(32.68\\%\\).","code":""},{"path":"in-class-exercise.html","id":"skewness-kurtosis-1","chapter":"7 In-class exercise","heading":"7.2 Skewness & Kurtosis","text":"Calculate skewness kurtosis following density function\\[f(x) =\\begin{cases}\n\\frac{3}{8}x^2 & \\text{} 0<x<2\\\\\n0 & \\text{otherwise}\n\\end{cases}\\]\\[\\begin{align*}\n\\mu_1&=\\mathbb{E}[X] \\\\\n&=\\int_{0}^{2}x \\cdot \\frac{3}{8}x^2\\,dx \\\\\n&=\\frac{3}{2} \\\\\n\\\\\n\\mu_2&=\\mathbb{E}[X^2] \\\\\n&=\\int_{0}^{2}x^2 \\cdot \\frac{3}{8}x^2\\,dx \\\\\n&=\\frac{12}{5}\n\\end{align*}\\]\\[\\begin{align*}\nSk&=\\frac{\\mathbb{E}[(X-\\mu_1)^3]}{\\sigma^3} \\\\\n&=\\frac{\\int_{0}^{2}(x-\\mu_1)^3 \\cdot \\frac{3}{8}x^2\\,dx}{(\\mu_2-\\mu_1^2)^{3/2}} \\\\\n&=\\frac{\\int_{0}^{2}(x-\\frac{3}{2})^3 \\cdot \\frac{3}{8}x^2\\,dx}{\\left[ \\frac{12}{5}-\\left( \\frac{3}{2} \\right)^2 \\right]^{3/2}} \\\\\n&=-0.86 \\\\\n\\\\\nKur&=\\frac{\\mathbb{E}[(X-\\mu_1)^4]}{\\sigma^4} \\\\\n&=\\frac{\\int_{0}^{2}(x-\\mu_1)^4 \\cdot \\frac{3}{8}x^2\\,dx}{(\\mu_2-\\mu_1^2)^{4/2}} \\\\\n&=\\frac{\\int_{0}^{2}(x-\\frac{3}{2})^4 \\cdot \\frac{3}{8}x^2\\,dx}{\\left[ \\frac{12}{5}-\\left( \\frac{3}{2} \\right)^2 \\right]^{4/2}} \\\\\n&=3.10\n\\end{align*}\\]Answer: skewness \\(-0.86\\) kurtosis \\(3.10\\).","code":""},{"path":"in-class-exercise.html","id":"python","chapter":"7 In-class exercise","heading":"Python","text":"Calculate skewness kurtosis log return exchange rate EURO USD.Calculate skewness kurtosis log return exchange rate S&P500.","code":"import numpy as np\nimport pandas as pd\n# Import and calculate log return    \neurusd_url='https://docs.google.com/spreadsheets/d/e/2PACX-1vT4WqdVoUIiaMcd4jQj5by3Oauc6G4EFq9VDDrpzG2oBn6TFzyNE1yPV2fKRal5F7DmRzCtVa4nSQIw/pub?gid=0&single=true&output=csv'\neurusd=pd.read_csv(eurusd_url)\neurusd.head()#>          Date  USD per euro\n#> 0  27/07/2005        1.1990\n#> 1  28/07/2005        1.2100\n#> 2  29/07/2005        1.2093\n#> 3  01/08/2005        1.2219\n#> 4  02/08/2005        1.2217eurusd_logret = np.log(eurusd['USD per euro']) - np.log(eurusd['USD per euro'].shift(1))\neurusd_logret[:6]#> 0         NaN\n#> 1    0.009132\n#> 2   -0.000579\n#> 3    0.010365\n#> 4   -0.000164\n#> 5    0.007421\n#> Name: USD per euro, dtype: float64import matplotlib.pyplot as plt\n# Exploratory\neurusd_logret.plot()\nplt.xlabel(\"Date\")\nplt.ylabel(\"Log-Return'\")\nplt.title(\"Log-Return of Exchange Rate over time'\")\nplt.show()import matplotlib.pyplot as plt\nfig = plt.figure()\nax1 = fig.add_axes([0.1,0.1,0.8,0.8])\neurusd_logret.plot.hist(bins = 60)\nax1.set_xlabel(\"Log Return\")\nax1.set_ylabel(\"Percent\")\nax1.set_title(\"Histogram of Log return\")\nplt.show()import pandas as pd\neurusd_logret.skew()#> -0.07336059594162114eurusd_logret.kurtosis()#> 4.66844649461392import numpy as np\nimport pandas as pd\nsp500_url='https://docs.google.com/spreadsheets/d/e/2PACX-1vT4WqdVoUIiaMcd4jQj5by3Oauc6G4EFq9VDDrpzG2oBn6TFzyNE1yPV2fKRal5F7DmRzCtVa4nSQIw/pub?gid=279168786&single=true&output=csv'\nsp500=pd.read_csv(sp500_url)\nsp500.head()#>          Date    Open    High     Low   Close    Volume  Adj Close\n#> 0  01/03/1985  165.37  166.11  164.38  164.57  88880000     164.57\n#> 1  01/04/1985  164.55  164.55  163.36  163.68  77480000     163.68\n#> 2  01/07/1985  163.68  164.71  163.68  164.24  86190000     164.24\n#> 3  01/08/1985  164.24  164.59  163.91  163.99  92110000     163.99\n#> 4  01/09/1985  163.99  165.57  163.99  165.18  99230000     165.18sp500_logret = np.log(sp500['Close']) - np.log(sp500['Close'].shift(1))\nsp500_logret[:6]#> 0         NaN\n#> 1   -0.005423\n#> 2    0.003415\n#> 3   -0.001523\n#> 4    0.007230\n#> 5    0.018772\n#> Name: Close, dtype: float64import matplotlib.pyplot as plt\nsp500_logret.plot()\nplt.xlabel(\"Date\")\nplt.ylabel(\"Log-Return'\")\nplt.title(\"Log-Return of S&P500 over time'\")\nplt.show()import matplotlib.pyplot as plt\nfig = plt.figure()\nax1 = fig.add_axes([0.1,0.1,0.8,0.8])\nsp500_logret.plot.hist(bins = 60)\nax1.set_xlabel(\"Log Return\")\nax1.set_ylabel(\"Percent\")\nax1.set_title(\"Histogram of Log return\")\nplt.show()import pandas as pd\nsp500_logret.skew()#> -1.2989867430563735sp500_logret.kurtosis()#> 28.28091194470013"},{"path":"in-class-exercise.html","id":"r","chapter":"7 In-class exercise","heading":"R","text":"Calculate skewness kurtosis log return exchange rate EURO USD.Calculate skewness kurtosis log return exchange rate S&P500.","code":"\nlibrary(tidyverse)\nlibrary(moments)\n# Import and calculate log return\neurusd_url=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vT4WqdVoUIiaMcd4jQj5by3Oauc6G4EFq9VDDrpzG2oBn6TFzyNE1yPV2fKRal5F7DmRzCtVa4nSQIw/pub?gid=0&single=true&output=csv\"\neurusd=read.csv(eurusd_url)\nhead(eurusd)#>         Date USD.per.euro\n#> 1 27/07/2005       1.1990\n#> 2 28/07/2005       1.2100\n#> 3 29/07/2005       1.2093\n#> 4 01/08/2005       1.2219\n#> 5 02/08/2005       1.2217\n#> 6 03/08/2005       1.2308\neurusd_logret=eurusd[,2] %>% \n  log %>% \n  diff\nhead(eurusd_logret)#> [1]  0.0091324836 -0.0005786798  0.0103653445 -0.0001636929  0.0074210330\n#> [6]  0.0008933285\nplot(eurusd_logret,type=\"l\")\nhist(eurusd_logret,breaks=60)\nlibrary(e1071)\nskewness(eurusd_logret)#> [1] -0.07318848\n#> attr(,\"method\")\n#> [1] \"moment\"\nkurtosis(eurusd_logret)#> [1] 4.633551\n#> attr(,\"method\")\n#> [1] \"excess\"\nlibrary(tidyverse)\nlibrary(moments)\n# Import and calculate log return\nsp500_url=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vT4WqdVoUIiaMcd4jQj5by3Oauc6G4EFq9VDDrpzG2oBn6TFzyNE1yPV2fKRal5F7DmRzCtVa4nSQIw/pub?gid=279168786&single=true&output=csv\"\nsp500=read.csv(sp500_url)\nhead(sp500)#>         Date   Open   High    Low  Close    Volume Adj.Close\n#> 1 01/03/1985 165.37 166.11 164.38 164.57  88880000    164.57\n#> 2 01/04/1985 164.55 164.55 163.36 163.68  77480000    163.68\n#> 3 01/07/1985 163.68 164.71 163.68 164.24  86190000    164.24\n#> 4 01/08/1985 164.24 164.59 163.91 163.99  92110000    163.99\n#> 5 01/09/1985 163.99 165.57 163.99 165.18  99230000    165.18\n#> 6  1/10/1985 165.18 168.31 164.99 168.31 124700000    168.31\nsp500_logret= sp500$Adj.Close %>% \n  log %>% \n  diff\nhead(sp500_logret)#> [1] -0.005422709  0.003415471 -0.001523322  0.007230338  0.018771729\n#> [6] -0.002379396\nplot(sp500_logret,type=\"l\")\nhist(sp500_logret,breaks=60)\nlibrary(e1071)\nskewness(sp500_logret)#> [1] -1.298466\n#> attr(,\"method\")\n#> [1] \"moment\"\nkurtosis(sp500_logret)#> [1] 28.25285\n#> attr(,\"method\")\n#> [1] \"excess\""},{"path":"in-class-exercise.html","id":"the-jarque-bera-jb-tests","chapter":"7 In-class exercise","heading":"7.3 The Jarque-Bera (JB) tests","text":"","code":""},{"path":"in-class-exercise.html","id":"python-1","chapter":"7 In-class exercise","heading":"Python","text":"Check data log return exchange rate Euro USD follow normal distribution.\\(p-value<0.05\\) can reject null hypothesis \\(H_0: Sk=0 \\text{ } Kur=3\\) meaning log return exchange rate EURUSD follow normal distribution.Check data log return exchange rate S&P500 follow normal distribution.\\(p-value<0.05\\) can reject null hypothesis \\(H_0: Sk=0 \\text{ } Kur=3\\) meaning log return exchange rate S&P500 follow normal distribution.","code":"import scipy.stats as stats\nprint(stats.jarque_bera(eurusd_logret[1:]),stats.kstest(eurusd_logret[1:],'norm'))#> Jarque_beraResult(statistic=1150.3195976112938, pvalue=0.0) KstestResult(statistic=0.48876441843556134, pvalue=5.961875332718074e-282)import scipy.stats as stats\nprint(stats.jarque_bera(sp500_logret[1:]),stats.kstest(sp500_logret[1:],'norm'))#> Jarque_beraResult(statistic=250996.03457721754, pvalue=0.0) KstestResult(statistic=0.4800295652866924, pvalue=0.0)"},{"path":"in-class-exercise.html","id":"r-1","chapter":"7 In-class exercise","heading":"R","text":"Check data log return exchange rate Euro USD follow normal distribution.\\(p-value<0.05\\) can reject null hypothesis \\(H_0: Sk=0 \\text{ } Kur=3\\) meaning log return exchange rate EURUSD follow normal distribution.Check data log return exchange rate S&P500 follow normal distribution.\\(p-value<0.05\\) can reject null hypothesis \\(H_0: Sk=0 \\text{ } Kur=3\\) meaning log return exchange rate S&P500 follow normal distribution.","code":"\nlibrary(moments)\njarque.test(eurusd_logret)#> \n#>  Jarque-Bera Normality Test\n#> \n#> data:  eurusd_logret\n#> JB = 1150.3, p-value < 2.2e-16\n#> alternative hypothesis: greater\nlibrary(moments)\njarque.test(sp500_logret)#> \n#>  Jarque-Bera Normality Test\n#> \n#> data:  sp500_logret\n#> JB = 250996, p-value < 2.2e-16\n#> alternative hypothesis: greater"},{"path":"in-class-exercise.html","id":"q-q-plot-1","chapter":"7 In-class exercise","heading":"7.4 Q-Q plot","text":"","code":""},{"path":"in-class-exercise.html","id":"python-2","chapter":"7 In-class exercise","heading":"Python","text":"Q-Q plot log return exchange rate Euro USDQ-Q plot log return S&P500","code":"import statsmodels.api as sm\nimport pylab as py\nsm.qqplot(eurusd_logret, line ='q')\npy.show()import statsmodels.api as sm\nimport pylab as py\nsm.qqplot(sp500_logret, line ='q')\npy.show()"},{"path":"in-class-exercise.html","id":"r-2","chapter":"7 In-class exercise","heading":"R","text":"Q-Q plot log return exchange rate Euro USDQ-Q plot log return S&P500","code":"\nqqnorm(eurusd_logret)\nqqline(eurusd_logret, col = \"red\")\nqqnorm(sp500_logret)\nqqline(sp500_logret, col = \"red\")"},{"path":"homework.html","id":"homework","chapter":"Homework","heading":"Homework","text":"","code":""},{"path":"homework.html","id":"problem-1","chapter":"Homework","heading":"Problem 1","text":"prices dividends stock given follows.","code":""},{"path":"homework.html","id":"question-a","chapter":"Homework","heading":"Question a","text":"Determine \\(R_2\\) \\(R_4(3)\\).\\[\\begin{align*}\nR_2&=\\frac{P_2-P_1+d_2}{P_1} \\\\\n&=\\frac{54-52+0.2}{52} \\\\\n&=0.042 \\\\\nR_3&=\\frac{P_3-P_2+d_3}{P_2} \\\\\n&=\\frac{53-54+0.2}{54} \\\\\n&=-0.015 \\\\\nR_4&=\\frac{P_4-P_3+d_4}{P_3} \\\\\n&=\\frac{59-53+0.25}{53} \\\\\n&=0.118 \\\\\n\\end{align*}\\]\\[\\begin{align*}\nR_4(3)&=(1+R_4)(1+R_3)(1+R_2)-1 \\\\\nR_4(3)&=(1+0.118)(1-0.015)(1+0.042)-1 \\\\\n&\\approx 0.148\n\\end{align*}\\]Answer: \\(R_2 \\approx 0.042\\) \\(R_4(3) \\approx 0.148\\).","code":""},{"path":"homework.html","id":"question-b","chapter":"Homework","heading":"Question b","text":"Determine \\(r_3\\).\\[\\begin{align*}\nr_3&=\\ln(1+R_3) \\\\\n&\\approx R_3 \\\\\n&\\approx-0.015\n\\end{align*}\\]Answer: \\(r_3 \\approx -0.015\\)","code":""},{"path":"homework.html","id":"problem-2","chapter":"Homework","heading":"Problem 2","text":"Assume log returns \\(r_t \\sim \\mathcal{N}(0.06, 0.47)\\) ..d.","code":""},{"path":"homework.html","id":"question-a-1","chapter":"Homework","heading":"Question a","text":"Determine distribution \\(r_t(4)\\).\\[\\begin{align*}\nr_t(4)&=r_t+r_{t-1}+r_{t-2}+r_{t-3} \\\\\n&\\sim 4 \\cdot \\mathcal{N}(0.06,0.47) \\\\\n&\\sim  \\mathcal{N}(4 \\cdot 0.06,4 \\cdot 0.47) \\\\\n&\\sim \\mathcal{N}(0.24,1.18)\n\\end{align*}\\]Answer: distribution \\(r_t(4)\\) \\(\\mathcal{N}(0.24,1.18)\\).","code":""},{"path":"homework.html","id":"question-b-1","chapter":"Homework","heading":"Question b","text":"Find \\(cov(r_2(1), r_2(2))\\).\\[\\begin{align*}\ncov(r_2(1),r_2(2))&=cov(r_2,r_2+r_1) \\\\\n&=cov(r_2,r_2)+cov(r_2,r_1) \\\\\n&=var(r_2)+cov(r_1,r_2) \\\\\n&=0.47\n\\end{align*}\\]Answer: \\(cov(r_2(1),r_2(2))=0.47\\)","code":""},{"path":"homework.html","id":"question-c","chapter":"Homework","heading":"Question c","text":"Determine distribution \\(r_t(3)\\) \\(r_{t−2} = 0.6\\).\\[\\begin{align*}\n[r_t(3)|r_{t-2}=0.6]&=[r_t+r_{t-1}+r_{t-2}|r_{t-2}=0.6] \\\\\n&=r_t+r_{t-1}+0.6 \\\\\n&\\sim \\mathcal{N}(0.06,0.47)+\\mathcal{N}(0.06,0.47)+0.6 \\\\\n&\\sim \\mathcal{N}(2 \\cdot 0.06+0.6, 2 \\cdot 0.47) \\\\\n&\\sim \\mathcal{N}(0.72, 0.94)\n\\end{align*}\\]Answer: \\(r_{t-2}=0.6\\), distribution \\(r_t(3)\\) \\(\\mathcal{N}(0.72,0.94)\\).","code":""},{"path":"homework.html","id":"problem-3","chapter":"Homework","heading":"Problem 3","text":"Assume stock current price $97 ..d. log returns\\[r_t \\sim \\mathcal{N}(2 \\cdot 10^{−4}, 9 \\cdot 10^{−4})\\]\nprobability price exceeds \\(\\$100\\) 20 trading days?\\[\\begin{align*}\n\\ln \\left( \\frac{P_{20}}{P_0} \\right) &= r_{20}(20) \\\\\n\\ln  P_{20} - \\ln P_0 &= \\sum_{t=1}^{20}r_t \\\\\n&\\sim 20 \\cdot \\mathcal{N}(2 \\cdot 10^{−4}, 9 \\cdot 10^{−4}) \\\\\n&\\sim  \\mathcal{N}(20 \\cdot 2 \\cdot 10^{−4}, 20 \\cdot 9 \\cdot 10^{−4}) \\\\\n\\end{align*}\\]\\[\\begin{align*}\n\\rightarrow \\ln(P_{20})&=\\ln(P_{0})+r_{20}(20) \\\\\n&\\sim \\ln(97)+\\mathcal{N}(20 \\cdot 2 \\cdot 10^{−4}, 20 \\cdot 9 \\cdot 10^{−4}) \\\\\n&\\sim \\mathcal{N}(\\ln(97)+20 \\cdot 2 \\cdot 10^{−4}, 20 \\cdot 9 \\cdot 10^{−4}) \\\\\n\\end{align*}\\]\\[\\begin{align*}\n\\mathcal{P}(P_{20}>100)&=\\mathcal{P}(\\ln(P_{20})>\\ln(100)) \\\\\n&=\\mathcal{P} \\left(\\frac{\\ln(P_{20})-(\\ln(97)+20 \\cdot 2 \\cdot 10^{−4})}{\\sqrt{20 \\cdot 9 \\cdot 10^{−4})}} > \\frac{\\ln(100)-(\\ln(97)+20 \\cdot 2 \\cdot 10^{−4})}{\\sqrt{20 \\cdot 9 \\cdot 10^{−4})}} \\right) \\\\\n&=\\mathcal{P} \\left(\\mathcal{Z} > \\frac{\\ln(100)-(\\ln(97)+20 \\cdot 2 \\cdot 10^{−4})}{\\sqrt{20 \\cdot 9 \\cdot 10^{−4})}} \\right) \\\\\n&=\\mathcal{P} \\left(\\mathcal{Z} < -\\frac{\\ln(100)-(\\ln(97)+20 \\cdot 2 \\cdot 10^{−4})}{\\sqrt{20 \\cdot 9 \\cdot 10^{−4})}} \\right) \\\\\n&=0.42183\n\\end{align*}\\]Answer: probability price exceeds \\(\\$100\\) 20 trading days 42.183%.","code":""},{"path":"homework.html","id":"problem-4","chapter":"Homework","heading":"Problem 4","text":"Assume log returns \\(r_t \\sim \\mathcal{N}(5 \\cdot 10^{−4}, 0.012)\\) ..d. Minimize t \\[\\mathcal{P} \\left( \\frac{P_t}{P_0}  \\geq 2\\right) \\geq 0.9\\]\n.e. probability price doubles t days least 90%.\\[\\begin{align*}\n\\ln\\left( \\frac{P_t}{P_0} \\right) &=r_t(t) \\\\\n&=\\sum_{=1}^{t}r_i \\\\\n&\\sim t \\cdot \\mathcal{N}(5 \\cdot 10^{−4}, 0.012) \\\\\n&\\sim  \\mathcal{N}(t \\cdot 5 \\cdot 10^{−4},t \\cdot 0.012)\n\\end{align*}\\]\\[\\begin{align*}\n\\mathcal{P} \\left( \\frac{P_t}{P_0}  \\geq 2\\right) &= \\mathcal{P} \\left( \\ln \\left( \\frac{P_t}{P_0} \\right)  \\geq \\ln(2) \\right) \\\\\n&=\\mathcal{P} \\left(\\frac{\\ln \\left( \\frac{P_t}{P_0} \\right)-t \\cdot 5 \\cdot 10^{−4}}{\\sqrt{t \\cdot 0.012}} \\geq\n\\frac{\\ln(2)-t \\cdot 5 \\cdot 10^{−4}}{\\sqrt{t \\cdot 0.012}} \\right) \\\\\n&=\\mathcal{P} \\left(\\mathcal{Z} \\geq\n\\frac{\\ln(2)-t \\cdot 5 \\cdot 10^{−4}}{\\sqrt{t \\cdot 0.012}} \\right) \\\\\n&=\\mathcal{P} \\left(\\mathcal{Z} \\leq\n-\\frac{\\ln(2)-t \\cdot 5 \\cdot 10^{−4}}{\\sqrt{t \\cdot 0.012}} \\right)\n\\end{align*}\\]\\[\\begin{align*}\n&\\mathcal{P} \\left( \\frac{P_t}{P_0}  \\geq 2\\right) \\geq 0.9 \\\\\n&\\rightarrow \\mathcal{P} \\left(\\mathcal{Z} \\leq\n-\\frac{\\ln(2)-t \\cdot 5 \\cdot 10^{−4}}{\\sqrt{t \\cdot 0.012}} \\right) \\geq 0.9 \\\\\n&\\rightarrow -\\frac{\\ln(2)-t \\cdot 5 \\cdot 10^{−4}}{\\sqrt{t \\cdot 0.012}}\\geq\\Phi^{-1}(0.9) \\\\\n&\\rightarrow t \\geq 81638.20\n\\end{align*}\\]Answer: Minimum value t probability price doubles t days 81639.","code":""},{"path":"homework.html","id":"problem-5","chapter":"Homework","heading":"Problem 5","text":"Let \\((X_n)_{n \\geq 0}\\) log-normal geometric random walk parameters \\(\\mu\\) \\(\\sigma\\), .e.\\[ X_k= X_0 e^{\\sum_{=1}^k r_i}, \\forall k \\\\mathbb{N} \\]\\(r_i \\sim \\mathcal{N}(\\mu,\\sigma^2)\\) ..d \\(X_0 \\neq 0\\) constant.","code":""},{"path":"homework.html","id":"question-a-2","chapter":"Homework","heading":"Question a","text":"Determine \\(P(X_2 > 1.3X_0)\\).\\[\\begin{align*}\nr_1+r_2 &\\sim \\mathcal{N}(\\mu,\\sigma^2)+\\mathcal{N}(\\mu,\\sigma^2) \\\\\n&\\sim \\mathcal{N}(2\\mu,2\\sigma^2)\n\\end{align*}\\]\\[\\begin{align*}\n\\mathbb{P}(X_2>1.3X_0) &= \\mathbb{P} \\left( \\frac{X_2}{X_0}>1.3 \\right) \\\\\n&= \\mathbb{P} \\left( e^{r_1+r_2}>1.3 \\right) \\\\\n&=\\mathbb{P} \\left({r_1+r_2}>\\ln(1.3) \\right) \\\\\n&=\\mathbb{P} \\left( \\mathcal{Z} > \\frac{\\ln(1.3)-2\\mu}{\\sigma \\sqrt{2}} \\right) \\\\\n&=\\Phi \\left( -\\frac{\\ln(1.3)-2\\mu}{\\sigma \\sqrt{2}} \\right)\n\\end{align*}\\]Answer: \\(\\mathbb{P}(X_2>1.3X_0)=\\Phi \\left( -\\frac{\\ln(1.3)-2\\mu}{\\sigma \\sqrt{2}} \\right)\\)","code":""},{"path":"homework.html","id":"question-b-2","chapter":"Homework","heading":"Question b","text":"Find density \\(f_{X_1}\\) \\(X_1\\).\\[\\begin{align*}\nF_{X_1}(x) &=\\mathbb{P}(X_1 \\leq x) \\\\\n&=\\mathbb(X_0e^{r_1} \\leq x) \\\\\n&=\\mathbb{P}(r_1 \\leq \\ln(x)-\\ln(X_0) \\\\\n&=\\mathbb{P} \\left( \\mathcal{Z} \\leq \\frac{\\ln(x)-\\ln(X_0)-\\mu}{\\sigma} \\right) \\\\\n&=\\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\frac{\\ln(x)-\\ln(X_0)-\\mu}{\\sigma}} e^{\\frac{-1}{2}t^2}\\,dt \\\\ \\rightarrow f_{X_1}(x) &= \\frac{1}{\\sqrt{2\\pi}} \\cdot \\left( \\frac{\\ln(x)-\\ln(X_0)-\\mu}{\\sigma} \\right)' \\cdot e^{-\\frac{1}{2}\\left( \\frac{\\ln(x)-\\ln(X_0)-\\mu}{\\sigma} \\right)^2} \\\\\n&=\\frac{e^{-\\frac{1}{2}\\frac{(\\ln(x)-\\ln(X_0)-\\mu)^2}{\\sigma^2}}}{\\sigma x \\sqrt{2\\pi}}\n\\end{align*}\\]Answer: \\(f_{X_1}(x)=\\frac{e^{-\\frac{(\\ln(x)-\\ln(X_0)-\\mu)^2}{2\\sigma^2}}}{\\sigma x \\sqrt{2\\pi}}\\)","code":""},{"path":"homework.html","id":"question-c-1","chapter":"Homework","heading":"Question c","text":"Find formula \\(0.9\\) quantile \\(X_k\\) \\(k \\\\mathbb{N}\\).Let \\(x_k\\) 0.9 quantile \\(X_k\\)\n\\[\\begin{align*}\n\\sum_{=1}^{k} r_i &\\sim k \\cdot \\mathcal{N}(\\mu,\\sigma^2) \\\\\n&\\sim \\mathcal{N}(k\\mu,k\\sigma^2) \\\\\n\\end{align*}\\]\\[\\begin{align*}\n\\mathbb{P}(X_k \\leq x_k) &= \\mathbb{P} \\left( \\frac{X_k}{X_0} \\leq \\frac{x_k}{X_0} \\right) \\\\\n&= \\mathbb{P} \\left( e^{\\sum_{=1}^{k} r_i} \\leq \\frac{x_k}{X_0} \\right) \\\\\n&=\\mathbb{P} \\left({\\sum_{=1}^{k} r_i} \\leq \\ln(x_k) -\\ln(X_0) \\right) \\\\\n&=\\mathbb{P} \\left( \\mathcal{Z} \\leq \\frac{\\ln(x_k) -\\ln(X_0)-k\\mu}{\\sigma \\sqrt{k}} \\right) \\\\\n&=\\Phi \\left( \\frac{\\ln(x_k) -\\ln(X_0)-k\\mu}{\\sigma \\sqrt{k}} \\right)\n\\end{align*}\\]\\[\\begin{align*}\n&\\mathbb{P}(X_k \\leq x_k) = 0.9 \\\\\n&\\rightarrow \\Phi \\left( \\frac{\\ln(x_k) -\\ln(X_0)-k\\mu}{\\sigma \\sqrt{k}} \\right) = 0.9 \\\\\n&\\rightarrow \\frac{\\ln(x_k) -\\ln(X_0)-k\\mu}{\\sigma \\sqrt{k}}=\\Phi^{-1}(0.9) \\\\\n&\\rightarrow x_k=X_0 e^{\\Phi^{-1}(0.9) \\sigma \\sqrt{k} +k\\mu}\n\\end{align*}\\]Answer: formula 0.9 quantile \\(X_k\\) \\(k \\\\mathbb{N}\\) \\(X_0 e^{\\Phi^{-1}(0.9) \\sigma \\sqrt{k} +k\\mu}\\).","code":""},{"path":"homework.html","id":"problem-6","chapter":"Homework","heading":"Problem 6","text":"Given data McDonald’s stock returns. Using R Python:","code":""},{"path":"homework.html","id":"python-3","chapter":"Homework","heading":"Python","text":"","code":""},{"path":"homework.html","id":"question-a-3","chapter":"Homework","heading":"Question a","text":"Plot histogram display fitted normal.","code":"import pandas as pd\n\n# Import data from my Google Spreadsheet\nmcd_url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTI1rEZM9rAQqxrz5ogOTzKJZXD99n6vmsRpZXFzILLoyBs-ViFx24WOC5jqf61uaG7M5XDv6h3kG4D/pub?gid=2115254660&single=true&output=csv'\nmcd = pd.read_csv(mcd_url)\nmcd.head()#>        Date   Open   High    Low  Close    Volume  Adj Close\n#> 0  1/4/2010  62.63  63.07  62.31  62.78   5839300      53.99\n#> 1  1/5/2010  62.66  62.75  62.19  62.30   7099000      53.58\n#> 2  1/6/2010  62.20  62.41  61.06  61.45  10551300      52.85\n#> 3  1/7/2010  61.25  62.34  61.11  61.90   7517700      53.24\n#> 4  1/8/2010  62.27  62.41  61.60  61.84   6107300      53.19import numpy as np\n# Calculate Log Returns\nmcd_logret = np.log(list(mcd['Adj Close'])[1:]) - np.log(list(mcd['Adj Close'])[:-1])\nmcd_logret[:6] # first 10 elements#> array([-0.00762298, -0.01371815,  0.00735228, -0.00093958,  0.00767866,\n#>         0.00539586])from scipy.stats.distributions import norm\nimport matplotlib.pyplot as plt\n# Histogram and fitted normal distribution\nmu, var = norm.fit(mcd_logret)\nx = np.linspace(min(mcd_logret), max(mcd_logret), 100)\nfitted_mcd_logret = norm.pdf(x, mu, var)\nplt.hist(mcd_logret, density = True)#> (array([ 0.18620447,  0.46551117,  2.60686253,  9.4964278 , 37.24089335,\n#>        46.27180998, 10.6136546 ,  2.2344536 ,  0.09310223,  0.2793067 ]), array([-0.04555068, -0.03641728, -0.02728388, -0.01815047, -0.00901707,\n#>         0.00011633,  0.00924973,  0.01838313,  0.02751654,  0.03664994,\n#>         0.04578334]), <BarContainer object of 10 artists>)plt.plot(x, fitted_mcd_logret, 'r-')\nplt.show()"},{"path":"homework.html","id":"question-b-3","chapter":"Homework","heading":"Question b","text":"Use QQ plot Jaque-Bera test test normality interpret result.presence outliers, .e. log returns seems normally distributed.\\(p−value<0.05\\) can reject null hypothesis \\(H_0\\): \\(Sk=0\\) \\(Kur=3\\) meaning log return data follow normal distribution.","code":"import statsmodels.api as sm\nimport pylab\nsm.qqplot(mcd_logret, line = 's')\npylab.show()from scipy.stats import jarque_bera\n# Carry out a Jarque-Bera tests\njarque_bera(mcd_logret)#> Jarque_beraResult(statistic=367.2407128291914, pvalue=0.0)"},{"path":"homework.html","id":"question-c-2","chapter":"Homework","heading":"Question c","text":"Calculate skewness, kurtosis give comments related risk management.negative skewness indicates left-skewed distribution, .e. investors can expect recurrent small gains huge losses investing McDonalds’ stock. Hence stock potential investors since expected huge losses may overwhelm frequent (small) gains.positive excess kurtosis indicates leptokurtic distribution, .e. large outliers. Hence McDonalds’ stock desirable pessimistic investors since chance experiencing big losses high.","code":"from scipy.stats import skew, kurtosis\n# Skewness and Kurtosis\nprint('Skewness:', skew(mcd_logret))#> Skewness: -0.1604213839619458print('Excess Kurtosis:', kurtosis(mcd_logret))#> Excess Kurtosis: 2.7187806721684025"},{"path":"homework.html","id":"r-3","chapter":"Homework","heading":"R","text":"","code":""},{"path":"homework.html","id":"question-a-4","chapter":"Homework","heading":"Question a","text":"Plot histogram display fitted normal.","code":"\nlibrary(tidyverse)\n\n# Import data from my Google Spreadsheet\nmcd_url=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vTI1rEZM9rAQqxrz5ogOTzKJZXD99n6vmsRpZXFzILLoyBs-ViFx24WOC5jqf61uaG7M5XDv6h3kG4D/pub?gid=2115254660&single=true&output=csv\"\nmcd=read.csv(mcd_url)\n\n# Calculate log return\nmcd_logret= mcd$Adj.Close %>% \n  log %>% \n  diff\nhead(mcd_logret)#> [1] -0.0076229801 -0.0137181518  0.0073522812 -0.0009395848  0.0076786593\n#> [6]  0.0053958639\n# Histogram and fitted normal distribution\nh=hist(mcd_logret)\nxfit = seq(min(mcd_logret), max(mcd_logret), length = 100)\nyfit = dnorm(xfit, mean = mean(mcd_logret), sd = sd(mcd_logret)) * diff(h$mids[1:2]) * length(mcd_logret)\nlines(xfit, yfit, col = \"red\", lwd = 2)"},{"path":"homework.html","id":"question-b-4","chapter":"Homework","heading":"Question b","text":"Use QQ plot Jaque-Bera test test normality interpret result. (c) Calculate skewness, kurtosis give comments related risk management.presence outliers, .e. log returns seems normally distributed.\\(p−value<0.05\\) can reject null hypothesis \\(H_0\\): \\(Sk=0\\) \\(Kur=3\\) meaning log return data follow normal distribution.","code":"\nlibrary(moments)\n# Make a Q-Q plot and add a red line\nqqnorm(mcd_logret)\nqqline(mcd_logret, col = \"red\")\n# Carry out a Jarque-Bera test\njarque.test(mcd_logret)#> \n#>  Jarque-Bera Normality Test\n#> \n#> data:  mcd_logret\n#> JB = 367.24, p-value < 2.2e-16\n#> alternative hypothesis: greater"},{"path":"homework.html","id":"question-c-3","chapter":"Homework","heading":"Question c","text":"Calculate skewness, kurtosis give comments related risk management.negative skewness indicates left-skewed distribution, .e. investors can expect recurrent small gains huge losses investing McDonalds’ stock. Hence stock potential investors since expected huge losses may overwhelm frequent (small) gains.positive excess kurtosis indicates leptokurtic distribution, .e. large outliers. Hence McDonalds’ stock desirable pessimistic investors since chance experiencing big losses high.","code":"\nlibrary(moments)\nskewness(mcd_logret)#> [1] -0.1602168\n#> attr(,\"method\")\n#> [1] \"moment\"\nkurtosis(mcd_logret)-3#> [1] -0.290941\n#> attr(,\"method\")\n#> [1] \"excess\""},{"path":"homework.html","id":"problem-7","chapter":"Homework","heading":"Problem 7","text":"Assume random variable X distribution\n\\[P(X =−4)= \\frac{1}{3}, P(X =1)= \\frac{1}{2}, P(X =5)= \\frac{1}{6}\\]\nCheck \\(X\\) skewness \\(0\\), distributed symmetrically.\\[\\begin{align*}\nE[X] &=\\mathbb{P}(X=-4) \\cdot (-4)+\\mathbb{P}(X=1) \\cdot (1)+\\mathbb{P}(X=5) \\cdot (5) \\\\\n&=0\n\\end{align*}\\]\\[\\begin{align*}\nE[X^2] &=\\mathbb{P}(X=-4) \\cdot (-4)^2+\\mathbb{P}(X=1) \\cdot (1)^2+\\mathbb{P}(X=5) \\cdot (5)^2 \\\\\n&=\\frac{1}{3} \\cdot (16) + \\frac{1}{2} \\cdot (1)+\\frac{1}{6} \\cdot (25) \\\\\n&=10\n\\end{align*}\\]\\[\\begin{align*}\nVar(x) &= E[X^2] - E[X]^2 \\\\\n&=10-0 \\\\\n&=10\n\\end{align*}\\]\\[\\begin{align*}\nE[X^3] &=\\mathbb{P}(X=-4) \\cdot (-4)^3+\\mathbb{P}(X=1) \\cdot (1)^3+\\mathbb{P}(X=5) \\cdot (5)^3 \\\\\n&=\\frac{1}{3} \\cdot (-64) + \\frac{1}{2} \\cdot (1)+\\frac{1}{6} \\cdot (125) \\\\\n&=0\n\\end{align*}\\]Since \\(\\mu = E[X] = 0\\) \\(\\sigma^2 = Var(X) = 10\\), skewness \\(X\\) given \n\\[ \\tilde \\mu_3=\\frac{\\mathbb{E}(X^3)-3\\mu\\sigma^2-\\mu^3}{\\sigma^3}=\\frac{0-0-0}{\\sqrt{1000}}=0 \\]Suppose X symmetric distribution, exists \\(x_0 \\\\mathbb{R}\\) \n\\[ \\mathbb{P}(X=x_0-\\delta)=\\mathbb{P}(X=x_0+\\delta), \\forall \\delta >0 \\]Letting \\(\\delta=x_0-1\\) implies\n\\[\\mathbb{P}(X=1)=\\mathbb{P}(X=2x_0-1)=\\frac{1}{2}, \\forall \\delta >0\\]thus \\(2x_0-1=1\\), .e. \\(x_0=1\\). Letting \\(\\delta=4\\) gives\n\\[ 0=\\mathbb{P}(X=-3)=\\mathbb{P}(X=5)=\\frac{1}{6} (!) \\]","code":""},{"path":"homework.html","id":"problem-8","chapter":"Homework","heading":"Problem 8","text":"","code":""},{"path":"homework.html","id":"question-a-5","chapter":"Homework","heading":"Question a","text":"Show X, Y random variables cov(X, Y ) = 0, X, Y may independent.Let \\(X\\) normal distribution \\(Y\\) \\(X^2\\) \n\\[ Cov(X,Y)=\\mathbb{E}(XY)-E(X)E(Y)=0 \\]However,\n\\[ 0.25=\\mathbb{E}(Y|X=0.5) \\neq E(Y)=Var(X)=1 \\]Hence, X Y inidependent.","code":""},{"path":"homework.html","id":"question-b-5","chapter":"Homework","heading":"Question b","text":"Prove correlation invariant linear transformations.Let , b, c, d constants ac > 0, random variables X, Y, \n\\[\\begin{align*}\nCorr(aX+b,cY+d)&=\\frac{Cov(aX+b,cY++d)}{\\sqrt{Var(aX+b)Var(cY+d)}} \\\\\n&=\\frac{ac \\cdot Cov(X,Y)}{\\sqrt{^2c^2Var(X)Var(Y)}} \\\\\n&=\\frac{Cov(X,Y)}{\\sqrt{Var(X)Var(Y)}} \\\\\n&=Corr(X,Y)\n\\end{align*}\\]","code":""},{"path":"stationary-processes.html","id":"stationary-processes","chapter":"8 Stationary processes","heading":"8 Stationary processes","text":"volatility plays crucial role financial risk management, \nmain measure risk. hands, volatility \nkey factor , e.g., Investment decisions, Portfolio construction\n(Markowitz model) Derivative pricing (Black-Scholes model).Chapter focus estimation forecasting \nvolatility single asset (univariate).volatility plays crucial role financial risk management, \nmain measure risk. hands, volatility \nkey factor , e.g., Investment decisions, Portfolio construction\n(Markowitz model) Derivative pricing (Black-Scholes model).Chapter focus estimation forecasting \nvolatility single asset (univariate).","code":""},{"path":"stationary-processes.html","id":"time-series","chapter":"8 Stationary processes","heading":"8.1 Time series","text":"time series sequence observations chronological order. example: daily log returns stock monthly values Consumer Price Index (CPI).stochastic process sequence random variables can viewed “theoretical” “population” analog time series, conversely, time series can considered sample stochastic process.Denote \\(\\{X_t, t \\\\}\\) time series, time index. example: \\(= \\{1, 2, 3, ...\\}\\) \\(= \\{2000, 2001, 2002...2021\\}\\). Equally spaced time series common practice. case \n\\(= \\{t_1, t_2, ..., t_n\\}\\), \n\\((\\Delta = t_{+1} − t)_i\\) \\(\\Delta\\) constant.","code":""},{"path":"stationary-processes.html","id":"remark-1","chapter":"8 Stationary processes","heading":"8.1.1 Remark","text":"Difference traditional Statistical InferenceIn traditional statistic inference, data assumed ..d\nprocess (random sample).time series, need assumption wish model dependency among observations leads concept autocorrelation.main problems time seriesFormulate estimate parametric model \\(X_t\\) (need propose methods estimation model diagnostics).point related estimation autoregressive (AR) ARMA models.Estimation Missing values (fill“gaps”).Prediction Forecasting (“like know future value ”). example data \\(x_1, x_2, ..., x_{100}\\), wish forecast next 10 values, \\(x_{101}, ..., x_{110}\\). case, forecasting horizon 10.Plotting time series observe fluctuations time series, e.g., find stationarity non-stationarity, cycles, trends, outliers interventions. Assisting formulation parametric model.","code":""},{"path":"stationary-processes.html","id":"example-4","chapter":"8 Stationary processes","heading":"Example","text":"Consider Financial Index SP500. data consists excess returns \\(X_t = \\ln(S_t) −\\ln(S_{t−1})\\). plot see following properties \\(X_t\\):mean level process seems constant.sections data explosive behavior (high volatility).data corresponds non-stationary process (define detailed).variance (volatility) constant time.linear time series model available data.","code":"\nlibrary(tidyverse)\nsp500 = read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vT4WqdVoUIiaMcd4jQj5by3Oauc6G4EFq9VDDrpzG2oBn6TFzyNE1yPV2fKRal5F7DmRzCtVa4nSQIw/pub?gid=279168786&single=true&output=csv\")\n\nsp500$Close %>% \n  log %>% \n  diff %>% \n  plot(type = \"l\",col = \"blue\")"},{"path":"stationary-processes.html","id":"autocovariance","chapter":"8 Stationary processes","heading":"8.2 Autocovariance","text":"","code":""},{"path":"stationary-processes.html","id":"definition-3","chapter":"8 Stationary processes","heading":"8.2.1 Definition","text":"autocovariance function stochastic process \\(X\\) defined \n\\[\\gamma(t,\\tau)=\\mathbb{E}(X_t −\\mu_t)(X_{t−\\tau} −\\mu_{t−\\tau})\\]\n\\(\\tau \\\\mathbb{Z}\\), \\(\\mu_t = E(X_t)\\).autocovariance function symmetric, .e., \\(\\gamma(t,\\tau) = \\gamma(t − \\tau,−\\tau)\\). special case \\(\\tau = 0\\) \\(\\gamma(t, 0) = Var(X_t)\\).general \\(\\gamma(t,\\tau)\\) depend t well \\(\\tau\\).","code":""},{"path":"stationary-processes.html","id":"example-5","chapter":"8 Stationary processes","heading":"Example","text":"Find autocovariance function Brownian motion?\\[\\begin{align*}\n&B_t \\sim \\mathcal{N}(0,t) \\\\\n&\\rightarrow E[B_t^2] =Var(B_t)=t\n\\end{align*}\\]\\[\\begin{align*}\n&B_t-B_{t-\\tau} \\sim \\mathcal{N}(0,t-\\tau) \\\\\n&\\rightarrow E[(B_t-B_{t-\\tau})^2]=Var(B_t-B_{t-\\tau})=t-\\tau\n\\end{align*}\\]\\[\\begin{align*}\n\\gamma(t,\\tau)&=E[(B_t-\\mu_t)(B_{t-\\tau}-\\mu_{t-\\tau})] \\\\\n&=E[B_tB_{t-\\tau}] \\\\\n&=-\\frac{1}{2}E[(B_t-B_{t-\\tau})^2-B_t^2-B_{t-\\tau}^2] \\\\\n&=-\\frac{1}{2}\\{E[(B_t-B_{t-\\tau})^2] -E[B_t^2]-E[B_{t-\\tau}^2]\\} \\\\\n&=-\\frac{1}{2} [(\\tau)-(t)-(t-\\tau)]=t-\\tau\n\\end{align*}\\]Answer: autocovariance function Brownian motion \\(t-\\tau\\).","code":""},{"path":"stationary-processes.html","id":"stationary","chapter":"8 Stationary processes","heading":"8.3 Stationary","text":"","code":""},{"path":"stationary-processes.html","id":"strictly-stationary","chapter":"8 Stationary processes","heading":"8.3.1 Strictly Stationary","text":"process said strictly stationary aspects behavior unchanged shifts time. Mathematically, stationarity defined requirement every \\(m\\) \\(n\\) distribution \n\\((X_1, X_2, ..., X_n)\\) \\((X_{1+m}, X_{2+m}, ..., X_{n+m})\\) .","code":""},{"path":"stationary-processes.html","id":"weakly-stationary","chapter":"8 Stationary processes","heading":"8.3.2 Weakly Stationary","text":"process weakly stationary mean, variance, covariance unchanged time shifts. precisely, \\(X_1, X_2, ...\\) weakly stationary process \\(\\mathbb{E}(X_t)=\\mu, \\forall t\\)\\(Var(X_t) = \\sigma_2\\) (positive finite constant) \\(t\\).\\(Cov(X_t, X_s) = \\gamma(|t − s|), \\forall t, s\\) function \\(\\gamma\\).see , mean variance change time covariance two observations depends lag, time distance \\(|t − s|\\).function \\(\\gamma\\) autocovariance function process symmetric property \\(\\gamma(h) = \\gamma(−h)\\).\\[\\begin{align*}\n\\gamma(h)=cov(X_t,X_{t+h}) \\\\\n\\rightarrow \\gamma(-h)=cov(X_{t},X_{t-h})\n\\end{align*}\\]Let \\(s=t-h\\) \\(t=s+h\\)\n\\[\\gamma(-h)=cov(X_{s+h},X_{s})=\\gamma(h) \\]correlation \\(X_t\\) \\(X_{t+h}\\) denoted \\(\\rho(h)\\). Function \\(\\rho\\) called autocorrelation function (ACF). \\(\\gamma(0) = \\sigma^2\\) , hence\n\\(\\gamma(h) = \\sigma^2 \\rho(h)\\) hence \\(\\rho(h) = \\frac{\\gamma(h)}{\\gamma(0)}\\).ACF normalized \\([−1, 1]\\). Since process required covariance stationary, ACF depends one parameter, lag \\(h\\).","code":""},{"path":"stationary-processes.html","id":"example-6","chapter":"8 Stationary processes","heading":"Example","text":"Consider random walk \\(X: X_t = c + X_{t−1} + \\epsilon_t\\), c constant white noise \\(\\epsilon_t\\). see \\(c \\neq 0\\), \\(Z_t := X_t −X_{t−1} = c+ \\epsilon_t\\) non-zero mean. call random walk drift. Note since \\(\\epsilon_t\\) independent call \\(X_t\\) random walk independent increments. convenience, assume \\(c\\) \\(X_0\\) set zero. \\[\\begin{align*}\n&X_t =\\epsilon_t + \\epsilon_{t−1} +...+\\epsilon_1 \\\\\n\\\\\n&\\mu_t =E(X_t)=0 \\\\\n\\\\\n&Var(X_t) = t\\sigma\n\\end{align*}\\]\\(Var(X_t)\\) stationary rather increases linearly time makes random walk “wander”, .e., \\(X_t\\) takes increasingly longer excursions away conditional mean \\(0\\), therefore mean-reverting.\\(s<t\\) \\[ \\rho(t,s)=\\sqrt{1-\\frac{s}{t}} \\]\\(\\rho\\) depending \\(t\\) well \\(s\\), thus random walk covariance stationary. following figure shows relationship among different processes: Stationary processes largest set, followed white noise, martingale difference (MD), ..d. processes.","code":""},{"path":"stationary-processes.html","id":"estimating-parameters","chapter":"8 Stationary processes","heading":"8.4 Estimating Parameters","text":"Let \\(X_1, X_2, ..., X_n\\) observations weakly stationary process. estimate autocovariance function, use sample autocovariance function defined \\[ \\hat{\\gamma}(h)=\\frac{1}{n} \\sum_{t=1}^{n-h}(X_{t+h}-\\bar X)(X-t-\\bar X) \\]estimate function \\(\\rho\\), use sample autocorrelation function\n(sample ACF) defined \\[\\hat \\rho(h) =\\frac{\\hat \\gamma(h)}{\\hat \\gamma(h)}\\]visualize dependencies \\(x_t\\) different lags h, use Correlogram.correlogram plot \\(h\\) (x-axis) versus corresponding value \\(\\hat \\rho(h)\\) (y-axis).correlogram may exhibit patterns different degrees dependency time series.“band” size \\(\\frac{2}{\\sqrt{n}}\\) added correlogram asymptotically \\(\\hat \\rho(h) \\sim \\mathcal{N} \\left(0, \\frac{1}{n} \\right)\\) data close white noise process.band used detect significant autocorrelations, .e. autocorelations different zero.","code":"\nlibrary(tidyquant)\nmsft = tq_get('MSFT',from=as.Date(\"2010-01-01\"),\n               to=as.Date(\"2014-01-01\"),\n               get = \"stock.prices\")\n\nmsft_logret=msft$adjusted %>% \n  log() %>% \n  diff()\n\nacf(msft_logret,lag.max=10)"},{"path":"stationary-processes.html","id":"the-adf-test","chapter":"8 Stationary processes","heading":"8.5 The ADF Test","text":"ADF Test also called Unit Root Test. test uses following null alternative hypotheses:\\(H_0\\) : time series contains unit root. means time series non-stationary, .e., time-dependent structure constant variance time.\\(H_1\\) : time series stationary.","code":"\nlibrary(tseries)\nadf.test(msft_logret)#> \n#>  Augmented Dickey-Fuller Test\n#> \n#> data:  msft_logret\n#> Dickey-Fuller = -9.7881, Lag order = 10, p-value = 0.01\n#> alternative hypothesis: stationary"},{"path":"stationary-processes.html","id":"kpss-test","chapter":"8 Stationary processes","heading":"8.6 KPSS test","text":"ideas KPSS test comes regression model time\ntrend\\(X_t =c+ \\mu_t+k \\sum_{=1}^{t} \\xi_i +\\eta_t\\)stationary \\(\\eta_t\\) ..d \\(\\xi\\) mean \\(0\\) variance \\(1\\). Note third term random walk. set null hypothesis: data stationary .\\[ H_0 : k = 0 \\\\\nH_1 : k \\neq 0 \\]Test results Microsoft data","code":"\nlibrary(tseries)\nkpss.test(msft_logret)#> \n#>  KPSS Test for Level Stationarity\n#> \n#> data:  msft_logret\n#> KPSS Level = 0.20346, Truncation lag parameter = 7, p-value = 0.1"},{"path":"stationary-processes.html","id":"ljungbox-test","chapter":"8 Stationary processes","heading":"8.7 Ljung–Box Test","text":"Sample ACF test bounds.bounds used test null hypothesis autocorrelation coefficient \\(0\\).null hypothesis rejected sample autocorrelation outside bounds.usual level test \\(0.05\\).","code":""},{"path":"stationary-processes.html","id":"example-7","chapter":"8 Stationary processes","heading":"Example","text":"(First-order Autoregression Model (AR(1))) time series \\(X = (X_t)\\) called AR(1) value X time t linear function value \\(X\\) time \\(t − 1\\) follows\\[X_t=\\delta+\\phi_1 X_{t-1}+w_t=\\delta+\\sum_{h=0}^\\infty \\phi_1^h w_{t-h} \\]errors \\(w_t \\sim \\mathcal{N}(0,\\sigma_w^2)\\) ..d.\\(w_t\\) independent \\(X_t\\).\\(\\phi_1<1\\). condition guarantees \\(X_t\\) weakly stationary.\\[\\begin{align*}\n&\\mu=\\mathbb{E}(X_t)=\\frac{\\delta}{1-\\phi_1} \\\\\n\\\\\n&Var(X_t)=\\frac{\\sigma_w^2}{1-\\phi_1^2} \\\\\n\\\\\n&Cov(X_t,X_{t+h})=\\gamma(h)=\\phi_1^h \\cdot \\frac{\\sigma_w^2}{1-\\phi_1^2} \\\\\n\\\\\n&\\rho(h)=\\phi_1^h\n\\end{align*}\\]Note magnitude ACF decays geometrically zero, either slowly \\(\\phi_1 = 0.95\\), moderately slowly \\(\\phi_1 = 0.75\\), rapidly \\(\\phi_1 = 0.25\\). now simulate AR(1) plot ACF \\(\\phi_1 =0.64\\) \\(\\sigma_w^2 =1\\).null hypothesis Ljung–Box test \n\\[H_0 :\\rho(1)=\\rho(2)=...\\rho(m)=0\\]\nm. Ljung–Box test rejects, conclude one \\(\\rho(1), \\rho(2), ..., \\rho(m)\\) nonzero. Ljung–Box test sometimes called simply Box test.\n\\[Q(m)=n(n+2) \\sum_{=j}^m \\frac{\\hat p^2 (j)}{n-j} \\sim \\chi^2(m)\\]","code":"\nlibrary(stats)\nts.sim = arima.sim(list(order = c(1,0,0), ar = 0.64), n = 100,sd=1)\nplot(ts.sim,col=\"blue\")\nacf(ts.sim)"},{"path":"stationary-processes.html","id":"example-8","chapter":"8 Stationary processes","heading":"Example","text":"Consider AR(1) \\(\\phi_1 = 0.64\\) \\(\\sigma_w^2 = 1\\), results Box test RIf \\(|\\phi_1| \\geq 1\\) AR(1) process nonstationary, mean, variance, covariances correlations constant.","code":"\nlibrary(stats)\nts.sim = arima.sim(list(order = c(1,0,0), ar = 0.64), n = 100,sd=1)\nplot(ts.sim,col=\"blue\")\nBox.test(ts.sim, lag = 10, type = \"Ljung-Box\")#> \n#>  Box-Ljung test\n#> \n#> data:  ts.sim\n#> X-squared = 75.684, df = 10, p-value = 3.5e-12"},{"path":"stationary-processes.html","id":"pacf","chapter":"8 Stationary processes","heading":"8.8 PACF","text":"partial correlation conditional correlation. correlation two variables assumption know take account values set variables.","code":""},{"path":"stationary-processes.html","id":"example-9","chapter":"8 Stationary processes","heading":"Example","text":"Consider regression model \\(y\\) response variable, \\(x_1, x_2, x_3\\) predictor variables. partial correlation y \\(x_3\\) correlation variables determined taking account \\(y\\) \\(x_3\\) related \\(x_1\\) \\(x_2\\).regression, partial correlation found correlating residuals two different regressions:Regression predict \\(y\\) \\(x_1\\) \\(x_2\\).Regression predict \\(x_3\\) \\(x_1\\) \\(x_2\\).correlate “parts” \\(y\\) \\(x_3\\) predicted \\(x_1\\) \\(x_2\\). can define partial correlation just described \n\\[\\frac{Cov(y, x_3 | x_1, x_2)}{\\sqrt{Var(y | x_1, x_2)Var(x_3 | x_1, x_2)}}\\]time series, partial autocorrelation \\(x_t\\) \\(x_{t−h}\\) defined conditional correlation \\(x_t\\) \\(x_{t−h}\\) conditional \\(x_{t−h+1}, ..., x_{t−1}\\), set observations come time points \\(t\\) \\(t − h\\).\\[\\frac{Cov(y, x_3 | x_1, x_2)}{\\sqrt{Var(y | x_1, x_2)Var(x_3 | x_1, x_2)}}\\]","code":""},{"path":"stationary-processes.html","id":"example-10","chapter":"8 Stationary processes","heading":"Example","text":"3rd order (lag) partial autocorrelation :\\[\\frac{Cov(x_t, x_{t-3} | x_{t-1}, x_{t-2})}{\\sqrt{Var(x_t | x_t, x_{t-3})Var(x_{t-3} | x_t, x_{t-3})}}\\]","code":""},{"path":"ewma.html","id":"ewma","chapter":"9 EWMA","heading":"9 EWMA","text":"Denote \\(y_t\\) return stock time \\(t\\). ThenVolatility weighted sum past returns, weights \\(\\omega_i\\), \ndefined \n\\[ \\hat \\sigma_t^2=\\omega_1y_{t-1}^2+\\omega_2y_{t-2}^2+...+\\omega_Ly_{t-L}^2 \\]\nL length estimation window, .e., number observations used calculation. called MA model.extension MA model Exponentially weighted moving average. Let weights exponentially declining, denote \\(\\lambda^\\)\n\\[ \\hat \\sigma_t^2=\\lambda y_{t-1}^2+\\lambda^2 y_{t-2}^2+...+\\lambda^L y_{t-L}^2 \\]\n\\(0 < \\lambda < 1\\). \\(L\\) large enough, term αn negligible \\(n > L\\). set \\(L = \\infty\\).Note sum weights \n\\[\\frac{\\lambda}{1-\\lambda}=\\sum_{=1}^\\infty \\lambda^\\]\nexponentially weighted moving average defined \n\\[ \\hat \\sigma_t^2=\\frac{1-\\lambda}{\\lambda} \\sum_{=1}^{\\infty}\\lambda^y_{t-}^2 \\]\n, hence, get EWMA equation (???)\n\\[ \\hat \\sigma_t^2=\\lambda \\hat \\sigma_{t-1}^2+(1-\\lambda)y_{t-1}^2 \\]Note JP Morgan set daily data \\(\\lambda = 0.94\\).","code":""},{"path":"ewma.html","id":"example-11","chapter":"9 EWMA","heading":"Example","text":"Suppose \\(\\lambda = 0.9\\), volatility estimated market variable \nday \\(n − 1\\) \\(1\\%\\) per day, day \\(n − 1\\) market variable\nincreased \\(2\\%\\). means \\(\\sigma_{n-1}^2=0.01^2=0.0001\\) \\(y_{n-1}^2=0.02^2=0.0004\\). equation (1) get\n\\[\\sigma_n^2=0.9 \\cdot 0.0001 + 0.1 \\cdot 0.0004=0.00013 \\]\nestimate volatility day \\(n\\) \\(\\sigma_n = \\sqrt{0.00013} = 1.4\\%\\) per\nday. Note expected value \\(y_{n-1}^2\\) \\(\\sigma_{n-1}^2= 0.0001\\). Hence, realized value \\(y_{n−1}^2 = 0.0002\\) greater expected value, \nresult volatility estimate increase. realized value \\(y_{n−1}^2\\) less expected valued, estimate volatility decreased.","code":""},{"path":"arch-and-garch.html","id":"arch-and-garch","chapter":"10 ARCH and GARCH","heading":"10 ARCH and GARCH","text":"","code":""},{"path":"arch-and-garch.html","id":"arch","chapter":"10 ARCH and GARCH","heading":"10.1 ARCH","text":"ARCH model proposed Robert Engle 1982 called autoregressive conditionally heteroscadastic.volatility models derive .Returns assumed conditional distribution (\nassumed normal)\n\\[y_t \\sim \\mathcal{N} (0,\\sigma_t^2)\\]\ncan write\n\\[y_t=\\sigma_t \\epsilon_t \\]\n\\(\\epsilon_t \\sim \\mathcal{N}(0, 1)\\) called residual.ARCH(L1) defined \n\\[Var(y_t | y_{t−1}, y_{t−2}, ..., y_{t−L_1} ) = \\sigma_t^2 = \\omega + \\sum_{=1}^{L_1} \\alpha_i y_{t−}^2\\]\n\\(L_1\\) called lag model. seen ARCH model, volatility weighted average past returns.common form ARCH (1)\n\\[Var(y_t | y_{t−1}) = \\sigma_t^2 = \\omega + \\alpha y_{t−1}^2\\]\n\\(\\omega\\) \\(\\alpha\\) parameters can estimated maximum likelihood.assume series \\(mean = 0\\) (can always done centering), ARCH model written \n\\[\\begin{align*}\n&y_t = \\sigma_t \\epsilon_t \\\\\n&\\sigma_t=\\sqrt{\\omega+\\alpha y_{t-1}^2} \\\\\n&\\epsilon_t \\sim \\mathcal{N}(0,1),..d\n\\end{align*}\\]require \\(\\omega,\\alpha>0\\) \\(\\omega+\\alpha y_{t-1}^2>0, \\forall t\\). also require \\(\\alpha < 1\\) order process stationary finite variance. Now \n\\[y_t^2 =\\epsilon_t^2(\\omega+\\alpha y_{t−1}^2)\\]\nsimilar AR(1) variable \\(y_t^2\\) multiplicative noise mean \\(1\\) rather additive noise mean \\(0\\).","code":""},{"path":"arch-and-garch.html","id":"garch","chapter":"10 ARCH and GARCH","heading":"10.2 GARCH","text":"turns ARCH model good model almost nobody uses . , needs use information many days t calculate volatility day t. , needs lot lags.\\(GARCH(L_1, L_2)\\) model defines \n\\[ \\sigma_t^2=\\omega+\\sum_{=1}^{L_1} \\alpha_i y_{t-}^2 + \\sum_{=1}^{L_2} \\beta_i \\sigma_{t-}^2 \\]\n, hence, \\(GARCH(1,1)\\)\n\\[ \\sigma_t^2=\\omega+\\alpha y_{t-1}^2+\\beta \\sigma_{t-1}^2 \\]\\(GARCH(1,1)\\) common specification.","code":""},{"path":"arch-and-garch.html","id":"unconditional-volatility","chapter":"10 ARCH and GARCH","heading":"10.2.1 Unconditional volatility","text":"unconditional volatility (-called long-run variance rate) unconditional expectation volatility given time\n\\[\\sigma^2=\\mathbb{E}(\\sigma_t^2) \\]\n\n\\[ \\sigma^2=\\mathbb{E}(\\omega+\\alpha y_{t-1}^2+\\beta \\sigma_{t-1}^2)=\\omega +\\alpha \\sigma^2+\\beta \\sigma^2 \\]\nHence,\n\\[ \\sigma^2=\\frac{\\omega}{1-\\alpha-\\beta} \\]ensure positive volatility forecasts need condition \\(\\omega, \\alpha, \\beta \\geq 0\\)\nparameter negative \\(\\sigma_{t+1}\\) may negative.stationary need condition \\(\\alpha+\\beta<1\\)\nSetting \\(\\gamma := 1 − \\alpha − \\beta\\) \\(V := \\sigma^2\\) (called long-run variance rate). \n\\[ \\sigma_t^2=\\gamma V+\\alpha y_{t-1}^2+\\beta \\sigma_{t-1}^2 \\]","code":""},{"path":"arch-and-garch.html","id":"meaning-of-parameters","chapter":"10 ARCH and GARCH","heading":"10.2.2 Meaning of Parameters","text":"parameter \\(\\alpha\\) news, shows volatility reacts new information.parameter \\(\\beta\\) memory, shows much volatility remembers past.sum \\(\\alpha + \\beta\\) determines quickly predictability (memory) process dies :\n\n\\(\\alpha + \\beta \\approx 0\\) predictability die quickly.\n\n\n\\(\\alpha + \\beta \\approx 1\\) predictability die slowly.\n\n\n\\(\\alpha + \\beta \\approx 0\\) predictability die quickly.\n\n\\(\\alpha + \\beta \\approx 1\\) predictability die slowly.\n","code":""},{"path":"arch-and-garch.html","id":"example-12","chapter":"10 ARCH and GARCH","heading":"Example","text":"Suppose \\(GARCH(1,1)\\) model estimated daily data \n\\[\\sigma_n =0.000002+0.13y_{n-1}^2 +0.86 \\sigma_{n-1}^2\\]\ncorresponds \\(\\omega = 0.000002, \\alpha = 0.13, \\beta = 0.86\\). \n\\[\\sigma^2 = \\frac{\\omega}{1-\\alpha-\\beta}= 0.0002\\]\n\\(\\sigma=\\sqrt{0.0002}=0.014=1.4\\%\\) per day.Suppose estimate volatility day \\(n − 1\\) \\(1.6\\%\\) per day\n\\(\\sigma^2 = 0.0162 = 0.000256\\), day \\(n − 1\\) market\nvariable decreased \\(1\\%\\) \\(y_{n−1}^2 = 0.01^2 = 0.0001\\). \n\\[\\sigma_n^2 = 0.000002 + 0.13 × 0.0001 + 0.86 × 0.000256 = 0.00023516\\]\nnew estimate volatility : \\(\\sqrt{0.00023516} = 0.0153\\) \\(1.53\\%\\) per day.","code":""},{"path":"maximum-likelihood.html","id":"maximum-likelihood","chapter":"11 Maximum likelihood","heading":"11 Maximum likelihood","text":"Maximum likelihood important widespread method estimation. maximum likelihood?Ask question parameters likely generated data . Suppose sample \\(\\{−0.2, 3, 4, −1, 0.5\\}\\). following three possibilities, likely parameters?Let \\(Y = (y_1,y_2,...,y_n)\\) vector data let \\(\\theta = (\\theta_1,\\theta_2,...,\\theta_p)\\) vector parameters. Let \\(f(Y | \\theta)\\) density Y depends parameters. function\n\\[L(\\theta) := f(Y | \\theta)\\]\nviewed function \\(\\theta\\) \\(Y\\) fixed observed data called\nlikelihood function.maximum likelihood estimator (MLE) value \\(\\theta\\) maximizes likelihood function. denote MLE \\(\\hat \\theta_{ML}\\).mathematically easier maximize \\(\\ln L(\\theta)\\), called log-likelihood. data independent, likelihood product marginal densities.","code":""},{"path":"maximum-likelihood.html","id":"application-to-arch1","chapter":"11 Maximum likelihood","heading":"11.1 Application to ARCH(1)","text":"Consider ARCH(1) model:\\[\\epsilon_t ∼ N(0,1)\\]\\(t = 2\\) density??\\[ f(y_2|y_1)=\\frac{1}{\\sqrt{2\\pi(\\omega+\\alpha y_1^2)}} e^{-\\frac{1}{2} \\frac{y_2^2}{2\\omega+\\alpha y_1^2}} \\]\nHence, joint density\n\\[ \\prod_{t=2}^T f(y_t|y_{t-1})=\\prod_{t=2}^T \\frac{1}{\\sqrt{2\\pi(\\omega+\\alpha y_{t-1}^2)}} e^{-\\frac{1}{2} \\frac{y_t^2}{2\\omega+\\alpha y_{t-1}^2}} \\]\n, log likelihood\n\\[ \\ln(L(\\omega, \\alpha)) =-\\frac{T-1}{2} \\ln(2\\pi)-\\frac{1}{2} \\sum_{t=2}^T \\left( \\ln(\\omega+\\alpha y_{t-1}^2) + \\frac{y_t^2}{\\omega+\\alpha y_{t-1}^2} \\right) \\]","code":""},{"path":"maximum-likelihood.html","id":"application-to-garch11","chapter":"11 Maximum likelihood","heading":"11.2 Application to GARCH(1,1)","text":"\\[ \\sigma_t^2=\\omega+\\alpha y_{t-1}^2 +\\beta \\sigma_{t-1}^2\\]\nHence, joint density\n\\[ f(y_2|y_1)=\\frac{1}{\\sqrt{2\\pi(\\omega+\\alpha y_1^2+\\beta \\hat \\sigma_1^2)}} e^{-\\frac{1}{2} \\frac{y_2^2}{\\omega +\\alpha y_1^2+\\beta \\hat \\sigma_1^2}} \\]\n, log likelihood\n\\[ \\ln(L(\\omega, \\alpha)) =-\\frac{T-1}{2} \\ln(2\\pi)-\\frac{1}{2} \\sum_{t=2}^T \\left( \\ln(\\omega+\\alpha y_{t-1}^2+\\beta \\hat \\sigma_{t-1}^2) + \\frac{y_t^2}{\\omega+\\alpha y_{t-1}^2+\\beta \\hat \\sigma_{t-1}^2} \\right) \\]","code":""},{"path":"maximum-likelihood.html","id":"the-importance-of-σ1","chapter":"11 Maximum likelihood","heading":"11.2.1 The importance of σ1","text":"\\(\\sigma_1\\) can make large difference.Especially sample size small.Typically set \\(\\sigma_1 = \\hat \\sigma\\).","code":""},{"path":"maximum-likelihood.html","id":"volatility-targeting","chapter":"11 Maximum likelihood","heading":"Volatility targeting","text":"Since long-run variance rate\n\\[\\sigma^2= \\frac{\\omega}{1-\\alpha-\\beta}\\].can set\n\\[ \\omega=\\hat \\sigma^2(1-\\alpha-\\beta) \\]\n\\(\\hat \\sigma^2\\) sample variance.Hence save one parameter estimation.","code":""},{"path":"future-volatility.html","id":"future-volatility","chapter":"12 Future volatility","heading":"12 Future volatility","text":"variance rate estimated end day \\(n − 1\\) \\(n\\) day apply \\(GARCH(1,1)\\) model \\[ \\sigma_n^2=\\omega+\\alpha y_{n-1}^2+\\beta \\sigma_{n-1}^2=\\sigma^2(1-\\alpha-\\beta)+\\alpha y_{n-1}^2+\\beta \\sigma_{n-1}^2 \\]\n\n\\[ \\sigma_n^2- \\sigma^2=\\alpha (y_{n-1}^2-\\sigma^2)+\\beta (\\sigma_{n-1}^2-\\sigma^2) \\]\nday \\(n+t\\) future \n\\[ \\sigma_{n+t}^2 - \\sigma^2=\\alpha (y_{n+t-1}^2-\\sigma^2)+\\beta(\\sigma_{n+t-1}^2-\\sigma^2) \\]\nHence,\n\\[ \\mathbb{E}[\\sigma_{n+t}^2 - \\sigma^2]=(\\alpha+\\beta)\\mathbb{E}[\\sigma_{n+t-1}^2 - \\sigma^2] \\]\ninduction obtain\n\\[ \\mathbb{E}(\\sigma_{n+t}^2) = \\sigma^2 + (\\alpha + \\beta)^t(\\sigma_n^2 − \\sigma^2) \\]","code":""},{"path":"future-volatility.html","id":"example-13","chapter":"12 Future volatility","heading":"Example","text":"S&P data consider earlier, \\(\\alpha + \\beta = 0.9935\\), log-run variance rate \\(\\sigma^2 = 0.0002075\\) (\\(\\sigma = 1.44\\%\\) per day). Suppose estimate current variance rate per day \\(0.0003\\) (corresponds volatility \\(1.732\\%\\) per day). \\(t = 10\\) days, calculate expected variance rate??\\(\\sigma_n^2 = 0.0003\\), hence\n\\[\\begin{align*}\n\\mathbb{E}(\\sigma_{n+10}^2 ) = 0.0002075 + 0.993510^{10} × (0.0003 − 0.0002075) = 0.0002942\n\\end{align*}\\]\nexpected volatility per day \\(\\sqrt{0.0002942} = 1.72\\%\\), still long-term volatility \\(1.44\\%\\) per day.","code":""},{"path":"future-volatility.html","id":"volatility-term-structures","chapter":"12 Future volatility","heading":"Volatility term structures","text":"Suppose day \\(n\\). define\n\\[V(t) = \\mathbb{E}(\\sigma_{n+1}^2 )\\]\n\n\\[ := \\ln \\left( \\frac{1}{\\alpha+\\beta} \\right) \\]\n\\(\\mathbb{E}(\\sigma_{n+t}^2) = \\sigma^22 + (\\alpha + \\beta)^t(\\sigma_n^2 − \\sigma^2)\\) \\[V(t) = \\sigma^2 + e^{−}(V(0) − \\sigma^2)\\]\naverage variance rate per day today time T.\\[ \\frac{1}{T} \\int_0^T V(t) \\,dt=\\frac{1}{T} \\int_0^T \\left( \\sigma^2 + e^{−}(V(0) − \\sigma^2) \\right)=\\sigma^2+\\frac{1-e^{-}}{} [V(0)-\\sigma^2] \\]Now define \\(sigma(T)\\) volatility per annum used price T-day option \\(GARCH(1,1)\\) model. \\[ \\sigma^2(T)=252 \\left( \\sigma^2+\\frac{1-e^{-}}{} [V(0)-\\sigma^2] \\right) \\]\nrelationship volatility options maturities referred volatility term structure.","code":""},{"path":"future-volatility.html","id":"example-14","chapter":"12 Future volatility","heading":"Example","text":"S&P data, using GARCH(1,1) model obtain coefficients \\(\\omega = 0.0000013465\\), \\(\\alpha = 0.083394\\) \\(\\beta = b = 0.910116\\). \n\\[ \\sigma^2(T)=252 \\left( \\sigma^2+\\frac{1-e^{-}}{} [V(0)-\\sigma^2] \\right) \\]\nassume \\(V(0) = 0.0003\\) \n\\[ \\sigma^2=\\frac{0.0000013465}{1 − 0.083394 − 0.910116}=0.0002073 \\]\n\\(= \\ln \\left( \\frac{1}{0.99351} \\right) = 0.00651\\). Hence,\n\\[ \\sigma^2(T)=252 \\left( 0.0002073+\\frac{1-e^{-0.00651 \\cdot T}}{0.00651 \\cdot T}[0.0003-0.0002073] \\right) \\]option life (days) T = 10, 30, 50, 100, 500, obtain option\nvolatility (\\(\\%\\) per annum)","code":""},{"path":"in-class-exercise-1.html","id":"in-class-exercise-1","chapter":"13 In-class exercise","heading":"13 In-class exercise","text":"","code":""},{"path":"in-class-exercise-1.html","id":"autocovariance-1","chapter":"13 In-class exercise","heading":"13.1 Autocovariance","text":"Find autocovariance function Brownian motion?\\[\\begin{align*}\n&B_t \\sim \\mathcal{N}(0,t) \\\\\n&\\rightarrow E[B_t^2] =Var(B_t)=t\n\\end{align*}\\]\\[\\begin{align*}\n&B_t-B_{t-\\tau} \\sim \\mathcal{N}(0,t-\\tau) \\\\\n&\\rightarrow E[(B_t-B_{t-\\tau})^2]=Var(B_t-B_{t-\\tau})=t-\\tau\n\\end{align*}\\]\\[\\begin{align*}\n\\gamma(t,\\tau)&=E[(B_t-\\mu_t)(B_{t-\\tau}-\\mu_{t-\\tau})] \\\\\n&=E[B_tB_{t-\\tau}] \\\\\n&=-\\frac{1}{2}E[(B_t-B_{t-\\tau})^2-B_t^2-B_{t-\\tau}^2] \\\\\n&=-\\frac{1}{2}\\{E[(B_t-B_{t-\\tau})^2] -E[B_t^2]-E[B_{t-\\tau}^2]\\} \\\\\n&=-\\frac{1}{2} [(\\tau)-(t)-(t-\\tau)]=t-\\tau\n\\end{align*}\\]Answer: autocovariance function Brownian motion \\(t-\\tau\\)Let \\(cov (X_t,X_{t+h})=\\gamma(h)\\)","code":""},{"path":"in-class-exercise-1.html","id":"question-a-6","chapter":"13 In-class exercise","heading":"13.1.1 Question a","text":"Prove \\(\\gamma(h)=\\gamma(-h)\\)\\[\\begin{align*}\n\\gamma(h)=cov(X_t,X_{t+h}) \\\\\n\\rightarrow \\gamma(-h)=cov(X_{t},X_{t-h})\n\\end{align*}\\]Let \\(s=t-h\\) \\(t=s+h\\)\n\\[\\gamma(-h)=cov(X_{s+h},X_{s})=\\gamma(h) \\]","code":""},{"path":"in-class-exercise-1.html","id":"question-b-6","chapter":"13 In-class exercise","heading":"13.1.2 Question b","text":"Prove \\(-1 \\leq \\rho(h) \\le1\\)\\[\\begin{align*}\n&\\mathbb{E}[(X_{t+h} \\pm X_{t})^2] \\ge 0 \\\\\n&\\rightarrow \\mathbb{E}[X_{t+h}^2] + \\mathbb{E}[X_{t}^2] \\pm 2 \\mathbb{E}[X_{t+h}X_{t}] \\ge 0 \\\\\n&\\rightarrow 2 \\gamma(0) \\pm 2\\gamma(h) \\ge 0 \\\\\n&\\rightarrow -2 \\gamma(0) \\leq 2\\gamma(h) \\leq 2 \\gamma(0) \\\\\n&\\rightarrow -1 \\leq \\rho(h) \\leq 1\n\\end{align*}\\]","code":""},{"path":"in-class-exercise-1.html","id":"adf-test","chapter":"13 In-class exercise","heading":"13.2 ADF test","text":"","code":""},{"path":"in-class-exercise-1.html","id":"python-4","chapter":"13 In-class exercise","heading":"Python","text":"","code":"import pandas_datareader as web\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprice = web.get_data_yahoo(\"^gspc\",\nstart = \"2009-01-01\",\nend = \"2021-12-31\")\n\n# Log-data\nx=np.log(price['Adj Close'])\nplt.plot(x,color=\"black\")\nplt.show()\n\n# First difference of log-datay=np.diff(np.log(price['Adj Close']))\nplt.plot(y,color=\"black\")\nplt.show()from statsmodels.tsa.stattools import adfuller\nresult=adfuller(x)\nprint('ADF Statistic: %f' % result[0])#> ADF Statistic: -0.541575print('p-value: %f' % result[1])#> p-value: 0.883645result=adfuller(y)\nprint('ADF Statistic: %f' % result[0])#> ADF Statistic: -12.311760print('p-value: %f' % result[1])#> p-value: 0.000000"},{"path":"in-class-exercise-1.html","id":"r-4","chapter":"13 In-class exercise","heading":"R","text":"","code":"\nlibrary(tseries)\nlibrary(zoo)\nprice = get.hist.quote(instrument = \"^gspc\",start = \"2009-01-01\",\n                       end = (\"2021-12-31\"),  quote = \"AdjClose\")#> time series starts 2009-01-02\n#> time series ends   2021-12-30\nx=coredata(log(price))\ny=coredata(diff(log(price)))\n# Log-data\nts.plot(x,xlab=\"time\",ylab=\"returns\")\n# First difference of log-data\nts.plot(y,xlab=\"time\",ylab=\"returns\")\nlibrary(aTSA)\nadf.test(x)#> Augmented Dickey-Fuller Test \n#> alternative: stationary \n#>  \n#> Type 1: no drift no trend \n#>       lag  ADF p.value\n#>  [1,]   0 2.47    0.99\n#>  [2,]   1 2.87    0.99\n#>  [3,]   2 2.66    0.99\n#>  [4,]   3 2.73    0.99\n#>  [5,]   4 2.81    0.99\n#>  [6,]   5 2.83    0.99\n#>  [7,]   6 3.09    0.99\n#>  [8,]   7 2.84    0.99\n#>  [9,]   8 3.06    0.99\n#> Type 2: with drift no trend \n#>       lag    ADF p.value\n#>  [1,]   0 -0.367   0.910\n#>  [2,]   1 -0.216   0.930\n#>  [3,]   2 -0.275   0.922\n#>  [4,]   3 -0.346   0.913\n#>  [5,]   4 -0.317   0.917\n#>  [6,]   5 -0.374   0.909\n#>  [7,]   6 -0.369   0.910\n#>  [8,]   7 -0.461   0.893\n#>  [9,]   8 -0.494   0.881\n#> Type 3: with drift and trend \n#>       lag   ADF p.value\n#>  [1,]   0 -4.15  0.0100\n#>  [2,]   1 -3.53  0.0391\n#>  [3,]   2 -3.82  0.0174\n#>  [4,]   3 -3.81  0.0180\n#>  [5,]   4 -3.69  0.0241\n#>  [6,]   5 -3.72  0.0223\n#>  [7,]   6 -3.45  0.0471\n#>  [8,]   7 -3.82  0.0177\n#>  [9,]   8 -3.63  0.0293\n#> ---- \n#> Note: in fact, p.value = 0.01 means p.value <= 0.01\nadf.test(y)#> Augmented Dickey-Fuller Test \n#> alternative: stationary \n#>  \n#> Type 1: no drift no trend \n#>       lag   ADF p.value\n#>  [1,]   0 -65.9    0.01\n#>  [2,]   1 -40.3    0.01\n#>  [3,]   2 -33.1    0.01\n#>  [4,]   3 -29.5    0.01\n#>  [5,]   4 -26.1    0.01\n#>  [6,]   5 -25.6    0.01\n#>  [7,]   6 -21.3    0.01\n#>  [8,]   7 -21.2    0.01\n#>  [9,]   8 -19.2    0.01\n#> Type 2: with drift no trend \n#>       lag   ADF p.value\n#>  [1,]   0 -66.1    0.01\n#>  [2,]   1 -40.4    0.01\n#>  [3,]   2 -33.3    0.01\n#>  [4,]   3 -29.6    0.01\n#>  [5,]   4 -26.3    0.01\n#>  [6,]   5 -25.8    0.01\n#>  [7,]   6 -21.5    0.01\n#>  [8,]   7 -21.5    0.01\n#>  [9,]   8 -19.4    0.01\n#> Type 3: with drift and trend \n#>       lag   ADF p.value\n#>  [1,]   0 -66.1    0.01\n#>  [2,]   1 -40.4    0.01\n#>  [3,]   2 -33.3    0.01\n#>  [4,]   3 -29.6    0.01\n#>  [5,]   4 -26.3    0.01\n#>  [6,]   5 -25.8    0.01\n#>  [7,]   6 -21.5    0.01\n#>  [8,]   7 -21.5    0.01\n#>  [9,]   8 -19.4    0.01\n#> ---- \n#> Note: in fact, p.value = 0.01 means p.value <= 0.01"},{"path":"in-class-exercise-1.html","id":"kpss-test-1","chapter":"13 In-class exercise","heading":"13.3 KPSS test","text":"","code":""},{"path":"in-class-exercise-1.html","id":"python-5","chapter":"13 In-class exercise","heading":"Python","text":"","code":"import statsmodels.api as sm\n#perform KPSS test\nresult=sm.tsa.stattools.kpss(x)#> /Users/cliex159/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:2018: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n#> look-up table. The actual p-value is smaller than the p-value returned.\n#> \n#>   warnings.warn(print('KPSS Statistic: %f' % result[0])#> KPSS Statistic: 8.352647print('p-value: %f' % result[1])#> p-value: 0.010000result=sm.tsa.stattools.kpss(y)#> /Users/cliex159/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:2022: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n#> look-up table. The actual p-value is greater than the p-value returned.\n#> \n#>   warnings.warn(print('KPSS Statistic: %f' % result[0])#> KPSS Statistic: 0.036716print('p-value: %f' % result[1])#> p-value: 0.100000"},{"path":"in-class-exercise-1.html","id":"r-5","chapter":"13 In-class exercise","heading":"R","text":"","code":"\nlibrary(tseries)\nkpss.test(x)#> KPSS Unit Root Test \n#> alternative: nonstationary \n#>  \n#> Type 1: no drift no trend \n#>  lag   stat p.value\n#>   13 0.0259     0.1\n#> ----- \n#>  Type 2: with drift no trend \n#>  lag   stat p.value\n#>   13 0.0781     0.1\n#> ----- \n#>  Type 1: with drift and trend \n#>  lag  stat p.value\n#>   13 0.112     0.1\n#> ----------- \n#> Note: p.value = 0.01 means p.value <= 0.01 \n#>     : p.value = 0.10 means p.value >= 0.10\nkpss.test(y)#> KPSS Unit Root Test \n#> alternative: nonstationary \n#>  \n#> Type 1: no drift no trend \n#>  lag stat p.value\n#>   13 2.16  0.0239\n#> ----- \n#>  Type 2: with drift no trend \n#>  lag   stat p.value\n#>   13 0.0371     0.1\n#> ----- \n#>  Type 1: with drift and trend \n#>  lag   stat p.value\n#>   13 0.0283     0.1\n#> ----------- \n#> Note: p.value = 0.01 means p.value <= 0.01 \n#>     : p.value = 0.10 means p.value >= 0.10"},{"path":"in-class-exercise-1.html","id":"fit-arima","chapter":"13 In-class exercise","heading":"13.4 Fit ARIMA","text":"","code":""},{"path":"in-class-exercise-1.html","id":"python-6","chapter":"13 In-class exercise","heading":"Python","text":"","code":"from statsmodels.tsa.arima.model import ARIMA\nmodel = ARIMA(x, order=(1,0,0))#> /Users/cliex159/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n#>   self._init_dates(dates, freq)\n#> /Users/cliex159/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n#>   self._init_dates(dates, freq)\n#> /Users/cliex159/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n#>   self._init_dates(dates, freq)model_fit = model.fit()\nprint(model_fit.summary())#>                                SARIMAX Results                                \n#> ==============================================================================\n#> Dep. Variable:              Adj Close   No. Observations:                 3274\n#> Model:                 ARIMA(1, 0, 0)   Log Likelihood                9977.250\n#> Date:                Wed, 16 Mar 2022   AIC                         -19948.500\n#> Time:                        22:19:50   BIC                         -19930.218\n#> Sample:                             0   HQIC                        -19941.953\n#>                                - 3274                                         \n#> Covariance Type:                  opg                                         \n#> ==============================================================================\n#>                  coef    std err          z      P>|z|      [0.025      0.975]\n#> ------------------------------------------------------------------------------\n#> const          7.5866      0.498     15.229      0.000       6.610       8.563\n#> ar.L1          0.9998      0.000   2474.239      0.000       0.999       1.001\n#> sigma2         0.0001   1.21e-06    108.789      0.000       0.000       0.000\n#> ===================================================================================\n#> Ljung-Box (L1) (Q):                  68.56   Jarque-Bera (JB):             23678.78\n#> Prob(Q):                              0.00   Prob(JB):                         0.00\n#> Heteroskedasticity (H):               1.01   Skew:                            -0.68\n#> Prob(H) (two-sided):                  0.86   Kurtosis:                        16.10\n#> ===================================================================================\n#> \n#> Warnings:\n#> [1] Covariance matrix calculated using the outer product of gradients (complex-step).model = ARIMA(y, order=(1,0,0))\nmodel_fit = model.fit()\nprint(model_fit.summary())#>                                SARIMAX Results                                \n#> ==============================================================================\n#> Dep. Variable:                      y   No. Observations:                 3273\n#> Model:                 ARIMA(1, 0, 0)   Log Likelihood               10015.913\n#> Date:                Wed, 16 Mar 2022   AIC                         -20025.825\n#> Time:                        22:19:50   BIC                         -20007.545\n#> Sample:                             0   HQIC                        -20019.279\n#>                                - 3273                                         \n#> Covariance Type:                  opg                                         \n#> ==============================================================================\n#>                  coef    std err          z      P>|z|      [0.025      0.975]\n#> ------------------------------------------------------------------------------\n#> const          0.0005      0.000      2.773      0.006       0.000       0.001\n#> ar.L1         -0.1437      0.007    -19.320      0.000      -0.158      -0.129\n#> sigma2         0.0001   1.32e-06     97.279      0.000       0.000       0.000\n#> ===================================================================================\n#> Ljung-Box (L1) (Q):                   0.31   Jarque-Bera (JB):             18498.33\n#> Prob(Q):                              0.58   Prob(JB):                         0.00\n#> Heteroskedasticity (H):               0.97   Skew:                            -0.83\n#> Prob(H) (two-sided):                  0.57   Kurtosis:                        14.53\n#> ===================================================================================\n#> \n#> Warnings:\n#> [1] Covariance matrix calculated using the outer product of gradients (complex-step)."},{"path":"in-class-exercise-1.html","id":"r-6","chapter":"13 In-class exercise","heading":"R","text":"","code":"\nfitAR1=arima(x, order = c(1,0,0))\nprint(fitAR1)#> \n#> Call:\n#> arima(x = x, order = c(1, 0, 0))\n#> \n#> Coefficients:\n#>          ar1  intercept\n#>       0.9998     7.5866\n#> s.e.  0.0002     0.5485\n#> \n#> sigma^2 estimated as 0.0001315:  log likelihood = 9973.97,  aic = -19941.94\nfitAR2=arima(y, order = c(1,0,0))\nprint(fitAR2)#> \n#> Call:\n#> arima(x = y, order = c(1, 0, 0))\n#> \n#> Coefficients:\n#>           ar1  intercept\n#>       -0.1437      5e-04\n#> s.e.   0.0173      2e-04\n#> \n#> sigma^2 estimated as 0.0001285:  log likelihood = 10012.31,  aic = -20018.63"},{"path":"in-class-exercise-1.html","id":"what-happens-with-price","chapter":"13 In-class exercise","heading":"13.5 What happens with price","text":"","code":""},{"path":"in-class-exercise-1.html","id":"python-7","chapter":"13 In-class exercise","heading":"Python","text":"","code":"from statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.stattools import adfuller\nimport statsmodels.api as sm\n#what happens if we fit AR for price, not that price is non-stationary\nfitAR=ARIMA(price['Adj Close'], order=(1,0,0))#> /Users/cliex159/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n#>   self._init_dates(dates, freq)\n#> /Users/cliex159/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n#>   self._init_dates(dates, freq)\n#> /Users/cliex159/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n#>   self._init_dates(dates, freq)print(fitAR)#> <statsmodels.tsa.arima.model.ARIMA object at 0x7fa897f964c0>result=adfuller(price['Adj Close'])\nprint('ADF Statistic: %f' % result[0])#> ADF Statistic: 1.855653print('p-value: %f' % result[1])#> p-value: 0.998453result=sm.tsa.stattools.kpss(price['Adj Close'])#> /Users/cliex159/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:2018: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n#> look-up table. The actual p-value is smaller than the p-value returned.\n#> \n#>   warnings.warn(print('KPSS Statistic: %f' % result[0])#> KPSS Statistic: 7.902349print('p-value: %f' % result[1])#> p-value: 0.010000"},{"path":"in-class-exercise-1.html","id":"r-7","chapter":"13 In-class exercise","heading":"R","text":"","code":"\nlibrary(tseries)\nlibrary(zoo)\n#what happens if we fit AR for price, not that price is non-stationary\nfitAR=arima(price$Adjusted, order = c(1,0,0))\nprint(fitAR)#> \n#> Call:\n#> arima(x = price$Adjusted, order = c(1, 0, 0))\n#> \n#> Coefficients:\n#>       ar1  intercept\n#>         1   2159.379\n#> s.e.    0        NaN\n#> \n#> sigma^2 estimated as 513.1:  log likelihood = -15248,  aic = 30501.99\nadf.test(coredata(price))#> Augmented Dickey-Fuller Test \n#> alternative: stationary \n#>  \n#> Type 1: no drift no trend \n#>       lag  ADF p.value\n#>  [1,]   0 2.96    0.99\n#>  [2,]   1 3.59    0.99\n#>  [3,]   2 3.25    0.99\n#>  [4,]   3 3.19    0.99\n#>  [5,]   4 3.46    0.99\n#>  [6,]   5 3.42    0.99\n#>  [7,]   6 3.77    0.99\n#>  [8,]   7 3.28    0.99\n#>  [9,]   8 3.62    0.99\n#> Type 2: with drift no trend \n#>       lag  ADF p.value\n#>  [1,]   0 1.25    0.99\n#>  [2,]   1 1.73    0.99\n#>  [3,]   2 1.48    0.99\n#>  [4,]   3 1.41    0.99\n#>  [5,]   4 1.62    0.99\n#>  [6,]   5 1.57    0.99\n#>  [7,]   6 1.80    0.99\n#>  [8,]   7 1.46    0.99\n#>  [9,]   8 1.67    0.99\n#> Type 3: with drift and trend \n#>       lag    ADF p.value\n#>  [1,]   0 -1.238   0.900\n#>  [2,]   1 -0.564   0.979\n#>  [3,]   2 -0.906   0.952\n#>  [4,]   3 -0.951   0.947\n#>  [5,]   4 -0.667   0.974\n#>  [6,]   5 -0.691   0.971\n#>  [7,]   6 -0.351   0.989\n#>  [8,]   7 -0.794   0.962\n#>  [9,]   8 -0.452   0.984\n#> ---- \n#> Note: in fact, p.value = 0.01 means p.value <= 0.01\nkpss.test(coredata(price))#> KPSS Unit Root Test \n#> alternative: nonstationary \n#>  \n#> Type 1: no drift no trend \n#>  lag   stat p.value\n#>   13 0.0872     0.1\n#> ----- \n#>  Type 2: with drift no trend \n#>  lag  stat p.value\n#>   13 0.066     0.1\n#> ----- \n#>  Type 1: with drift and trend \n#>  lag  stat p.value\n#>   13 0.151  0.0458\n#> ----------- \n#> Note: p.value = 0.01 means p.value <= 0.01 \n#>     : p.value = 0.10 means p.value >= 0.10"},{"path":"homework-1.html","id":"homework-1","chapter":"Homework","heading":"Homework","text":"","code":""},{"path":"homework-1.html","id":"problem-1-1","chapter":"Homework","heading":"Problem 1","text":"Give dataCalculate ACF lags 0 15 lower, upper bounds significant α = 5%","code":""},{"path":"homework-1.html","id":"python-8","chapter":"Homework","heading":"Python","text":"","code":"import numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Import Data\ndata = [10.31778, 10.29235, 10.30075, 10.29208, 10.31304, 10.32042,\n        10.36644, 10.36744, 10.39553, 10.48562, 10.47619, 10.46396,\n        10.34145, 10.40247, 10.39158, 10.35517, 10.35166, 10.36395]\n\nimport pandas as pd\ndf = pd.DataFrame(data, columns = ['data'])\ndf.head(5)#>        data\n#> 0  10.31778\n#> 1  10.29235\n#> 2  10.30075\n#> 3  10.29208\n#> 4  10.31304from statsmodels.tsa.stattools import acf\n# Calculate ACF\nprint('Calculated ACF by lags 0 - 15:\\n')#> Calculated ACF by lags 0 - 15:acf(df['data'], nlags = 15)#> array([ 1.        ,  0.71637405,  0.48086057,  0.24512236,  0.07189534,\n#>        -0.16133272, -0.38073392, -0.39587896, -0.41465118, -0.34811093,\n#>        -0.23179094, -0.09359336, -0.02129721, -0.02593246,  0.0128132 ,\n#>         0.02943992])import matplotlib.pyplot as plt\nfrom statsmodels.graphics.tsaplots import plot_acf\nplot_acf(df['data'], lags = 15)\nplt.show()"},{"path":"homework-1.html","id":"r-8","chapter":"Homework","heading":"R","text":"","code":"\n# Import Data\ndata = c(10.31778, 10.29235, 10.30075, 10.29208, 10.31304, 10.32042,\n        10.36644, 10.36744, 10.39553, 10.48562, 10.47619, 10.46396,\n        10.34145, 10.40247, 10.39158, 10.35517, 10.35166, 10.36395)\nhead(data)#> [1] 10.31778 10.29235 10.30075 10.29208 10.31304 10.32042\n# Calculate ACF\nacf(data,lag.max = 15,plot=F)#> \n#> Autocorrelations of series 'data', by lag\n#> \n#>      0      1      2      3      4      5      6      7      8      9     10 \n#>  1.000  0.716  0.481  0.245  0.072 -0.161 -0.381 -0.396 -0.415 -0.348 -0.232 \n#>     11     12     13     14     15 \n#> -0.094 -0.021 -0.026  0.013  0.029\n# Plot ACF\nacf(data,lag.max = 15)"},{"path":"homework-1.html","id":"problem-2-1","chapter":"Homework","heading":"Problem 2","text":"Consider \\(MA(q)\\).","code":""},{"path":"homework-1.html","id":"question-a-7","chapter":"Homework","heading":"Question a","text":"Calculate autocovariance \\(\\gamma(h)\\) ACF \\(\\rho(h)\\).Note MA(q) stationary since linear combination stationary\nprocesses. Note , white noise \n\\[\\gamma(0)=Cov(\\epsilon_t,\\epsilon_{t})=\\sigma^2 \\]\n\\(\\gamma(h)=0\\) \\(h \\neq 0\\). simple assume \\(E[X_t] = 0\\). \nautocovariance \\[\\begin{align*}\n\\gamma(h) &= Cov(X_t,X_{t+h}) \\\\\n&=Cov(\\sum_{=1}^q \\theta_i \\epsilon_{t-},\\sum_{j=1}^q \\theta_j \\epsilon_{t+h-j}) \\\\\n&= \\sum_{=1}^q \\sum_{j=1}^q \\theta_i \\theta_j Cov(\\epsilon_{t-},\\epsilon_{t+h-j}) \\\\\n&= \\sum_{=0}^{q-|h|} \\theta_i \\theta_{+|h|}\\sigma^2, |h| \\leq q\n\\end{align*}\\]\nHence,\n\\[ \\rho(h) = \\frac{\\sum_{=0}^{q-|h|} \\theta_i \\theta_{+|h|}\\sigma^2}{\\sum_{=0}^{q}\\theta_i^2} \\] \\(\\rho(h)=0\\) \\(|h| > q\\)","code":""},{"path":"homework-1.html","id":"question-b-7","chapter":"Homework","heading":"Question b","text":"Show MA(1) processes \\(X_t\\) \\(Y_t\\)\n\\[\\begin{align*}\nX_t = \\beta \\epsilon_{t−1} + \\epsilon_t \\\\\nY_t = \\frac{1}{\\beta} \\epsilon_{t−1} + \\epsilon_t \\\\\n\\end{align*}\\]\nACF.Consider \\(MA(1)\\) model \\(X_t=\\beta \\epsilon_{t-1}+\\epsilon_t\\). coefficient \\(\\theta_1=\\beta\\). ACF given \n\\[ \\rho_1=\\frac{\\beta}{1+\\beta^2}, (1) \\]\n\\(\\rho_h=0, \\forall h \\geq 2\\)Consider \\(MA(1)\\) model \\(Y_t=\\frac{1}{\\beta} \\epsilon_{t-1}+\\epsilon_t\\). coefficient \\(\\theta_1=\\frac{1}{\\beta}\\). ACF given \n\\[\\begin{align*} \\rho_1&=\\frac{\\frac{1}{\\beta}}{1+\\left(\\frac{1}{\\beta}\\right)^2} \\\\\n&=\\frac{1}{\\beta} \\cdot \\frac{\\beta^2}{1+\\beta^2} \\\\\n&=\\frac{\\beta}{1+\\beta^2}, (2)\n\\end{align*}\\]\n\\(\\rho_h=0, \\forall h \\geq 2\\)(1),(2) imply two \\(MA(1)\\) processes ACF.Answer: \\(X_t\\) \\(Y_t\\) ACF.","code":""},{"path":"homework-1.html","id":"problem-3-1","chapter":"Homework","heading":"Problem 3","text":"Suppose stationary process \\(X_t\\) autocovariance function given \\(\\gamma(h)\\).\nConsider process \\(Y_t = X_t − X_{t−1}\\).process \\(Y_t\\) stationary\\[\\begin{align*}\n\\mathbb{E}(Y_t)&=\\mathbb{E}(X_t)-\\mathbb{E}(X_{t-1}) \\\\\n&=0 \\\\\nVar(Y_t) &=Var(X_t-X_{t=1}) \\\\\n&=Var(X_t)+Var(X_{t-1})-2Cov(X_t,X_{t-1}) \\\\\n&=2\\sigma_x^2-2\\gamma_x(1) < \\infty \\\\\nCov(Y_t,Y_{t+h})&=Cov(X_t-X_{t-1},X_{t+h}-X_{t+h-1}) \\\\\n&=Cov(X_t,X_{t+h})\n-Cov(X_t,X_{t+h-1})\n-Cov(X_{t-1},X_{t+h})\n+Cov(X_{t-1},X_{t+h-1}) \\\\\n&=\\gamma(h)-\\gamma(h-1)-\\gamma(h+1)+\\gamma(h) \\\\\n&=2\\gamma(h)-\\gamma(h-1)-\\gamma(h+1)\n\\end{align*}\\]Answer: \\(\\{Yt\\}\\) weakly stationary procesFind autocorrelation function \\(Y_t\\)\\[\\begin{align*}\n\\rho(h)&=\\rho_h(Y_t) \\\\\n&=\\frac{\\gamma(h)}{\\gamma(0)} \\\\\n&=\\frac{2\\gamma(h)-\\gamma(h-1)-\\gamma(h+1)}{2 (\\gamma(0)-\\gamma(1))}\n\\end{align*}\\]Answer: autocorrelation function \\(Y_t\\) \\(\\frac{2\\gamma(h)-\\gamma(h-1)-\\gamma(h+1)}{2 (\\gamma(0)-\\gamma(1))}\\)","code":""},{"path":"homework-1.html","id":"problem-4-1","chapter":"Homework","heading":"Problem 4","text":"Find autocorrelation function second order moving average process \\(MA(2)\\)\n\\[X_t = 0.5 \\epsilon_{t−1} − 0.2 \\epsilon_{t−2} + \\epsilon_t\\]\n\\(\\epsilon_t\\) white noise.Apply problem \\(2\\) \\(q=2\\), \n\\[ \\gamma(h)=\\sum_{=0}^{2-|h|}\\theta_i \\theta_{+|h|}\\sigma^2, |h| \\leq 2 \\]\nHence,\n\\[\\begin{align*}\n\\gamma(0) &= (\\theta_0^2 + \\theta_1^2 + \\theta_2^2) \\sigma^2 \\\\\n&=(0.5^2 + 0.2^2 +1)\\sigma^2 \\\\\n&=1.29 \\sigma^2 \\\\\n\\gamma(1) &= (\\theta_0 \\theta_1 + \\theta_1 \\theta_2) \\sigma^2 \\\\\n&=(1 \\cdot 0.5   - 0.5 \\cdot 0.2 )\\sigma^2 \\\\\n&=0.4 \\sigma^2 \\\\\n\\gamma(2) &= \\theta_0 \\theta_2 \\sigma^2 \\\\\n&=-0.2 \\sigma^2 \\\\\n\\end{align*}\\]\\[\\begin{align*}\n\\gamma(0)&=Var(X_t) \\\\\n&=0.5^2 \\sigma^2 +0.2^2 \\sigma^2+\\sigma^2 \\\\\n&=(0.5^2 + 0.2^2 +1)\\sigma^2 \\\\\n&=1.29 \\sigma^2 \\\\\n\\gamma(1) &=Cov(X_t,X_{t-1}) \\\\\n&=Cov(0.5 \\epsilon_{t-1} - 0.2 \\epsilon_{t-2}+\\epsilon_t,0.5 \\epsilon_{t-2} -0.2\\epsilon_{t-3}+\\epsilon_{t-1}) \\\\\n&=0.5 \\cdot 1 Var(\\epsilon_{t-1})-0.2 \\cdot 0.5 Var(\\epsilon_{t-2}) \\\\\n&=(0.5 \\cdot 1 -0.2 \\cdot 0.5)\\sigma^2 \\\\\n&=0.4 \\sigma^2 \\\\\n\\gamma(2) &=Cov(X_t,X_{t-2}) \\\\\n&=Cov(0.5 \\epsilon_{t-1} - 0.2 \\epsilon_{t-2}+\\epsilon_t,0.5 \\epsilon_{t-3} -0.2\\epsilon_{t-4}+\\epsilon_{t-2}) \\\\\n&=-0.2\\cdot 1Var(\\epsilon_{t-2}) \\\\\n&=-0.2 \\sigma^2\n\\end{align*}\\]\\[\\rho(h)=\\begin{cases}\n1&  h=0.\\\\\n0.31&  h=1\\\\\n-0.155&  h=2 \\\\\n0&  h \\geq 3\n\\end{cases}\\]Answer: autocorrelation function second order moving average process \n\\[\\rho(h)=\\begin{cases}\n1&  h=0.\\\\\n0.31&  h=1\\\\\n-0.155&  h=2 \\\\\n0&  h \\geq 3\n\\end{cases}\\]","code":""},{"path":"homework-1.html","id":"problem-5-1","chapter":"Homework","heading":"Problem 5","text":"Assume price asset close trading yesterday \\(\\$300\\) volatility estimated \\(1.3\\%\\) per day. price close trading today \\(\\$298\\). Update volatility estimate using following methods:","code":""},{"path":"homework-1.html","id":"question-a-8","chapter":"Homework","heading":"Question a","text":"EWMA \\(\\lambda=0.94\\).\\[\\begin{align*}\n\\widehat{\\sigma}_t^2 &=\\lambda\\cdot\\widehat{\\sigma}_{t-1}^2+(1-\\lambda)\\cdot y_{t-1}^2 \\\\\n&=0.94\\cdot0.013^2+0.06\\cdot\\left( \\ln \\frac{298}{300}\\right)^2 \\\\\n&\\approx1.6153\\cdot10^{-4} \\\\\n\\rightarrow \\widehat{\\sigma}_t &\\approx0.0127\n\\end{align*}\\]Answer: volatility estimate using EWMA \\(\\lambda=0.94\\) \\(1.27\\%\\).","code":""},{"path":"homework-1.html","id":"question-b-8","chapter":"Homework","heading":"Question b","text":"GARCH\\((1,1)\\) model \\(\\omega=2\\cdot10^{-6},\\alpha=0.04,\\beta=0.94\\).\\[\\begin{align*}\n\\widehat{\\sigma}_t^2 &=\\omega+\\alpha\\cdot y_{t-1}^2+\\beta\\cdot\\widehat{\\sigma}_{t-1}^2 \\\\\n&=2\\cdot10^{-6}+0.04\\cdot\\left( \\ln \\frac{300}{298}\\right)^2+0.94\\cdot0.013^2 \\\\\n&\\approx1.6265\\cdot10^{-4} \\\\\n\\rightarrow \\widehat{\\sigma}_t &\\approx0.0128\n\\end{align*}\\]Answer: volatility estimate using GARCH\\((1,1)\\) model given parameters \\(1.28\\%\\).","code":""},{"path":"homework-1.html","id":"problem-6-1","chapter":"Homework","heading":"Problem 6","text":"Suppose parameters GARCH\\((1,1)\\) model \\(\\alpha=0.03,\\beta=0.95,\\omega=2\\cdot10^{-6}.\\)","code":""},{"path":"homework-1.html","id":"question-a-9","chapter":"Homework","heading":"Question a","text":"long-run average volatility?long-run average volatility \n\\[\\begin{align*}\n\\sigma &=\\sqrt{\\frac{\\omega}{1-\\alpha-\\beta}} \\\\\n&=\\sqrt{\\frac{2\\cdot10^{-6}}{1-0.03-0.95}} \\\\\n&=0.01\n\\end{align*}\\]Answer: long-run average volatility \\(1\\%\\).","code":""},{"path":"homework-1.html","id":"question-b-9","chapter":"Homework","heading":"Question b","text":"current volatility \\(1.5\\%\\) per day, estimate volatility \\(20\\), \\(40\\), \\(60\\) days?estimate volatility \\(20\\) days :\n\\[\\begin{align*}\n\\mathbb{E}(\\sigma_{n+20}^2) &=\\sigma^2+(\\alpha+\\beta)^{20}\\cdot(\\sigma_n^2-\\sigma^2) \\\\\n&=0.01^2+(0.03+0.95)^{20}\\cdot(0.015^2-0.01^2) \\\\\n&\\approx1.8345\\cdot10^{-4} \\\\\n\\rightarrow \\sigma_{n+20}&\\approx0.0135 \\\\\n\\end{align*}\\]estimate volatility \\(40\\) days :\n\\[\\begin{align*}\n\\mathbb{E}(\\sigma_{n+40}^2) &=\\sigma^2+(\\alpha+\\beta)^{40}\\cdot(\\sigma_n^2-\\sigma^2) \\\\\n&=0.01^2+(0.03+0.95)^{40}\\cdot(0.015^2-0.01^2) \\\\\n&\\approx1.5571\\cdot10^{-4} \\\\\n\\rightarrow \\sigma_{n+40}&\\approx0.0125 \\\\\n\\end{align*}\\]estimate volatility \\(60\\) days :\n\\[\\begin{align*}\n\\mathbb{E}(\\sigma_{n+60}^2) &=\\sigma^2+(\\alpha+\\beta)^{60}\\cdot(\\sigma_n^2-\\sigma^2) \\\\\n&=0.01^2+(0.03+0.95)^{60}\\cdot(0.015^2-0.01^2) \\\\\n&\\approx1.3719\\cdot10^{-4} \\\\\n\\rightarrow \\sigma_{n+60}&\\approx0.0117 \\\\\n\\end{align*}\\]Answer: current volatility \\(1.5\\%\\) per day, estimates volatility \\(20\\), \\(40\\), \\(60\\) days \\(1.35\\%\\), \\(1.25\\%\\) \\(1.17\\%\\), respectively.","code":""},{"path":"homework-1.html","id":"question-c-4","chapter":"Homework","heading":"Question c","text":"volatility used price \\(20\\), \\(40\\), \\(60\\)-day options?current volatility \\(1.5\\%\\) per day, \\[\\begin{align*}\n&=\\ln\\frac{1}{\\alpha+\\beta} \\\\\n&=\\ln\\frac{1}{0.03+0.95} \\\\\n&\\approx0.0202\n\\end{align*}\\]volatility used price \\(20\\)-day options:\n\\[\\begin{align*}\n\\sigma^2(20) &=252\\cdot\\left(\\sigma^2+\\frac{1-e^{-20a}}{20a}\\cdot(\\sigma_{n}^2-\\sigma^2)\\right) \\\\\n&= 252\\cdot\\left(0.01^2+\\frac{1-e^{-20\\cdot0.0202}}{20\\cdot0.0202}\\cdot(0.015^2-0.01^2)\\right)\\\\\n&\\approx0.0511 \\\\\n\\rightarrow\\sigma(20) &\\approx0.2261\n\\end{align*}\\]volatility used price \\(40\\)-day options:\n\\[\\begin{align*}\n\\sigma^2(40) &=252\\cdot\\left(\\sigma^2+\\frac{1-e^{-40a}}{40a}\\cdot(\\sigma_{n}^2-\\sigma^2)\\right) \\\\\n&= 252\\cdot\\left(0.01^2+\\frac{1-e^{-40\\cdot0.0202}}{40\\cdot0.0202}\\cdot(0.015^2-0.01^2)\\right)\\\\\n&\\approx0.0468 \\\\\n\\rightarrow\\sigma(40) &\\approx0.2164\n\\end{align*}\\]volatility used price \\(60\\)-day options:\n\\[\\begin{align*}\n\\sigma^2(60) &=252\\cdot\\left(\\sigma^2+\\frac{1-e^{-60a}}{60a}\\cdot(\\sigma_{n}^2-\\sigma^2)\\right) \\\\\n&= 252\\cdot\\left(0.01^2+\\frac{1-e^{-60\\cdot0.0202}}{60\\cdot0.0202}\\cdot(0.015^2-0.01^2)\\right)\\\\\n&\\approx0.0435 \\\\\n\\rightarrow\\sigma(60) &\\approx0.2085\n\\end{align*}\\]Answer: volatility used price \\(20\\), \\(40\\) \\(60\\)-day options \\(22.61\\%\\), \\(21.64\\%\\) \\(20.85\\%\\), respectively.","code":""},{"path":"homework-1.html","id":"question-d","chapter":"Homework","heading":"Question d","text":"Suppose event increases volatility \\(1.5%\\) per day \\(2%\\) per day. Estimate effect volatility \\(20\\), \\(40\\), \\(60\\) days.estimate volatility \\(20\\) days :\n\\[\\begin{align*}\n\\mathbb{E}(\\sigma_{n+20}^2) &=\\sigma^2+(\\alpha+\\beta)^{20}\\cdot(\\sigma_n^2-\\sigma^2) \\\\\n&=0.01^2+(0.03+0.95)^{20}\\cdot(0.02^2-0.01^2) \\\\\n&\\approx3.0028\\cdot10^{-4} \\\\\n\\rightarrow \\sigma_{n+20}&\\approx 0.0173 \\\\\n\\end{align*}\\]estimate volatility \\(40\\) days :\n\\[\\begin{align*}\n\\mathbb{E}(\\sigma_{n+40}^2) &=\\sigma^2+(\\alpha+\\beta)^{40}\\cdot(\\sigma_n^2-\\sigma^2) \\\\\n&=0.01^2+(0.03+0.95)^{40}\\cdot(0.02^2-0.01^2) \\\\\n&\\approx2.3371\\cdot10^{-4} \\\\\n\\rightarrow \\sigma_{n+40}&\\approx 0.0153\\\\\n\\end{align*}\\]estimate volatility \\(60\\) days :\n\\[\\begin{align*}\n\\mathbb{E}(\\sigma_{n+60}^2) &=\\sigma^2+(\\alpha+\\beta)^{60}\\cdot(\\sigma_n^2-\\sigma^2) \\\\\n&=0.01^2+(0.03+0.95)^{60}\\cdot(0.02^2-0.01^2) \\\\\n&\\approx1.8927\\cdot10^{-4} \\\\\n\\rightarrow \\sigma_{n+60}&\\approx 0.0138\\\\\n\\end{align*}\\]Therefore, volatility \\(20\\), \\(40\\) \\(60\\) days increases respectively \n\\[\\frac{0.0173}{0.0135}-1\\approx0.2814 \\\\\n\\frac{0.0153}{0.0125}-1\\approx0.2240 \\\\\n\\frac{0.0138}{0.0117}-1\\approx0.1795\\]Answer: event increases volatility \\(1.5%\\) per day \\(2%\\) per day, volatility \\(20\\), \\(40\\) \\(60\\) days increases \\(28.14\\%\\), \\(22.4\\%\\) \\(17.95\\%\\), respectively.","code":""},{"path":"homework-1.html","id":"question-e","chapter":"Homework","heading":"Question e","text":"Estimate much event increases volatilities used price \\(20\\), \\(40\\), \\(60\\)-day options.current volatility \\(2\\%\\) per day, \\[\\begin{align*}\n&=\\ln\\frac{1}{\\alpha+\\beta} \\\\\n&=\\ln\\frac{1}{0.03+0.95} \\\\\n&\\approx0.0202\n\\end{align*}\\]volatility used price \\(20\\)-day options:\n\\[\\begin{align*}\n\\sigma^2(20) &=252\\cdot\\left(\\sigma^2+\\frac{1-e^{-20a}}{20a}\\cdot(\\sigma_{n}^2-\\sigma^2)\\right) \\\\\n&= 252\\cdot\\left(0.01^2+\\frac{1-e^{-20\\cdot0.0202}}{20\\cdot0.0202}\\cdot(0.02^2-0.01^2)\\right)\\\\\n&\\approx0.0874 \\\\\n\\rightarrow\\sigma(20) &\\approx0.2956\n\\end{align*}\\]volatility used price \\(40\\)-day options:\n\\[\\begin{align*}\n\\sigma^2(40) &=252\\cdot\\left(\\sigma^2+\\frac{1-e^{-40a}}{40a}\\cdot(\\sigma_{n}^2-\\sigma^2)\\right) \\\\\n&= 252\\cdot\\left(0.01^2+\\frac{1-e^{-40\\cdot0.0202}}{40\\cdot0.0202}\\cdot(0.02^2-0.01^2)\\right)\\\\\n&\\approx0.0771 \\\\\n\\rightarrow\\sigma(40) &\\approx0.2776\n\\end{align*}\\]volatility used price \\(60\\)-day options:\n\\[\\begin{align*}\n\\sigma^2(60) &=252\\cdot\\left(\\sigma^2+\\frac{1-e^{-60a}}{60a}\\cdot(\\sigma_{n}^2-\\sigma^2)\\right) \\\\\n&= 252\\cdot\\left(0.01^2+\\frac{1-e^{-60\\cdot0.0202}}{60\\cdot0.0202}\\cdot(0.02^2-0.01^2)\\right)\\\\\n&\\approx0.0690 \\\\\n\\rightarrow\\sigma(60) &\\approx0.2627\n\\end{align*}\\]Therefore, event increases volatility \\(1.5%\\) per day \\(2%\\) per day, volatilities used price increase \n\\[\\frac{0.2956}{0.2261}-1\\approx0.3074 \\\\\n\\frac{0.2776}{0.2164}-1\\approx0.2828 \\\\\n\\frac{0.2627}{0.2085}-1\\approx0.2600\\]Answer: event increases volatility \\(1.5%\\) per day \\(2%\\) per day, volatilities used price increase \\(30.74\\%\\), \\(28.28\\%\\) \\(26\\%\\), respectively.","code":""},{"path":"homework-1.html","id":"problem-7-1","chapter":"Homework","heading":"Problem 7","text":"Consider ARCH\\((1)\\) process, show \n\\[\\mathbb{E}(\\sigma_{t+s}^2|\\mathcal{F}_t)=\\frac{1-\\alpha^s}{1-\\alpha}\\cdot\\omega+\\alpha^s\\cdot\\sigma_t^2,\\forall s\\geq1\\]Consider following ARCH\\((1)\\) process:\n\\[\\sigma_{t+1}^2=\\omega+\\alpha \\sigma_t^2\\epsilon_t^2\\]\nprove assertion\n\\[\\mathbb{E}(\\sigma_{t+s}^2|\\mathcal{F}_t)=\\frac{1-\\alpha^s}{1-\\alpha}\\cdot\\omega+\\alpha^s\\sigma_t^2,\\forall s\\geq1\\]\ninduction \\(s\\).\\(s=1\\):\n\\[\\begin{align*}\n\\mathbb{E}(\\sigma_{t+1}^2|\\mathcal{F}_t) &=\\mathbb{E}(\\omega+\\alpha \\sigma_t^2\\epsilon_t^2|\\mathcal{F}_t) \\\\\n&=\\mathbb{E}(\\omega+\\alpha \\sigma_t^2\\epsilon_t^2) \\\\\n&=\\mathbb{E}(\\omega)+\\mathbb{E}(\\alpha \\sigma_t^2\\epsilon_t^2) \\\\\n&=\\omega+\\alpha \\sigma_t^2\\mathbb{E}(\\epsilon_t^2) \\\\\n&=\\frac{1-\\alpha^1}{1-\\alpha}\\cdot\\omega+\\alpha \\sigma_t^2\n\\end{align*}\\]Assume assertion holds \\(k\\\\mathbb{N}\\). :\n\\[\\begin{align*}\n\\mathbb{E}(\\sigma_{t+k+1}^2|\\mathcal{F}_t) &= \\mathbb{E}(\\mathbb{E}(\\sigma_{t+k+1}^2|\\mathcal{F}_{t+1})|\\mathcal{F}_t) \\\\\n&=\\mathbb{E}\\left(\\left.\\frac{1-\\alpha^k}{1-\\alpha}\\cdot\\omega+\\alpha^k\\sigma_{t+1}^2\\right|\\mathcal{F}_t\\right)\\\\\n&= \\frac{1-\\alpha^k}{1-\\alpha}\\cdot\\omega+\\alpha^k\\mathbb{E}(\\sigma_{t+1}^2|\\mathcal{F}_t) \\\\\n&=\\frac{1-\\alpha^k}{1-\\alpha}\\cdot\\omega+\\alpha^k(\\omega+\\alpha \\sigma_t^2)\\\\\n&= \\left(\\frac{1-\\alpha^k}{1-\\alpha}+\\alpha^k\\right)\\cdot\\omega+\\alpha^{k+1}\\sigma_t^2 \\\\\n&=\\frac{1-\\alpha^{k+1}}{1-\\alpha}\\cdot\\omega+\\alpha^{k+1}\\sigma_t^2\n\\end{align*}\\]Therefore, assertion holds \\(\\forall s\\geq1\\).","code":""},{"path":"homework-1.html","id":"problem-8-1","chapter":"Homework","heading":"Problem 8","text":"","code":""},{"path":"homework-1.html","id":"python-9","chapter":"Homework","heading":"Python","text":"can download SP500 data internet using Python.","code":"import pandas_datareader as web\nprice = web.get_data_yahoo(\"^GSPC\",\n                           start = \"2009-01-01\",\n                           end =\"2021-12-31\")"},{"path":"homework-1.html","id":"question-a-10","chapter":"Homework","heading":"Question a","text":"Denote \\(y\\) returns SP500. Plot returns calculate statistical characterizations returns (e.g., min, max, sd, skewness, kurtosis, acf), use Jarque Berra test, Box test.","code":"# Calculate returns y\nimport numpy as np\ny = np.diff(np.log(price['Adj Close']))# Plot the returns\nimport matplotlib.pyplot as plt\nplt.plot(y)\nplt.show()# Statistical characterizations of returns\nfrom scipy.stats import describe\ndescribe(y)#> DescribeResult(nobs=3273, minmax=(-0.12765219747281709, 0.08968323251796306), mean=0.0005081885399690335, variance=0.0001314375361112753, skewness=-0.6777972104478536, kurtosis=13.133833345827092)# Autocorrelation function\nfrom statsmodels.tsa.stattools import acf\nacf(y)#> array([ 1.        , -0.1437426 ,  0.0873594 , -0.03140535, -0.019112  ,\n#>         0.00508723, -0.0803378 ,  0.10808321, -0.094185  ,  0.07152584,\n#>        -0.00891499, -0.00466423,  0.01929302, -0.04416083,  0.01990267,\n#>        -0.07326844,  0.05878776, -0.00504835, -0.02597924, -0.01826176,\n#>        -0.01700834,  0.03833622, -0.06437332,  0.03621343, -0.01485914,\n#>        -0.03767194, -0.02067457,  0.02913685, -0.01740174,  0.00977897,\n#>         0.00331506,  0.00575203, -0.03713924,  0.01212813, -0.01917425,\n#>         0.00639421])# Plot ACF of the returns\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.tsaplots import plot_acf\nplot_acf(y)\nplt.show()# Jarque Berra test\nimport scipy.stats as stats\nstats.jarque_bera(y)#> Jarque_beraResult(statistic=23774.964889700783, pvalue=0.0)# Box test\nfrom statsmodels.stats.diagnostic import acorr_ljungbox\nacorr_ljungbox(y)#>        lb_stat     lb_pvalue\n#> 1    67.688520  1.914751e-16\n#> 2    92.697505  7.430063e-21\n#> 3    95.930588  1.164970e-20\n#> 4    97.128307  4.018129e-20\n#> 5    97.213193  2.042500e-19\n#> 6   118.389393  3.550392e-23\n#> 7   156.729878  1.563740e-30\n#> 8   185.852981  6.065963e-36\n#> 9   202.653903  9.199582e-39\n#> 10  202.914988  3.979104e-38"},{"path":"homework-1.html","id":"question-b-10","chapter":"Homework","heading":"Question b","text":"Use ADF test prices returns see series stationary.","code":"# Plot price\nimport matplotlib.pyplot as plt\nplt.plot(price['Adj Close'])\nplt.show()# ADF test for prices\nfrom statsmodels.tsa.stattools import adfuller\nresult = adfuller(price['Adj Close'])\nprint('p-value: %f' % result[1])#> p-value: 0.998453# Plot the returns\nimport matplotlib.pyplot as plt\nplt.plot(y)\nplt.show()# ADF test for returns\nfrom statsmodels.tsa.stattools import adfuller\nresult = adfuller(y)\nprint('p-value: %f' % result[1])#> p-value: 0.000000"},{"path":"homework-1.html","id":"question-c-5","chapter":"Homework","heading":"Question c","text":"Using AR\\((1)\\) fit price returns y find coefficients fitted AR\\((1)\\) model.Note residuals mean zero, forecasts biased. Now using fact can check mean residuals AR\\((1)\\) price return see can apply AR\\((1)\\) directly price.Check independence residuals fitted AR\\((1)\\), independence ?ACF significant many lags residuals AR\\((1)\\) returns correlated thus independence.","code":"# Using AR(1) to fit the price\nimport statsmodels\nfrom statsmodels.tsa.arima.model import ARIMA\nar1_price = ARIMA(price['Adj Close'], \n                  order = (1, 0, 0)).fit()#> /Users/cliex159/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n#>   self._init_dates(dates, freq)\n#> /Users/cliex159/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n#>   self._init_dates(dates, freq)\n#> /Users/cliex159/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n#>   self._init_dates(dates, freq)print(ar1_price.summary())#>                                SARIMAX Results                                \n#> ==============================================================================\n#> Dep. Variable:              Adj Close   No. Observations:                 3274\n#> Model:                 ARIMA(1, 0, 0)   Log Likelihood              -15203.588\n#> Date:                Thu, 24 Mar 2022   AIC                          30413.175\n#> Time:                        16:39:12   BIC                          30431.456\n#> Sample:                             0   HQIC                         30419.722\n#>                                - 3274                                         \n#> Covariance Type:                  opg                                         \n#> ==============================================================================\n#>                  coef    std err          z      P>|z|      [0.025      0.975]\n#> ------------------------------------------------------------------------------\n#> const       2159.2460   1157.018      1.866      0.062    -108.467    4426.959\n#> ar.L1          0.9998      0.000   2301.214      0.000       0.999       1.001\n#> sigma2       630.8779      4.496    140.320      0.000     622.066     639.690\n#> ===================================================================================\n#> Ljung-Box (L1) (Q):                  87.33   Jarque-Bera (JB):             74201.03\n#> Prob(Q):                              0.00   Prob(JB):                         0.00\n#> Heteroskedasticity (H):               7.34   Skew:                            -1.12\n#> Prob(H) (two-sided):                  0.00   Kurtosis:                        26.21\n#> ===================================================================================\n#> \n#> Warnings:\n#> [1] Covariance matrix calculated using the outer product of gradients (complex-step).# Find the coefficients of the fitted AR(1) model\nar1_price.params[0:2]#> const    2159.246035\n#> ar.L1       0.999802\n#> dtype: float64# Using AR(1) to fit the returns\nimport statsmodels\nfrom statsmodels.tsa.arima.model import ARIMA\nar1_y = ARIMA(y, \n              order = (1, 0, 0)).fit()\nprint(ar1_y.summary())#>                                SARIMAX Results                                \n#> ==============================================================================\n#> Dep. Variable:                      y   No. Observations:                 3273\n#> Model:                 ARIMA(1, 0, 0)   Log Likelihood               10015.913\n#> Date:                Thu, 24 Mar 2022   AIC                         -20025.825\n#> Time:                        16:39:13   BIC                         -20007.545\n#> Sample:                             0   HQIC                        -20019.279\n#>                                - 3273                                         \n#> Covariance Type:                  opg                                         \n#> ==============================================================================\n#>                  coef    std err          z      P>|z|      [0.025      0.975]\n#> ------------------------------------------------------------------------------\n#> const          0.0005      0.000      2.773      0.006       0.000       0.001\n#> ar.L1         -0.1437      0.007    -19.320      0.000      -0.158      -0.129\n#> sigma2         0.0001   1.32e-06     97.279      0.000       0.000       0.000\n#> ===================================================================================\n#> Ljung-Box (L1) (Q):                   0.31   Jarque-Bera (JB):             18498.33\n#> Prob(Q):                              0.58   Prob(JB):                         0.00\n#> Heteroskedasticity (H):               0.97   Skew:                            -0.83\n#> Prob(H) (two-sided):                  0.57   Kurtosis:                        14.53\n#> ===================================================================================\n#> \n#> Warnings:\n#> [1] Covariance matrix calculated using the outer product of gradients (complex-step).# Find the coefficients of the fitted AR(1) model\nar1_y.params[0:2]#> array([ 0.00050302, -0.14374591])# Check the mean of residuals\nar1_price.resid[1:].mean()#> 1.1800462919613017# Check the mean of residuals\nar1_y.resid[1:].mean()#> -3.311666982146061e-06# Plot ACF of residuals\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.tsaplots import plot_acf\nplot_acf(ar1_y.resid)\nplt.show()"},{"path":"homework-1.html","id":"question-d-1","chapter":"Homework","heading":"Question d","text":"Fit returns ARMA\\((3,3)\\), compare AR\\((1)\\) , can conclude \nARMA\\((3,3)\\) better AR\\((1)\\)?AIC ARMA\\((3,3)\\) less AIC AR\\((1)\\) can conclude ARMA\\((3,3)\\) better AR\\((1)\\).","code":"# Fit the returns by ARMA(3,3)\nimport statsmodels\nfrom statsmodels.tsa.arima.model import ARIMA\narma33_y = ARIMA(y, \n                 order = (3, 0, 3)).fit()\nprint(arma33_y.summary())#>                                SARIMAX Results                                \n#> ==============================================================================\n#> Dep. Variable:                      y   No. Observations:                 3273\n#> Model:                 ARIMA(3, 0, 3)   Log Likelihood               10024.145\n#> Date:                Thu, 24 Mar 2022   AIC                         -20032.290\n#> Time:                        16:39:19   BIC                         -19983.542\n#> Sample:                             0   HQIC                        -20014.833\n#>                                - 3273                                         \n#> Covariance Type:                  opg                                         \n#> ==============================================================================\n#>                  coef    std err          z      P>|z|      [0.025      0.975]\n#> ------------------------------------------------------------------------------\n#> const          0.0005      0.000      2.464      0.014       0.000       0.001\n#> ar.L1         -0.0633      2.201     -0.029      0.977      -4.377       4.250\n#> ar.L2          0.0372      1.404      0.027      0.979      -2.715       2.789\n#> ar.L3         -0.0115      0.374     -0.031      0.976      -0.744       0.721\n#> ma.L1         -0.0700      2.201     -0.032      0.975      -4.384       4.244\n#> ma.L2          0.0399      1.125      0.035      0.972      -2.166       2.246\n#> ma.L3         -0.0131      0.349     -0.038      0.970      -0.697       0.670\n#> sigma2         0.0001   1.46e-06     87.390      0.000       0.000       0.000\n#> ===================================================================================\n#> Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):             17882.67\n#> Prob(Q):                              0.99   Prob(JB):                         0.00\n#> Heteroskedasticity (H):               0.95   Skew:                            -0.75\n#> Prob(H) (two-sided):                  0.45   Kurtosis:                        14.35\n#> ===================================================================================\n#> \n#> Warnings:\n#> [1] Covariance matrix calculated using the outer product of gradients (complex-step)."},{"path":"homework-1.html","id":"question-e-1","chapter":"Homework","heading":"Question e","text":"Use ARCH\\((1)\\), GARCH\\((1,1)\\) t-GARCH\\((1,1)\\) fit \nvolatility returns give conclusions.AIC t-GARCH\\((1,1)\\) smallest can conclude t-GARCH\\((1,1)\\) best model.","code":"# ARCH(1)\nimport arch\nfrom arch import arch_model\narch_fit = arch_model(y, mean = 'Zero', \n                         vol = 'ARCH', \n                         q = 1).fit()#> Iteration:      1,   Func. Count:      4,   Neg. LLF: -7592.8746576983285\n#> Iteration:      2,   Func. Count:     10,   Neg. LLF: -9873.7669996417\n#> Iteration:      3,   Func. Count:     15,   Neg. LLF: 4730401.0010247845\n#> Iteration:      4,   Func. Count:     21,   Neg. LLF: -10296.047927667008\n#> Iteration:      5,   Func. Count:     23,   Neg. LLF: -10296.047927666674\n#> Optimization terminated successfully    (Exit mode 0)\n#>             Current function value: -10296.047927667008\n#>             Iterations: 5\n#>             Function evaluations: 23\n#>             Gradient evaluations: 5print(arch_fit.summary())#>                         Zero Mean - ARCH Model Results                        \n#> ==============================================================================\n#> Dep. Variable:                      y   R-squared:                       0.000\n#> Mean Model:                 Zero Mean   Adj. R-squared:                  0.000\n#> Vol Model:                       ARCH   Log-Likelihood:                10296.0\n#> Distribution:                  Normal   AIC:                          -20588.1\n#> Method:            Maximum Likelihood   BIC:                          -20575.9\n#>                                         No. Observations:                 3273\n#> Date:                Thu, Mar 24 2022   Df Residuals:                     3273\n#> Time:                        16:39:20   Df Model:                            0\n#>                               Volatility Model                              \n#> ============================================================================\n#>                  coef    std err          t      P>|t|      95.0% Conf. Int.\n#> ----------------------------------------------------------------------------\n#> omega      7.9907e-05  4.727e-06     16.905  4.106e-64 [7.064e-05,8.917e-05]\n#> alpha[1]       0.3975  6.722e-02      5.914  3.348e-09     [  0.266,  0.529]\n#> ============================================================================\n#> \n#> Covariance estimator: robust# GARCH(1,1)\nimport arch\nfrom arch import arch_model\ngarch_fit = arch_model(y, \n                       mean = 'Zero', \n                       vol = 'GARCH',\n                       p = 1, \n                       q = 1).fit()#> Iteration:      1,   Func. Count:      5,   Neg. LLF: 3967.6568400522383\n#> Iteration:      2,   Func. Count:     14,   Neg. LLF: -10811.544183900245\n#> Optimization terminated successfully    (Exit mode 0)\n#>             Current function value: -10811.544186499636\n#>             Iterations: 6\n#>             Function evaluations: 14\n#>             Gradient evaluations: 2print(garch_fit.summary())#>                        Zero Mean - GARCH Model Results                        \n#> ==============================================================================\n#> Dep. Variable:                      y   R-squared:                       0.000\n#> Mean Model:                 Zero Mean   Adj. R-squared:                  0.000\n#> Vol Model:                      GARCH   Log-Likelihood:                10811.5\n#> Distribution:                  Normal   AIC:                          -21617.1\n#> Method:            Maximum Likelihood   BIC:                          -21598.8\n#>                                         No. Observations:                 3273\n#> Date:                Thu, Mar 24 2022   Df Residuals:                     3273\n#> Time:                        16:39:21   Df Model:                            0\n#>                               Volatility Model                              \n#> ============================================================================\n#>                  coef    std err          t      P>|t|      95.0% Conf. Int.\n#> ----------------------------------------------------------------------------\n#> omega      4.0254e-06  2.451e-10  1.642e+04      0.000 [4.025e-06,4.026e-06]\n#> alpha[1]       0.2008  4.872e-03     41.225      0.000     [  0.191,  0.210]\n#> beta[1]        0.7802  9.059e-03     86.132      0.000     [  0.762,  0.798]\n#> ============================================================================\n#> \n#> Covariance estimator: robust# t-GARCH(1,1)\nimport arch\nfrom arch import arch_model\ntgarch_fit = arch_model(y, \n                        mean = 'Zero', \n                        vol = 'GARCH',\n                        p = 1, \n                        q = 1, \n                        dist = 'StudentsT').fit()#> Iteration:      1,   Func. Count:      5,   Neg. LLF: -10902.36462172786\n#> Optimization terminated successfully    (Exit mode 0)\n#>             Current function value: -10902.36462175196\n#>             Iterations: 5\n#>             Function evaluations: 5\n#>             Gradient evaluations: 1print(tgarch_fit.summary())#>                           Zero Mean - GARCH Model Results                           \n#> ====================================================================================\n#> Dep. Variable:                            y   R-squared:                       0.000\n#> Mean Model:                       Zero Mean   Adj. R-squared:                  0.000\n#> Vol Model:                            GARCH   Log-Likelihood:                10902.4\n#> Distribution:      Standardized Student's t   AIC:                          -21796.7\n#> Method:                  Maximum Likelihood   BIC:                          -21772.4\n#>                                               No. Observations:                 3273\n#> Date:                      Thu, Mar 24 2022   Df Residuals:                     3273\n#> Time:                              16:39:22   Df Model:                            0\n#>                               Volatility Model                              \n#> ============================================================================\n#>                  coef    std err          t      P>|t|      95.0% Conf. Int.\n#> ----------------------------------------------------------------------------\n#> omega      2.6331e-06  6.349e-09    414.698      0.000 [2.621e-06,2.646e-06]\n#> alpha[1]       0.2000  1.803e-02     11.094  1.346e-28     [  0.165,  0.235]\n#> beta[1]        0.7800  1.543e-02     50.537      0.000     [  0.750,  0.810]\n#>                               Distribution                              \n#> ========================================================================\n#>                  coef    std err          t      P>|t|  95.0% Conf. Int.\n#> ------------------------------------------------------------------------\n#> nu             6.5511      0.173     37.951      0.000 [  6.213,  6.889]\n#> ========================================================================\n#> \n#> Covariance estimator: robust"},{"path":"homework-1.html","id":"r-9","chapter":"Homework","heading":"R","text":"can download SP500 data internet using R.","code":"\nlibrary(tseries)\nlibrary(zoo)\nprice = get.hist.quote(instrument = \"^gspc\",\n                       start = \"2009-01-01\",\n                       end = (\"2021-12-31\"),  \n                       quote = \"AdjClose\")#> time series starts 2009-01-02\n#> time series ends   2021-12-30"},{"path":"homework-1.html","id":"question-a-11","chapter":"Homework","heading":"Question a","text":"Denote \\(y\\) returns SP500. Plot returns calculate statistical characterizations returns (e.g., min, max, sd, skewness, kurtosis, acf), use Jarque Berra test, Box test.","code":"\n# Calculate returns y\nlibrary(tidyverse)\ny = price %>% \n  log %>% \n  diff\n# Plot the returns\ny %>% \n  plot\n# Statistical characterizations of returns\nlibrary(psych)\ny %>% \n  describe %>% \n  select(min,\n         max,\n         sd,\n         skew,\n         kurtosis)#>      min  max   sd  skew kurtosis\n#> X1 -0.13 0.09 0.01 -0.68    13.17\n# Plot ACF of the returns\ny %>% \n  coredata %>% \n  acf\n# Jarque Berra test\nlibrary(moments)\ny %>% \n  coredata %>% \n  c %>% \n  jarque.test#> \n#>  Jarque-Bera Normality Test\n#> \n#> data:  .\n#> JB = 23922, p-value < 2.2e-16\n#> alternative hypothesis: greater\n# Box test\nlibrary(stats)\ny %>% \n  Box.test(lag = 10, \n           type = \"Ljung-Box\")#> \n#>  Box-Ljung test\n#> \n#> data:  .\n#> X-squared = 180.1, df = 10, p-value < 2.2e-16"},{"path":"homework-1.html","id":"question-b-11","chapter":"Homework","heading":"Question b","text":"Use ADF test prices returns see series stationary.","code":"\n# Plot price\nprice %>% \n  plot\n# ADF test for prices\nlibrary(tseries)\nprice %>% \n  coredata %>%\n  adf.test#> Augmented Dickey-Fuller Test \n#> alternative: stationary \n#>  \n#> Type 1: no drift no trend \n#>       lag  ADF p.value\n#>  [1,]   0 2.96    0.99\n#>  [2,]   1 3.59    0.99\n#>  [3,]   2 3.25    0.99\n#>  [4,]   3 3.19    0.99\n#>  [5,]   4 3.46    0.99\n#>  [6,]   5 3.42    0.99\n#>  [7,]   6 3.77    0.99\n#>  [8,]   7 3.28    0.99\n#>  [9,]   8 3.62    0.99\n#> Type 2: with drift no trend \n#>       lag  ADF p.value\n#>  [1,]   0 1.25    0.99\n#>  [2,]   1 1.73    0.99\n#>  [3,]   2 1.48    0.99\n#>  [4,]   3 1.41    0.99\n#>  [5,]   4 1.62    0.99\n#>  [6,]   5 1.57    0.99\n#>  [7,]   6 1.80    0.99\n#>  [8,]   7 1.46    0.99\n#>  [9,]   8 1.67    0.99\n#> Type 3: with drift and trend \n#>       lag    ADF p.value\n#>  [1,]   0 -1.238   0.900\n#>  [2,]   1 -0.564   0.979\n#>  [3,]   2 -0.906   0.952\n#>  [4,]   3 -0.951   0.947\n#>  [5,]   4 -0.667   0.974\n#>  [6,]   5 -0.691   0.971\n#>  [7,]   6 -0.351   0.989\n#>  [8,]   7 -0.794   0.962\n#>  [9,]   8 -0.452   0.984\n#> ---- \n#> Note: in fact, p.value = 0.01 means p.value <= 0.01\n# Plot the returns\ny %>% \n  plot\n# ADF test for returns\nlibrary(tseries)\ny %>% \n  coredata %>%\n  adf.test#> Augmented Dickey-Fuller Test \n#> alternative: stationary \n#>  \n#> Type 1: no drift no trend \n#>       lag   ADF p.value\n#>  [1,]   0 -65.9    0.01\n#>  [2,]   1 -40.3    0.01\n#>  [3,]   2 -33.1    0.01\n#>  [4,]   3 -29.5    0.01\n#>  [5,]   4 -26.1    0.01\n#>  [6,]   5 -25.6    0.01\n#>  [7,]   6 -21.3    0.01\n#>  [8,]   7 -21.2    0.01\n#>  [9,]   8 -19.2    0.01\n#> Type 2: with drift no trend \n#>       lag   ADF p.value\n#>  [1,]   0 -66.1    0.01\n#>  [2,]   1 -40.4    0.01\n#>  [3,]   2 -33.3    0.01\n#>  [4,]   3 -29.6    0.01\n#>  [5,]   4 -26.3    0.01\n#>  [6,]   5 -25.8    0.01\n#>  [7,]   6 -21.5    0.01\n#>  [8,]   7 -21.5    0.01\n#>  [9,]   8 -19.4    0.01\n#> Type 3: with drift and trend \n#>       lag   ADF p.value\n#>  [1,]   0 -66.1    0.01\n#>  [2,]   1 -40.4    0.01\n#>  [3,]   2 -33.3    0.01\n#>  [4,]   3 -29.6    0.01\n#>  [5,]   4 -26.3    0.01\n#>  [6,]   5 -25.8    0.01\n#>  [7,]   6 -21.5    0.01\n#>  [8,]   7 -21.5    0.01\n#>  [9,]   8 -19.4    0.01\n#> ---- \n#> Note: in fact, p.value = 0.01 means p.value <= 0.01"},{"path":"homework-1.html","id":"question-c-6","chapter":"Homework","heading":"Question c","text":"Using AR\\((1)\\) fit price returns y find coefficients fitted AR\\((1)\\) model.Note residuals mean zero, forecasts biased. Now using fact can check mean residuals AR\\((1)\\) price return see can apply AR\\((1)\\) directly price.Check independence residuals fitted AR\\((1)\\), independence ?ACF significant many lags residuals AR\\((1)\\) returns correlated thus independence.","code":"\n# Using AR(1) to fit the price\nlibrary(stats)\nar1_price = price %>%\n  arima(c(1,0,0))\n# Find the coefficients of the fitted AR(1) model\nar1_price %>%\n  coefficients#>          ar1    intercept \n#>    0.9999917 2159.3788250\n# Using AR(1) to fit the returns\nlibrary(stats)\nar1_y = y %>% \n  arima(c(1,0,0))\n# Find the coefficients of the fitted AR(1) model\nar1_y %>% \n  coefficients#>           ar1     intercept \n#> -0.1576312868  0.0005086707\n# Check the mean of residuals\nar1_price %>% \n  residuals %>% \n  coredata %>% \n  na.omit %>% \n  mean#> [1] 1.131751\n# Check the mean of residuals\nar1_y %>% \n  residuals %>% \n  coredata %>% \n  na.omit %>% \n  mean#> [1] -3.824746e-06\n# Plot ACF of the residuals\nlibrary(stats)\nar1_y %>% \n  residuals %>% \n  coredata %>% \n  na.omit %>% \n  acf"},{"path":"homework-1.html","id":"question-d-2","chapter":"Homework","heading":"Question d","text":"Fit returns ARMA\\((3,3)\\), compare AR\\((1)\\) , can conclude \nARMA\\((3,3)\\) better AR\\((1)\\)?AIC ARMA\\((3,3)\\) less AIC AR\\((1)\\) can conclude ARMA\\((3,3)\\) better AR\\((1)\\).","code":"\n# Fit the returns by ARMA(3,3)\nlibrary(stats)\narma33_y = y %>%\n  arima(c(3,0,3))\narma33_y$aic < ar1_y$aic#> [1] TRUE"},{"path":"homework-1.html","id":"question-e-2","chapter":"Homework","heading":"Question e","text":"Use ARCH\\((1)\\), GARCH\\((1,1)\\) t-GARCH\\((1,1)\\) (using package rugarch) fit \nvolatility returns give conclusions.AIC t-GARCH\\((1,1)\\) smallest can conclude t-GARCH\\((1,1)\\) best model.","code":"\n# ARCH(1)\nlibrary(fGarch)\narch.fit = garchFit(~garch(1,0), data = y, trace = F)\nsummary(arch.fit)#> \n#> Title:\n#>  GARCH Modelling \n#> \n#> Call:\n#>  garchFit(formula = ~garch(1, 0), data = y, trace = F) \n#> \n#> Mean and Variance Equation:\n#>  data ~ garch(1, 0)\n#> <environment: 0x7fc59153aae8>\n#>  [data = y]\n#> \n#> Conditional Distribution:\n#>  norm \n#> \n#> Coefficient(s):\n#>         mu       omega      alpha1  \n#> 8.6504e-04  7.8455e-05  4.1419e-01  \n#> \n#> Std. Errors:\n#>  based on Hessian \n#> \n#> Error Analysis:\n#>         Estimate  Std. Error  t value Pr(>|t|)    \n#> mu     8.650e-04   1.640e-04    5.276 1.32e-07 ***\n#> omega  7.845e-05   2.664e-06   29.452  < 2e-16 ***\n#> alpha1 4.142e-01   3.821e-02   10.839  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Log Likelihood:\n#>  10305.09    normalized:  3.15044 \n#> \n#> Description:\n#>  Thu Mar 24 16:39:26 2022 by user:  \n#> \n#> \n#> Standardised Residuals Tests:\n#>                                 Statistic p-Value    \n#>  Jarque-Bera Test   R    Chi^2  4427.257  0          \n#>  Shapiro-Wilk Test  R    W      0.9298395 0          \n#>  Ljung-Box Test     R    Q(10)  22.19605  0.01413642 \n#>  Ljung-Box Test     R    Q(15)  31.72511  0.007016061\n#>  Ljung-Box Test     R    Q(20)  39.5145   0.005750492\n#>  Ljung-Box Test     R^2  Q(10)  663.3026  0          \n#>  Ljung-Box Test     R^2  Q(15)  880.8894  0          \n#>  Ljung-Box Test     R^2  Q(20)  1068.422  0          \n#>  LM Arch Test       R    TR^2   427.7749  0          \n#> \n#> Information Criterion Statistics:\n#>       AIC       BIC       SIC      HQIC \n#> -6.299046 -6.293458 -6.299048 -6.297045\n# GARCH(1,1)\nlibrary(rugarch)\ngarch_spec = ugarchspec(variance.model = list(model = \"sGARCH\",\n                                           garchOrder = c(1,1)),\n                       mean.model = list(armaOrder = c(0,0),\n                                       include.mean = T,\n                                       distribution.model = \"norm\"))\ngarch_fit = ugarchfit(garch_spec, y %>% coredata %>% c)\ngarch_fit#> \n#> *---------------------------------*\n#> *          GARCH Model Fit        *\n#> *---------------------------------*\n#> \n#> Conditional Variance Dynamics    \n#> -----------------------------------\n#> GARCH Model  : sGARCH(1,1)\n#> Mean Model   : ARFIMA(0,0,0)\n#> Distribution : norm \n#> \n#> Optimal Parameters\n#> ------------------------------------\n#>         Estimate  Std. Error  t value Pr(>|t|)\n#> mu      0.000805    0.000129   6.2607 0.000000\n#> omega   0.000003    0.000001   2.6538 0.007958\n#> alpha1  0.170394    0.014539  11.7194 0.000000\n#> beta1   0.802782    0.015565  51.5761 0.000000\n#> \n#> Robust Standard Errors:\n#>         Estimate  Std. Error  t value Pr(>|t|)\n#> mu      0.000805    0.000185   4.3598 0.000013\n#> omega   0.000003    0.000008   0.4560 0.648389\n#> alpha1  0.170394    0.025679   6.6356 0.000000\n#> beta1   0.802782    0.058438  13.7374 0.000000\n#> \n#> LogLikelihood : 10826.74 \n#> \n#> Information Criteria\n#> ------------------------------------\n#>                     \n#> Akaike       -6.6174\n#> Bayes        -6.6099\n#> Shibata      -6.6174\n#> Hannan-Quinn -6.6147\n#> \n#> Weighted Ljung-Box Test on Standardized Residuals\n#> ------------------------------------\n#>                         statistic p-value\n#> Lag[1]                      4.129 0.04216\n#> Lag[2*(p+q)+(p+q)-1][2]     4.271 0.06377\n#> Lag[4*(p+q)+(p+q)-1][5]     5.361 0.12664\n#> d.o.f=0\n#> H0 : No serial correlation\n#> \n#> Weighted Ljung-Box Test on Standardized Squared Residuals\n#> ------------------------------------\n#>                         statistic p-value\n#> Lag[1]                     0.3257  0.5682\n#> Lag[2*(p+q)+(p+q)-1][5]    2.0941  0.5964\n#> Lag[4*(p+q)+(p+q)-1][9]    2.8388  0.7853\n#> d.o.f=2\n#> \n#> Weighted ARCH LM Tests\n#> ------------------------------------\n#>             Statistic Shape Scale P-Value\n#> ARCH Lag[3]  0.009343 0.500 2.000  0.9230\n#> ARCH Lag[5]  0.933101 1.440 1.667  0.7529\n#> ARCH Lag[7]  1.242758 2.315 1.543  0.8712\n#> \n#> Nyblom stability test\n#> ------------------------------------\n#> Joint Statistic:  3.0795\n#> Individual Statistics:              \n#> mu     0.06252\n#> omega  0.06964\n#> alpha1 0.34031\n#> beta1  0.80804\n#> \n#> Asymptotic Critical Values (10% 5% 1%)\n#> Joint Statistic:          1.07 1.24 1.6\n#> Individual Statistic:     0.35 0.47 0.75\n#> \n#> Sign Bias Test\n#> ------------------------------------\n#>                    t-value      prob sig\n#> Sign Bias           3.0094 2.637e-03 ***\n#> Negative Sign Bias  0.6287 5.296e-01    \n#> Positive Sign Bias  1.6317 1.028e-01    \n#> Joint Effect       24.5022 1.962e-05 ***\n#> \n#> \n#> Adjusted Pearson Goodness-of-Fit Test:\n#> ------------------------------------\n#>   group statistic p-value(g-1)\n#> 1    20     151.8    9.633e-23\n#> 2    30     174.9    8.735e-23\n#> 3    40     195.7    9.306e-23\n#> 4    50     222.6    5.796e-24\n#> \n#> \n#> Elapsed time : 0.21032\n# TGARCH(1,1)\nlibrary(rugarch)\ntgarch_spec = ugarchspec(variance.model = list(model = \"sGARCH\",\n                                           garchOrder = c(1,1)),\n                       mean.model = list(armaOrder = c(0,0),\n                                       include.mean = T,\n                                       distribution.model = \"std\"))\ntgarch_fit = ugarchfit(tgarch_spec, y %>% coredata %>% c)\ntgarch_fit#> \n#> *---------------------------------*\n#> *          GARCH Model Fit        *\n#> *---------------------------------*\n#> \n#> Conditional Variance Dynamics    \n#> -----------------------------------\n#> GARCH Model  : sGARCH(1,1)\n#> Mean Model   : ARFIMA(0,0,0)\n#> Distribution : norm \n#> \n#> Optimal Parameters\n#> ------------------------------------\n#>         Estimate  Std. Error  t value Pr(>|t|)\n#> mu      0.000805    0.000129   6.2607 0.000000\n#> omega   0.000003    0.000001   2.6538 0.007958\n#> alpha1  0.170394    0.014539  11.7194 0.000000\n#> beta1   0.802782    0.015565  51.5761 0.000000\n#> \n#> Robust Standard Errors:\n#>         Estimate  Std. Error  t value Pr(>|t|)\n#> mu      0.000805    0.000185   4.3598 0.000013\n#> omega   0.000003    0.000008   0.4560 0.648389\n#> alpha1  0.170394    0.025679   6.6356 0.000000\n#> beta1   0.802782    0.058438  13.7374 0.000000\n#> \n#> LogLikelihood : 10826.74 \n#> \n#> Information Criteria\n#> ------------------------------------\n#>                     \n#> Akaike       -6.6174\n#> Bayes        -6.6099\n#> Shibata      -6.6174\n#> Hannan-Quinn -6.6147\n#> \n#> Weighted Ljung-Box Test on Standardized Residuals\n#> ------------------------------------\n#>                         statistic p-value\n#> Lag[1]                      4.129 0.04216\n#> Lag[2*(p+q)+(p+q)-1][2]     4.271 0.06377\n#> Lag[4*(p+q)+(p+q)-1][5]     5.361 0.12664\n#> d.o.f=0\n#> H0 : No serial correlation\n#> \n#> Weighted Ljung-Box Test on Standardized Squared Residuals\n#> ------------------------------------\n#>                         statistic p-value\n#> Lag[1]                     0.3257  0.5682\n#> Lag[2*(p+q)+(p+q)-1][5]    2.0941  0.5964\n#> Lag[4*(p+q)+(p+q)-1][9]    2.8388  0.7853\n#> d.o.f=2\n#> \n#> Weighted ARCH LM Tests\n#> ------------------------------------\n#>             Statistic Shape Scale P-Value\n#> ARCH Lag[3]  0.009343 0.500 2.000  0.9230\n#> ARCH Lag[5]  0.933101 1.440 1.667  0.7529\n#> ARCH Lag[7]  1.242758 2.315 1.543  0.8712\n#> \n#> Nyblom stability test\n#> ------------------------------------\n#> Joint Statistic:  3.0795\n#> Individual Statistics:              \n#> mu     0.06252\n#> omega  0.06964\n#> alpha1 0.34031\n#> beta1  0.80804\n#> \n#> Asymptotic Critical Values (10% 5% 1%)\n#> Joint Statistic:          1.07 1.24 1.6\n#> Individual Statistic:     0.35 0.47 0.75\n#> \n#> Sign Bias Test\n#> ------------------------------------\n#>                    t-value      prob sig\n#> Sign Bias           3.0094 2.637e-03 ***\n#> Negative Sign Bias  0.6287 5.296e-01    \n#> Positive Sign Bias  1.6317 1.028e-01    \n#> Joint Effect       24.5022 1.962e-05 ***\n#> \n#> \n#> Adjusted Pearson Goodness-of-Fit Test:\n#> ------------------------------------\n#>   group statistic p-value(g-1)\n#> 1    20     151.8    9.633e-23\n#> 2    30     174.9    8.735e-23\n#> 3    40     195.7    9.306e-23\n#> 4    50     222.6    5.796e-24\n#> \n#> \n#> Elapsed time : 0.360929"},{"path":"sem-2-2020-2021.html","id":"sem-2-2020-2021","chapter":"14 Sem 2 2020-2021","heading":"14 Sem 2 2020-2021","text":"","code":""},{"path":"sem-2-2020-2021.html","id":"problem-1-2","chapter":"14 Sem 2 2020-2021","heading":"Problem 1","text":"prices dividends stock given follows.","code":""},{"path":"sem-2-2020-2021.html","id":"question-a-12","chapter":"14 Sem 2 2020-2021","heading":"Question a","text":"Determine \\(R_2\\) \\(R_4(3)\\).\\[\\begin{align*}\nR_2&=\\frac{P_2-P_1+d_2}{P_1} \\\\\n&=\\frac{85-82+0.1}{82} \\\\\n&=0.038 \\\\\nR_3&=\\frac{P_3-P_2+d_3}{P_2} \\\\\n&=\\frac{83-85+0.1}{85} \\\\\n&=-0.022 \\\\\nR_4&=\\frac{P_4-P_3+d_4}{P_3} \\\\\n&=\\frac{87-83+0.125}{83} \\\\\n&=0.050 \\\\\n\\end{align*}\\]\\[\\begin{align*}\nR_4(3)&=(1+R_4)(1+R_3)(1+R_2)-1 \\\\\nR_4(3)&=(1+0.038)(1-0.022)(1+0.050)-1 \\\\\n&\\approx 0.066\n\\end{align*}\\]Answer: \\(R_2 \\approx 0.042\\) \\(R_4(3) \\approx 0.148\\).","code":""},{"path":"sem-2-2020-2021.html","id":"question-b-12","chapter":"14 Sem 2 2020-2021","heading":"Question b","text":"Determine \\(r_3\\).\\[\\begin{align*}\nr_3&=\\ln(1+R_3) \\\\\n&\\approx R_3 \\\\\n&\\approx-0.022\n\\end{align*}\\]Answer: \\(r_3 \\approx -0.022\\)","code":""},{"path":"sem-2-2020-2021.html","id":"problem-2-2","chapter":"14 Sem 2 2020-2021","heading":"Problem 2","text":"daily log returns stock normally distributed mean \\(0.001\\) standard deviation \\(0.02\\). stock price now \\(\\$99\\). probability exceed \\(\\$103\\) \\(10\\) trading days?\\[\\begin{align*}\n\\ln \\left( \\frac{P_{10}}{P_0} \\right) &= r_{10}(10) \\\\\n\\ln  P_{10} - \\ln P_0 &= \\sum_{t=1}^{10}r_t \\\\\n&\\sim 10 \\cdot \\mathcal{N}(0.001, 0.02^2) \\\\\n&\\sim  \\mathcal{N}(10 \\cdot 0.001, 10 \\cdot 0.02^2) \\\\\n\\end{align*}\\]\\[\\begin{align*}\n\\rightarrow \\ln(P_{10})&=\\ln(P_{0})+r_{10}(10) \\\\\n&\\sim \\ln(99)+\\mathcal{N}(10 \\cdot 0.001, 10 \\cdot 0.02^2) \\\\\n&\\sim \\mathcal{N}(\\ln(99)+10 \\cdot 0.001, 10 \\cdot 0.02^2) \\\\\n\\end{align*}\\]\\[\\begin{align*}\n\\mathcal{P}(P_{10}>103)&=\\mathcal{P}(\\ln(P_{10})>\\ln(103)) \\\\\n&=\\mathcal{P} \\left(\\frac{\\ln(P_{10})-(\\ln(99)+10 \\cdot 0.001)}{\\sqrt{10 \\cdot 0.02^2}} > \\frac{\\ln(103)-(\\ln(99)+10 \\cdot 0.001)}{\\sqrt{10 \\cdot 0.02^2}} \\right) \\\\\n&=\\mathcal{P} \\left(\\mathcal{Z} > \\frac{\\ln(103)-(\\ln(99)+10 \\cdot 0.001)}{\\sqrt{10 \\cdot 0.02^2}} \\right) \\\\\n&=\\mathcal{P} \\left(\\mathcal{Z} < -\\frac{\\ln(103)-(\\ln(99)+10 \\cdot 0.001)}{\\sqrt{10 \\cdot 0.02^2}} \\right) \\\\\n&=0.31983\n\\end{align*}\\]Answer: probability price exceeds \\(\\$103\\) 10 trading days 31.983%.","code":""},{"path":"sem-2-2020-2021.html","id":"problem-3-2","chapter":"14 Sem 2 2020-2021","heading":"Problem 3","text":"Write definition weakly stationary process.process weakly stationary mean, variance, covariance unchanged time shifts. precisely, \\(X_1, X_2, ...\\) weakly stationary process \\(\\mathbb{E}(X_t)=\\mu, \\forall t\\)\\(Var(X_t) = \\sigma_2\\) (positive finite constant) \\(t\\).\\(Cov(X_t, X_s) = \\gamma(|t − s|), \\forall t, s\\) function \\(\\gamma\\).Write first-order Autoregressive model (\\(AR(1)\\)) time series \\(X_t\\). Write formulas mean \\(\\mathbb{E}(X_t)\\), variance \\(Var(X_t)\\) correlation function \\(\\rho(h)\\) observations \\(h\\) time periods, find condition \\(X_t\\) weakly stationary.time series \\(X = (X_t)\\) called AR(1) value X time t linear function value \\(X\\) time \\(t − 1\\) follows\n\\[X_t=\\delta+\\phi_1 X_{t-1}+w_t\\]errors \\(w_t \\sim \\mathcal{N}(0,\\sigma_w^2)\\) ..d.\\(w_t\\) independent \\(X_t\\).\\(\\phi_1<1\\). condition guarantees \\(X_t\\) weakly stationary.\\[\\begin{align*}\n&\\mu=\\mathbb{E}(X_t)=\\frac{\\delta}{1-\\phi_1} \\\\\n\\\\\n&Var(X_t)=\\frac{\\sigma_w^2}{1-\\phi_1^2} \\\\\n\\\\\n&Cov(X_t,X_{t+h})=\\gamma(h)=\\phi_1^h \\cdot \\frac{\\sigma_w^2}{1-\\phi_1^2} \\\\\n\\\\\n&\\rho(h)=\\phi_1^h\n\\end{align*}\\]","code":""},{"path":"sem-2-2020-2021.html","id":"problem-4-2","chapter":"14 Sem 2 2020-2021","heading":"Problem 4","text":"Assume price asset close trading yesterday \\(\\$110\\) volatility estimated \\(1.1\\%\\) per day. price close trading today \\(\\$108.5\\). Update volatility estimate using following methods:","code":""},{"path":"sem-2-2020-2021.html","id":"question-a-13","chapter":"14 Sem 2 2020-2021","heading":"Question a","text":"EWMA \\(\\lambda=0.9\\).\\[\\begin{align*}\n\\widehat{\\sigma}_t^2 &=\\lambda\\cdot\\widehat{\\sigma}_{t-1}^2+(1-\\lambda)\\cdot y_{t-1}^2 \\\\\n&=0.9\\cdot0.011^2+(1-0.9)\\cdot\\left( \\ln \\frac{108.5}{110}\\right)^2 \\\\\n\\rightarrow \\widehat{\\sigma}_t &\\approx0.0113\n\\end{align*}\\]Answer: volatility estimate using EWMA \\(\\lambda=0.9\\) \\(1.13\\%\\).","code":""},{"path":"sem-2-2020-2021.html","id":"question-b-13","chapter":"14 Sem 2 2020-2021","heading":"Question b","text":"GARCH\\((1,1)\\) model \\(\\omega=1\\cdot10^{-6},\\alpha=0.05,\\beta=0.94\\).\\[\\begin{align*}\n\\widehat{\\sigma}_t^2 &=\\omega+\\alpha\\cdot y_{t-1}^2+\\beta\\cdot\\widehat{\\sigma}_{t-1}^2 \\\\\n&=1\\cdot10^{-6}+0.05\\cdot\\left( \\ln \\frac{108.5}{110}\\right)^2+0.94\\cdot0.011^2 \\\\\n\\rightarrow \\widehat{\\sigma}_t &\\approx0.0111\n\\end{align*}\\]Answer: volatility estimate using GARCH\\((1,1)\\) model given parameters \\(1.11\\%\\).","code":""},{"path":"sem-2-2020-2021.html","id":"problem-5-2","chapter":"14 Sem 2 2020-2021","heading":"Problem 5","text":"loss \\(L\\) investment probability distributionCompute Value--Risk confidence level \\(\\alpha = 99 \\%\\)cumulative distribution function loss \\(L\\) \n\\[\\begin{align*}\nF(x) &=\\begin{cases}\n0 & x \\leq -200 \\\\\n0.1681 & -200 \\leq x \\leq -150 \\\\\n0.1681+0.3602 & -150 \\leq x \\leq 0 \\\\\n0.1681+0.3602+0.3087 & 0 \\leq x \\leq 50 \\\\\n0.1681+0.3602+0.3087+0.1323 & 50 \\leq x \\leq 100 \\\\\n0.1681+0.3602+0.3087+0.1323+0.0284 & 100 \\leq x \\leq170 \\\\\n0.1681+0.3602+0.3087+0.1323+0.0284+0.0023 & 170 \\leq x \\\\\n\\end{cases} \\\\\n&=\\begin{cases}\n0 & x \\leq -200 \\\\\n0.1681 & -200 \\leq x \\leq -150 \\\\\n0.5283 & -150 \\leq x \\leq 0 \\\\\n0.837 & 0 \\leq x \\leq 50 \\\\\n0.9693 & 50 \\leq x \\leq 100 \\\\\n0.9977 & 100 \\leq x \\leq170 \\\\\n1 & 170 \\leq x \\\\\n\\end{cases}\n\\end{align*}\\]\\[VaR_{0.99}(L_{100}) = \\inf \\{ x:F_L(x) \\geq 0.99 \\} = 100 \\]Answer: \\(VaR_{0.99}(L_{100})=100\\)","code":""},{"path":"sem-2-2020-2021.html","id":"problem-6-2","chapter":"14 Sem 2 2020-2021","heading":"Problem 6","text":"hold portfolio consisting long position 1 share stock \\(S\\). stock price today \\(P_0=\\$100\\). Let \\(X_t\\) denote log return day \\(t\\). daily log returns assumed independent normally distributed zero mean standard deviation \\(\\sigma = 0.1\\). Let \\(L_{100}\\) denote loss today 100 trading days deciding portfolio.Prove \\(L_{100} = -P_0(e^{\\sum_{=1}^{100}}-1).\\)\\[\\begin{align*}\n-P_0(e^{\\sum_{=1}^{100} X_i}-1) &= P_0 - P_0e^{X_1+X_2+...+X_{100}} \\\\\n&= P_0 - P_0e^{\\sum_{=1}^{100} \\ln \\frac{P_1}{P_0} + \\ln \\frac{P_2}{P_1}+...+\\ln \\frac{P_{100}}{P_{99}}} \\\\\n&= P_0 - P_0e^{ \\ln \\frac{P_{100}}{P_0}} \\\\\n&= P_0 - P_0 \\cdot \\frac{P_{100}}{P_0} \\\\\n&= P_0 - P_{100} \\\\\n&= L_{100}\n\\end{align*}\\]question ) compute \\(VaR_{0.99}(L_{100})\\)\\[\\begin{align*}\nL_{100} &= -P_0(e^{\\sum_{=1}^{100} X_i}-1) \\\\\n\\rightarrow \\ln \\left( 1 - \\frac{L_{100}}{P_0} \\right) &= \\sum_{=1}^{100} X_i \\\\\n& \\sim 100 \\cdot \\mathcal{N}(0,0.1^2) \\\\\n& \\sim  \\mathcal{N}(100 \\cdot 0,100 \\cdot 0.1^2) \\\\\n\\rightarrow 1 - \\frac{L_{100}}{P_0} &\\sim \\log \\mathcal{N}(100 \\cdot 0,100 \\cdot 0.1^2) \\\\\n\\rightarrow L_{100} &\\sim P_0 - P_0 \\cdot \\log \\mathcal{N}(100 \\cdot 0,100 \\cdot 0.1^2) \\\\\n\\rightarrow F_{L_{100}}(x) &= 100 - 100 \\cdot \\Phi \\left(\\frac{\\ln x - 100 \\cdot 0}{100 \\cdot 0.1^2} \\right)\n\\end{align*}\\]\\[\\begin{align*}\nF_{L_{100}}(x) &\\geq 0.99 \\\\\n\\rightarrow 100 - 100 \\cdot \\Phi \\left(\\frac{\\ln x - 100 \\cdot 0}{100 \\cdot 0.1^2} \\right) &\\geq 0.99 \\\\\n\\rightarrow \\Phi \\left(\\frac{\\ln x - 100 \\cdot 0}{100 \\cdot 0.1^2} \\right) &\\leq \\frac{100-0.99}{100} \\\\\n\\rightarrow \\frac{\\ln x - 100 \\cdot 0}{100 \\cdot 0.1^2} &\\leq \\Phi^{-1}(0.99) \\\\\n\\rightarrow x &\\leq e^{100 \\cdot 0 + 100 \\cdot 0.1^2 \\cdot \\Phi^{-1}(0.99)} \\\\\n\\end{align*}\\]\\[\\begin{align*}\nVaR_{0.99}(L_{100}) &= \\inf \\{x:F_{L_{100}}(x) \\geq 0.99  \\} \\\\\n&=e^{2.33}\n\\end{align*}\\]Answer: \\(VaR_{0.99}(L_{100})=e^{2.33}\\)","code":""},{"path":"type-of-tails.html","id":"type-of-tails","chapter":"15 Type of Tails","heading":"15 Type of Tails","text":"FRM focus principally events occur 1% 5%\nprobability. fine day--day applications financial institutions, methods GARCH historical\nsimulation well suited provide VaR purposes.risk analysis concerned negative observations lower tails, hence follow convention, can pre-multiply returns -1In risk applications, need focus entire distribution. Since care large losses, usually belong tails. example, GARCH modeling done entire distribution returns.EVT, hand, focuses explicitly analyzing tail regions distributions (.e., probability uncommon events).Furthermore, reason believe distribution returns symmetric; upper lower tails thickness shape. cases, upper tail returns thinner lower tail. example, upper tail return Microsoft thinner lower tail.EVT can useful situations enables us explicitly\nidentify type asymmetry extreme tails.risk applications need focus entire\ndistribution returns since care large losses,\nusually belong tails.main result EVT states , regardless overall shape\ndistribution,tails distributions fall one three\ncategories long distribution asset return series\nchange time. means risk applications\nneed focus one three categories:Weibull Thin tails distribution finite endpoint (e.g.,\ndistribution mortality insurance/re-insurance claims).Gumbel Tails decline exponentially (e.g., normal log-normal\ndistributions).Frechet Tails decline power law; tails known “fat\ntails” (e.g., Student-t Pareto distributions).following figure shows distributions Weibull, Gumbel \nFrechet distributionsFrom figure see : () Weibull clearly finite endpoint. (ii) Frechet tail thicker Gumbel’s.applications finance, know returns fat tailed","code":""},{"path":"gev-distribution.html","id":"gev-distribution","chapter":"16 GEV distribution","heading":"16 GEV distribution","text":"Quantitative financial risk management concerned maximal\nlosses (worst-case losses). Let Xi ..d distribution F\ncontinuous. block maximum given \\[M_n := \\max(X_1,X_2,...,X_n)\\]","code":""},{"path":"gev-distribution.html","id":"maximum-domain-of-attraction","chapter":"16 GEV distribution","heading":"Maximum domain of attraction","text":"Suppose find normalizing sequences real numbers \\(c_n > 0\\) \n\\(d_n\\), \\(\\frac{M_n − d_n}{c_n}\\) converge distribution, .e.,\\[\\begin{align*}\nP\\left(\\frac{M_n-d_n}{c_n} \\leq x \\right) &= P(M_n \\leq c_nx+d_n) \\\\\n&= P(M_i \\leq c_nx+d_n,=1,2,...,n) \\\\\n&= F^n(c_nx+d_n) \\rightarrow H(x), n \\rightarrow \\infty\n\\end{align*}\\]\nnon-degenerate df \\(H\\) (unit jump). F \nmaximum domain attraction \\(H(F \\MDA(H))\\).","code":""},{"path":"gev-distribution.html","id":"the-standard-generalized-extreme-value-gev","chapter":"16 GEV distribution","heading":"The (standard) generalized extreme value (GEV)","text":"(standard) generalized extreme value (GEV)\ndistribution given \\[H_\\xi(x)=\\begin{equation}\n    \\begin{cases}\n      e^{-(1+ \\xi x)^{\\frac{1}{\\xi}}}, & \\xi \\neq 0 \\ \\\\\n      e^{e^{-x}}, & \\xi = 0\n    \\end{cases}\\,\n\\end{equation}\\]\\(1 + \\xi x > 0\\). Depending value \\(\\xi, H_{\\xi}\\) become one \nthree distributions:\\(\\xi > 0\\), \\(H_{\\xi}\\) Frechetif \\(\\xi < 0\\), \\(H_{\\xi}\\) Weibullif \\(\\xi = 0\\), \\(H_{\\xi}\\) GumbelFisher-Tippet Gnedenko theoremsThe theorems state maximum sample properly normalized IID random variables converges distribution one three possible distributions: Weibull, Gumbel FrechetLet \\(X_1, X_2, ..., X_T\\) denote IID random variables (RVs) term\nMT indicate maxima sample size \\(T\\)\nstandardized distribution maxima, \\(M_T := \\max(X_1, X_2, ..., X_T)\\), \\[\\lim_{T \\\\infty} P \\left( \\frac{M_T-a_T}{b_T} \\leq x \\right) = H(x)\\]constants \\(a_T\\) \\(b_T > 0\\) exist defined \\(a_T = T \\mathbb{E}(X_1)\\) \\(b_T = \\sqrt{Var(X_1)}\\)Example 1(Exponential distribution)\nLet \\(X_i \\sim Exp(\\lambda)\\), choosing \\(c_n = \\frac{1}{\\lambda}\\) \\(d_n = \\frac{\\log(n)}{\\lambda}\\), obtain\\[F^n(c_nx + d_n) = \\left(1 − \\frac{e^{−x}}{n} \\right)^n \\\\\n\\rightarrow e^(−e^{−x}) = H(x) (Gumbell)\\]Example 2. (Pareto distribution)\nLet \\(X_i\\) ..d Pareto distribution \\[F(x) = 1 − \\left( \\frac{\\kappa}{\\kappa +x} \\right)^{\\theta}, x \\geq 0, \\theta, \\kappa > 0\\]Chosing \\(c_n = \\frac{\\kappa n^{\\frac{1}{\\theta}}}{\\theta}\\) \\(d_n = \\kappa(n^{1θ }− 1)\\). get\n\\[F^n(c_nx+d_n)=\\left( 1+\\frac{-\\left(1+\\frac{x}{\\theta} \\right)^{-\\theta}}{n} \\right)^n \\\\\n\\rightarrow e^{-\\left( 1+\\frac{x}{\\theta} \\right)-\\theta}=H_{\\frac{1}{\\theta}}(x)\\]","code":""},{"path":"asset-returns-and-fat-tails.html","id":"asset-returns-and-fat-tails","chapter":"17 Asset returns and Fat tails","heading":"17 Asset returns and Fat tails","text":"term “fat tails” can several meanings, common “extreme outcomes occur frequently predicted normal distribution”.frequent definition one may encounter Kurtosis, always accurate indicating presence fat tails \\((Kur > 3)\\).kurtosis concerned sides distribution rather heaviness tails.","code":""},{"path":"asset-returns-and-fat-tails.html","id":"a-formal-definition-of-fat-tails","chapter":"17 Asset returns and Fat tails","heading":"A formal definition of fat tails","text":"formal definition fat tails comes regular variation\nRegular variation. random variable, X, distribution F fat\ntails varies regularly infinity; exists positive\nconstant > 0 :\n\\[\\lim_{t \\\\infty} \\frac{1-F(tx)}{1-F(t)} =x^{-t},x>0\\]","code":""},{"path":"asset-returns-and-fat-tails.html","id":"tail-distributions","chapter":"17 Asset returns and Fat tails","heading":"Tail distributions","text":"fat-tailed case, tail distribution Frechet:\n\\[H(x) = e^{−x^{−\\tau}}\\]Lemma. random variable X regular variation infinity (.e. fat tails) distribution function F satisfies following condition:\\[1 − F(x) = P(X > x) = Ax^{−\\tau} + o(x^{−\\tau})\\]\npositive constant , \\(x \\rightarrow \\infty\\).expression \\(o(x−\\tau\\)) remainder term Taylor-expansion \\(P(X > x)\\), consists terms type \\(Cx^{−\\tau}\\) constant C \\(j > \\tau\\)\\(x \\rightarrow \\infty\\) tails asymptotically Pareto distributed:\n\\[F(x) \\approx 1 - Ax^{-\\tau}\\]followng figure presents normal fat tail distribution respect \\(\\tau =2,4,6\\)","code":""},{"path":"asset-returns-and-fat-tails.html","id":"normal-and-fat-distributions","chapter":"17 Asset returns and Fat tails","heading":"Normal and fat distributions","text":"definition demonstrates fat tails defined rapidly tails distribution decline approach infinityAs tails become thicker, detect increasingly large observations impact calculation moments:\n\\[E(X^m) = \\int x^m f(x) \\,dx\\]\\(E(X^m)\\) exists positive \\(m\\), normal distribution, definition regular variation implies moments \\(m \\geq 1\\) defined fat-tailed data.","code":""},{"path":"evt-in-practice.html","id":"evt-in-practice","chapter":"18 EVT in practice","heading":"18 EVT in practice","text":"two main approachesBlock MaximaPeaks thresholds (POT)","code":""},{"path":"evt-in-practice.html","id":"block-maxima-approach","chapter":"18 EVT in practice","heading":"Block maxima approach","text":"approach follows directly regular variation definition\nestimate GEV dividing sample blocks using maxima blockThe procedure rather wasteful data relatively large sample needed accurate estimate estimation (maxima large blocks used).","code":""},{"path":"evt-in-practice.html","id":"peaks-over-thresholds-approach","chapter":"18 EVT in practice","heading":"Peaks over thresholds approach","text":"approach based models large observations exceed high threshold hence makes better use data extreme values.two common approaches POTFully parametric models (e.g. Generalized Pareto distribution \nGPD)Semi-parametric models (e.g. Hill estimator)","code":""},{"path":"evt-in-practice.html","id":"generalized-pareto-distribution","chapter":"18 EVT in practice","heading":"Generalized Pareto distribution","text":"Consider random variable \\(X\\), fix threshold \\(u\\) focus positive part \\(X − u\\)distribution \\(F_u(x)\\) ( called excess distribution u) defined follows\\[F_u(x) := P(X-u \\leq |X> u)=\\frac{F(x+u)-f(u)}{1-F(u)}\\]Mean excess function.\\(\\mathbb{E}(|X|) < \\infty\\) mean excess function \ndefined \n\\[e(u) := E(X − u | X > u)\\]Interpretation: \\(F_u\\) distribution excess loss \\(X − u\\) \\(u\\),\ngiven \\(X > u\\). \\(e(u)\\) mean \\(F_u\\) function \\(u\\).Interpretation: \\(F_u\\) distribution excess loss \\(X − u\\) \\(u\\),\ngiven \\(X > u\\). \\(e(u)\\) mean \\(F_u\\) function \\(u\\).continuous \\(X \\sim F\\) \\(\\mathbb{E}(X) < \\infty\\) following formula holds:\n\\[ES_{\\alpha} = e(VaR_{\\alpha}(X)) + VaR_{\\alpha}(X)\\]continuous \\(X \\sim F\\) \\(\\mathbb{E}(X) < \\infty\\) following formula holds:\n\\[ES_{\\alpha} = e(VaR_{\\alpha}(X)) + VaR_{\\alpha}(X)\\]Note \\(u\\) \\(VaR\\) \\(X\\) \\(F_u(x)\\) probability exceed \\(VaR\\) particular amount (shortfall) given \\(VaR\\) violated.Note \\(u\\) \\(VaR\\) \\(X\\) \\(F_u(x)\\) probability exceed \\(VaR\\) particular amount (shortfall) given \\(VaR\\) violated.key result \\(u \\rightarrow \\infty\\), \\(F_u(x)\\) converges Generalized Pareto distribution (GPD), say \\(G_{\\xi,\\beta}(x)\\)key result \\(u \\rightarrow \\infty\\), \\(F_u(x)\\) converges Generalized Pareto distribution (GPD), say \\(G_{\\xi,\\beta}(x)\\)\\[G_{\\xi,\\beta}(x)=\\begin{equation}\n  \\begin{cases}\n    1-(1+\\xi \\frac{x}{\\beta})^{\\frac{1}{\\xi}} & \\xi \\neq 0 \\\\\n    1-e^{\\frac{x}{\\beta}}, & \\xi = 0\n  \\end{cases}\\,\n\\end{equation}\\]\n\\(\\beta > 0\\) scale parameter, \\(\\xi\\) known shape. \\(x \\geq 0\\) \\(\\xi ≥ 0\\) \\(0 \\leq x \\leq −\\frac{\\beta}{\\xi}\\) ξ < 0.\\[G_{\\xi,\\beta}(x)=\\begin{equation}\n  \\begin{cases}\n    1-(1+\\xi \\frac{x}{\\beta})^{\\frac{1}{\\xi}} & \\xi \\neq 0 \\\\\n    1-e^{\\frac{x}{\\beta}}, & \\xi = 0\n  \\end{cases}\\,\n\\end{equation}\\]\n\\(\\beta > 0\\) scale parameter, \\(\\xi\\) known shape. \\(x \\geq 0\\) \\(\\xi ≥ 0\\) \\(0 \\leq x \\leq −\\frac{\\beta}{\\xi}\\) ξ < 0.Therefore need estimate shape \\(\\xi\\) scale \\(\\beta\\)\nparameters applying GDPTherefore need estimate shape \\(\\xi\\) scale \\(\\beta\\)\nparameters applying GDPRecall, certain values \\(\\xi\\) shape parameters, \\(G_{\\xi,\\beta}(x)\\) becomes one three distributions (Frechet (\\(\\xi > 0\\)); Weibull (\\(\\xi < 0\\)), Gumbel (\\(\\xi = 0\\))).Recall, certain values \\(\\xi\\) shape parameters, \\(G_{\\xi,\\beta}(x)\\) becomes one three distributions (Frechet (\\(\\xi > 0\\)); Weibull (\\(\\xi < 0\\)), Gumbel (\\(\\xi = 0\\))).Assume \\(F_u(x) = G_{\\xi,\\beta}(x), \\xi \\ 0\\), \\(u\\).Assume \\(F_u(x) = G_{\\xi,\\beta}(x), \\xi \\ 0\\), \\(u\\).obtain following GPD-based formula tail probabilities:obtain following GPD-based formula tail probabilities:\\[\\begin{align*}\n\\bar F(x) &= \\mathbb{P}(X>x) \\\\\n&= \\mathbb{P}(X>u) \\mathbb{P}(X>x|X>u) \\\\\n&= \\bar F(u) \\bar F_u(x-u) \\\\\n&= \\bar F(u) \\bar F_u(x-u) \\\\\n&= \\bar F(u) \\left(1+ \\xi \\frac{x-u}{\\beta} \\right)^{-\\frac{1}{\\xi}},x>u\n\\end{align*}\\]Assuming know \\[ \\bar F(u)\\], inverting formula \\(\\alpha \\geq F(u)\\) leads \\[\\begin{align*}\nVaR_{\\alpha}(X) &= F^{\\leftarrow}(\\alpha) \\\\\n&= u+ \\frac{\\beta}{\\xi} \\left[ \\frac{(1-\\alpha)^{-\\xi}}{\\bar F(u)} -1 \\right]\n\\end{align*}\\]\n\\[\\begin{align*}\nES_{\\alpha}(X) = \\frac{VaR_{\\alpha}(X)}{1-\\xi} + \\frac{\\beta-\\xi u}{1-\\xi}, \\xi<1\n\\end{align*}\\]","code":""},{"path":"evt-in-practice.html","id":"hill-method","chapter":"18 EVT in practice","heading":"Hill method","text":"approximation\n\\[\\begin{align*}\nF(x) = 1 − Ax^{−\\tau}\n\\end{align*}\\]\ntail index \\(−\\tau\\) can approximated Hill method given \n\\[\\begin{align*}\n\\hat \\xi = \\frac{1}{\\hat \\tau} = \\frac{1}{C_T} \\sum_{=1}^{C_T} \\log \\frac{x_{()}}{u}\n\\end{align*}\\]\n\\(C_T\\) number observations tail, \\(2 \\leq C_T \\leq T\\), \\(T \\rightarrrow \\infty\\) \\(C_T \\rightarrow \\infty\\), \\(\\frac{CT}{T} \\rightarrow 0\\), notation \\(x_()\\) indicates sorted data, maxima denoted x(1), second-largest observation \\(x_(2)\\).GPD, name suggests, general can applied\nthree types tailsHill method hand maximum domain \nattraction (MDA) Frechet distributionHence Hill method valid fat-tailed dataWe \\(\\bar F(x)=1-F(x) \\approx Ax^{-\\tau},x \\geq u\\). Estimate \\(\\tau\\) \\(\\hat \\tau\\), uu \\(x_{(C_T)}\\). (\\(C_T\\) sufficiently small)Note \\(=u \\bar F(u)\\), hence\n\\(\\hat = x_{(C_T)}^{\\hat \\tau} \\hat F(x_{(C_T)}^{\\hat \\tau}) \\approx x_{(C_T)}^{\\hat \\tau} \\frac{C_T}{T}\\). \\[\\hat F(x) = \\frac{C_T}{T}\\left( \\frac{x}{x_{(C_T)}} \\right)^{-\\hat \\tau}\\]\n\n\\[\\widehat {VaR}_{\\alpha} = \\left( \\frac{T}{C_T}(1-\\alpha) \\right)^{-\\frac{1}{\\tau}} x_{(C_T)}\\]\n\n\\[\\widehat {ES_\\alpha} = \\frac{\\hat \\tau}{\\hat \\tau-1} \\widehat{VaR_{\\alpha}}\\]","code":""},{"path":"homework-2.html","id":"homework-2","chapter":"Homework","heading":"Homework","text":"","code":""},{"path":"homework-2.html","id":"problem-1-3","chapter":"Homework","heading":"Problem 1","text":"Lebesgue\\(-\\)measurable function\n\\(L:(0,\\infty)\\rightarrow\\mathbb{R}\\) called slowly varying \\(\\infty\\) \n\\[\\lim_{x\\rightarrow\\infty}\\frac{L(tx)}{L(x)}=1,\\forall t>0\\] \ncalled regularly varying \\(\\infty\\) \n\\(\\alpha\\\\mathbb{R}\\) \n\\[\\lim_{x\\rightarrow\\infty}\\frac{L(tx)}{L(x)}=t^{\\alpha},\\forall t>0.\\]\nShow following functions slowly varying \\(\\infty:\\)","code":""},{"path":"homework-2.html","id":"question-a-14","chapter":"Homework","heading":"Question a","text":"\\(L(x)=2+\\cos(1/x),x>0.\\)\\(t>0,\\)\n\\[\\begin{align*}\n\\lim_{x\\rightarrow\\infty}\\frac{L(tx)}{L(x)}\n&=\\lim_{x\\rightarrow\\infty}\\frac{2+\\cos(1/tx)}{2+\\cos(1/x)} \\\\\n&=1.\n\\end{align*}\\]","code":""},{"path":"homework-2.html","id":"question-b-14","chapter":"Homework","heading":"Question b","text":"\\(L(x)=\\ln(x),x>0.\\)Show following functions regularly varying \\(\\infty:\\)\\(t>0,\\) L’Hospital rule\n\\[\\begin{align*}\n\\lim_{x\\rightarrow\\infty}\\frac{L(tx)}{L(x)} &= \\lim_{x\\rightarrow\\infty}\\frac{\\ln(tx)}{\\ln(x)} \\\\\n&=\\lim_{x\\rightarrow\\infty}\\left(\\left(\\frac{d}{dx}\\ln(tx)\\right):\\left(\\frac{d}{dx}\\ln(x)\\right)\\right)\\\\\n&= \\lim_{x\\rightarrow\\infty}\\left(\\left(\\frac{1}{tx}\\cdot t\\right):\\frac{1}{x}\\right) \\\\\n&=1.\n\\end{align*}\\]","code":""},{"path":"homework-2.html","id":"question-c-7","chapter":"Homework","heading":"Question c","text":"\\(h(x)=x^{-\\theta},x,\\theta>0.\\)\\(t>0,\\)\n\\[\\begin{align*}\n\\lim_{x\\rightarrow\\infty}\\frac{h(tx)}{h(x)}\n&=\\lim_{x\\rightarrow\\infty}\\frac{(tx)^{-\\theta}}{x^{-\\theta}} \\\\\n&=\\lim_{x\\rightarrow\\infty}t^{-\\theta} \\\\\n&=t^{-\\theta}=t^{\\alpha}\n\\end{align*}\\]\n\\(\\alpha=-\\theta.\\)","code":""},{"path":"homework-2.html","id":"question-d-3","chapter":"Homework","heading":"Question d","text":"\\(h(x)=(1+x)^{-\\theta},x>-1,\\theta>0.\\)\\(t>0,\\) L’Hospital rule\n\\[\\begin{align*}\n\\lim_{x\\rightarrow\\infty}\\frac{1+x}{1+tx}\n&=\\lim_{x\\rightarrow\\infty}\\left(\\left(\\frac{d}{dx}(1+x)\\right):\\left(\\frac{d}{dx}(1+tx)\\right)\\right) \\\\\n&=\\lim_{x\\rightarrow\\infty}\\frac{1}{t} \\\\\n&=\\frac{1}{t},\n\\end{align*}\\]\nimplying \n\\[\\begin{align*}\n\\lim_{x\\rightarrow\\infty}\\frac{L(tx)}{L(x)}\n&=\\lim_{x\\rightarrow\\infty}\\frac{(1+tx)^{-\\theta}}{(1+x)^{-\\theta}} \\\\\n&=\\left(\\lim_{x\\rightarrow\\infty}\\frac{1+x}{1+tx}\\right)^{\\theta} \\\\\n&=t^{-\\theta}=t^{\\alpha}\n\\end{align*}\\]\n\\(\\alpha=-\\theta.\\)","code":""},{"path":"homework-2.html","id":"problem-2-3","chapter":"Homework","heading":"Problem 2","text":"\\(\\xi<0\\) generalized extreme value (GEV)\ndistribution takes form\n\\[\\begin{align*}\nH_{\\xi}(x)=\\left\\{\\begin{matrix}\\exp(-(1+\\xi\\cdot x)^{-1/\\xi}) & x<-1/\\xi\\\\1 & x\\geq-1/\\xi\\end{matrix}\\right.\n\\end{align*}\\]\nreferred Weibull distribution, although differing \nstandard Weibull distribution used statistics actuarial science.\nAssume \\(X\\) distribution \\(H_{\\xi}\\) \\(Y=1+\\xi\\cdot X.\\)","code":""},{"path":"homework-2.html","id":"question-a-15","chapter":"Homework","heading":"Question a","text":"Derive distribution function Y domain.distribution function \\(Y\\) \n\\[\\begin{align*}\nF_Y(x)\n&= \\mathbb{P}(Y\\leq x) \\\\\n&= \\mathbb{P}(1+\\xi\\cdot X\\leq x) \\\\\n&=\\mathbb{P}\\left(X\\geq\\frac{x-1}{\\xi}\\right) \\\\\n&=1-H_{\\xi}\\left(\\frac{x-1}{\\xi}\\right)\\\\\n&= \\left\\{\\begin{matrix}1-\\exp(-(1+\\xi\\cdot(x-1)/\\xi)^{-1/\\xi}) & (x-1)/\\xi<-1/\\xi\\\\0 & (x-1)/\\xi\\geq-1/\\xi\\end{matrix}\\right.\\\\\n&= \\left\\{\\begin{matrix}0 & x\\leq0\\\\1-\\exp(-x^{-1/\\xi}) & x>0\\end{matrix}\\right..\n\\end{align*}\\]","code":""},{"path":"homework-2.html","id":"question-b-15","chapter":"Homework","heading":"Question b","text":"Verify \\(Y\\) standard Weibull distribution density\n\\[f_Y(y)=c\\gamma y^{\\gamma-1}\\exp(-cy^{\\gamma}),\\forall y>0\\] \n\\(c,\\gamma>0\\) parameters (determined) terms \\(\\xi.\\)density \\(Y\\) given \n\\[\\begin{align*}\nf_Y(y) &=\\frac{d}{dy}F_Y(y) \\\\\n&=(-1)^2\\cdot\\frac{-1}{\\xi}\\cdot y^{-1/\\xi-1}\\cdot\\exp(-y^{-1/\\xi}) \\\\\n&=c\\gamma y^{\\gamma-1}\\exp(-cy^{\\gamma})\n\\end{align*}\\]\n\n\\[\\left\\{\\begin{matrix}c\\gamma y^{\\gamma-1}=-y^{-1/\\xi-1}/\\xi\\\\-cy^{\\gamma}=-y^{-1/\\xi}\\end{matrix}\\right. \\\\ \\Rightarrow\\gamma=-\\frac{1}{\\xi},c=1.\\]","code":""},{"path":"homework-2.html","id":"problem-3-3","chapter":"Homework","heading":"Problem 3","text":"Let \\(X\\) random variable excess distribution\n\\[\\begin{align*}\nF(x)&=\\mathbb{P}(X-u\\leq x|X>u) \\\\\n&=1-c(k+x)^{-\\theta},\\forall x\\geq u\n\\end{align*}\\]\n\\(c,\\theta,u>0\\) \\(k\\\\mathbb{R}.\\) Let \\(\\alpha_1,\\alpha_2\\)\nsatisfy \\(F(u)<\\alpha_1\\leq\\alpha_2<1.\\)Assume \\(X\\) excess tail distribution\n\\(\\overline{F}(x)=1-F(x)=c(k+x)^{-\\theta}.\\) Since \\(F\\) continuous,\n\\[\\mathbb{P}(X\\leq VaR_{\\alpha}(X))=\\alpha\\hspace{4mm}\\text{}\\hspace{4mm}ES_{\\alpha}(X)=\\frac{1}{1-\\alpha}\\int_{\\alpha}^1VaR_{p}(X)dp,\\forall\\alpha\\[0,1].\\]","code":""},{"path":"homework-2.html","id":"question-a-16","chapter":"Homework","heading":"Question a","text":"Show \n\\[\\begin{equation}\n  VaR_{\\alpha_2}(X)=\\left(\\frac{1-\\alpha_1}{1-\\alpha_2}\\right)^{1/\\theta}(k+VaR_{\\alpha_1}(X))-k\n\\end{equation}\\]\n\n\\(VaR_{\\alpha}(X)=\\inf\\left\\{x:F(x)\\geq\\alpha\\right\\},\\forall\\alpha\\[0,1].\\)equalities\n\\[\\begin{align*}\n\\left(\\frac{k+VaR_{\\alpha_2}(X)}{k+VaR_{\\alpha_1}(X)}\\right)^{\\theta}\n&=\\frac{c(k+VaR_{\\alpha_1}(X))^{-\\theta}}{c(k+VaR_{\\alpha_2}(X))^{-\\theta}}\\\\\n&=\\frac{\\overline{F}(VaR_{\\alpha_1}(X))}{\\overline{F}(VaR_{\\alpha_2}(X))}\\\\\n&=\\frac{1-\\alpha_1}{1-\\alpha_2}\n\\end{align*}\\]\nclearly imply \\[\\begin{equation}\nVaR_{\\alpha_2}(X)=\\left(\\frac{1-\\alpha_1}{1-\\alpha_2}\\right)^{1/\\theta}(k+VaR_{\\alpha_1}(X))-k\n\\end{equation}.\\]","code":""},{"path":"homework-2.html","id":"question-b-16","chapter":"Homework","heading":"Question b","text":"Show \\(\\theta>1,\\) \n\\[ES_{\\alpha_2}(X)=\\frac{\\theta}{\\theta-1}\\cdot\\left(\\frac{1-\\alpha_1}{1-\\alpha_2}\\right)^{1/\\theta}(k+VaR_{\\alpha_1}(X))-k\\]\n\n\\(ES_{\\alpha}(X)=\\mathbb{E}(X|X\\geq VaR_{\\alpha}(X)),\\forall\\alpha\\[0,1].\\)part (),\n\\[VaR_{p}(X)=\\left(\\frac{1-\\alpha_1}{1-p}\\right)^{1/\\theta}(k+VaR_{\\alpha_1}(X))-k\\]\nhence \\[\\begin{aligned}\nES_{\\alpha_2}(X)\n&= \\frac{1}{1-\\alpha_2}\\int_{\\alpha_2}^1VaR_{p}(X)dp \\\\\n&=\\frac{1}{1-\\alpha_2}\\int_{\\alpha_2}^1\\left[\\left(\\frac{1-\\alpha_1}{1-p}\\right)^{1/\\theta}(k+VaR_{\\alpha_1}(X))-k\\right]dp\\\\\n&= \\frac{(1-\\alpha_1)^{1/\\theta}}{1-\\alpha_2}(k+VaR_{\\alpha_1}(X))\\int_{\\alpha_2}^1\\left(\\frac{1}{1-p}\\right)^{1/\\theta}dp-\\frac{1}{1-\\alpha_2}\\cdot\\int_{\\alpha_2}^1kdp\\\\\n&= \\frac{(1-\\alpha_1)^{1/\\theta}}{1-\\alpha_2}(k+VaR_{\\alpha_1}(X))\\cdot\\frac{\\theta}{\\theta-1}\\cdot\\frac{1}{(1-\\alpha_2)^{1/\\theta-1}}-k\\\\\n&= \\frac{\\theta}{\\theta-1}\\cdot\\left(\\frac{1-\\alpha_1}{1-\\alpha_2}\\right)^{1/\\theta}(k+VaR_{\\alpha_1}(X))-k\n\\end{aligned}\\] desired.","code":""}]
