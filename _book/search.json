[{"path":"index.html","id":"course-descripition","chapter":"Course Descripition","heading":"Course Descripition","text":"course provides students notions advanced tools statistics\nMathematics financial risk management e.g., time series\nmodels, copula theory Extreme Value Theory.","code":""},{"path":"index.html","id":"dr.-ta-quoc-bao","chapter":"Course Descripition","heading":"Dr. Ta Quoc Bao","text":"𝐇𝐮𝐦𝐚𝐧𝐬 𝐨𝐟 𝐌𝐀 |\n\n\n Dr. Ta Quoc Bao\n\n\n\n\n Academic Education BackgroundPh.D. Applied Mathematics, Åbo Akademi University, FinlandM.Sc. Probability Statistics, University Science, VNU-Hanoi, VietnamB.Sc. Probability Statistics, University Science, VNU-Hanoi, Vietnam\n Subjects InterestProbability, statistics & random processDifferential equationsFinancial risk management\nFun Facts️️\n\nbeloved teacher instructing students write academic publications related Econometrics.\nSince 2020, major medals\n\nFirst Price ️\n\nConsolation Price Olympic Econometrics.\ndetails right :\n\nhttps://www.facebook.com/fermyouthunion/posts/5965881330152078\n\n\ngentle approachableRemember awkward silence beginning lectures, Dr. Bao just like keeps asking students anything new. class, stories just easily start diets & fitness end international public health.\nyoungsters MA K21, even Zalo group chat. Somehow manages update news , share job opportunities , even closely interact within beloved FERMers.\nYes , just giving proper guidance quite sure career path.FERMers, usually come across education online courses, outdoor summer camps, quantitative trading competitions…\n\nExperienced Financial Bankings, colleagues just well likely data analyst, quantitative analyst, credit analyst explains numerous available employment possibility fast-forwarding career advice.can explore even funnier facts :\n\nhttps://math.hcmiu.edu.vn/user/tqbao/\n\ncan contact Dr. Ta Quoc Bao :\n Office: Room A2.606, International University, Thu Duc City, Ho Chi Minh City\n Email: baotq@hcmiu.edu.vn","code":""},{"path":"index.html","id":"course-references","chapter":"Course Descripition","heading":"Course References","text":".J. MacNeil, R. Frey P. Embrechts. Quantitative risk\nmanagement. Princeton University press. 2015J. Danielsson. Financial Risk Forecasting. Wiley Finance. 2011Allan M. Malz, Financial Risk Management: Models, History, \nInstitutions, Willey, 2011.","code":""},{"path":"returns.html","id":"returns","chapter":"1 Returns","heading":"1 Returns","text":"Let \\(P_t\\) denote price stock time \\(t\\). return relative change price financial asset given time interval, often represented percentage.","code":""},{"path":"returns.html","id":"simple-return","chapter":"1 Returns","heading":"1.1 Simple return","text":"simple return percentage change prices indicated R\n\\[ R_t=\\frac{P_t-P_{t-1}}{P_{t-1}}=\\frac{\\Delta P_t}{P_{t-1}} \\]n-period return given \n\\[\\begin{align*} R_t(n)&=\\frac{P_t}{P_{t-n}}-1\\\\\n&=\\frac{P_t}{P_{t-1}} \\times \\frac{P_{t-1}}{P_{t-2}} \\times ... \\times \\frac{P_{t-n+1}}{P_{t-n+2}}-1\\\\\n&=(1+R_t)(1+R_{t-1})(1+R_{t-2})...(1+R_{t-n+1})-1\n\\end{align*}\\]","code":""},{"path":"returns.html","id":"logarithm-return","chapter":"1 Returns","heading":"1.2 Logarithm return","text":"logarithm gross return called continuously compounded return\\[ Y_t(1)=\\log(1+R_t)=\\log \\left( \\frac{P_t}{P_{t-1}} \\right)=\\log(P_t)-\\log(P_{t-1}) \\]\\(n-period\\) return given \n\\[\\begin{align*}\nY_t(n)&=\\log(1+R_t(n)) \\\\\n&=\\log((1+R_t)(1+R_{t-1})(1+R_{t-2})...(1+R_{t-n+1})) \\\\\n&=\\log(1+R_t)+\\log(1+R_{t-1})+\\log(1+R_{t-2})...+\\log(1+R_{t-n+1})) \\\\\n&=Y_t+Y_{t-1}+Y_{t-2}+...+Y_{t-n+1}\n\\end{align*}\\]","code":""},{"path":"returns.html","id":"remark","chapter":"1 Returns","heading":"1.3 Remark","text":"","code":""},{"path":"returns.html","id":"approximation","chapter":"1 Returns","heading":"1.3.1 Approximation","text":"small price changes difference simple return log return small (negligible). Indeed, Taylor approximation \n\\[ \\log(1+x)=x-\\frac{x^2}{2}+\\frac{x^3}{3}+... \\approx x \\]Simple log-return approximately equal returns 10% since large difference \\(R_t\\) \\(Y_t\\) time observations goes zero \\(\\lim_{\\Delta t \\0} Y_t = R_t\\).\\[\\log(1000) − \\log(995) = 0.005012 \\approx \\frac{1000}{995} − 1 = 0.005025 \\\\\n\\log(1000) − \\log(885) = 0.12216 \\neq \\frac{1000}{885} − 1 = 0.12994\\]","code":""},{"path":"returns.html","id":"symmetry-property","chapter":"1 Returns","heading":"1.3.2 Symmetry property","text":"Continuous compounded return symmetry, Simple return . example\\[\\begin{align*}\n\\log \\left( \\frac{1000}{500} \\right) &=-\\log \\left( \\frac{500}{1000} \\right) \\\\\n\\frac{1000}{500}-1 &\\neq - \\left( \\frac{500}{1000}-1 \\right)\n\\end{align*}\\]","code":""},{"path":"returns.html","id":"portfolio-return","chapter":"1 Returns","heading":"1.3.3 Portfolio Return","text":"Consider portfolio \\(N\\) stocks simple returns \\(R_t\\),\\(\\) time \\(t\\), respectively. Denote \\(R_{t,p}\\) return portfolio time \\(t\\), \\(Y_t\\),\\(p\\) continuously compounded return portfolio time \\(t\\).simple return portfolio (proof!!!)\\[ R_{,p}=\\sum_{=1}^{N} \\omega_i R_{t,} \\]continuously compounded returns equality\\[\nY_{t,p}= \\log \\left( \\frac{P_{t,p}}{P_{t-1,p}} \\right) \\neq \\sum_{=1}^{n} \\omega_i \\left( \\frac{P_{t,}}{P_{t-1,}} \\right) =\\sum_{=1}^{n} \\omega_i Y_{t,}\n\\]However, difference compounded simple returns may significant small returns, e.g., daily return\n\\[Y_p=\\sum_{=1}^N \\omega_i R_i \\]\ntime observations goes 0, \n\\[\\lim_{\\Delta t \\0} Y_{t,p} = R_{t,p}\\], practice note thatSimple returns \n\nUsed accounting purposes.\n\n\nInvestors usually concerned simple returns.\n\n\nUsed accounting purposes.\n\nInvestors usually concerned simple returns.\nContinuously compounded returns advantages\n\nMathematics easier, see later.\n\n\nUsed derivatives pricing, e.g. Black–Scholes model.\n\n\nMathematics easier, see later.\n\nUsed derivatives pricing, e.g. Black–Scholes model.\n","code":""},{"path":"random-walk.html","id":"random-walk","chapter":"2 Random Walk","heading":"2 Random Walk","text":"Let sequence \\(X_1, X_2, ...,X_t\\) ..d random variables \\(S_0\\) arbitrary starting point \n\\[S_t=S_0+X_1+X_2+...+X_t \\]\nseries \\((S_t)_{t \\geq 0}\\) called random walk \\(X_1, X_2, ...,X_t\\) steps.","code":""},{"path":"random-walk.html","id":"simple-random-walk","chapter":"2 Random Walk","heading":"2.1 Simple random walk","text":"Let series \\((S_t)_{t \\geq 0}\\) random walk\n\\[S_t=S_0+X_1+X_2+...+X_t \\]\nsteps either \\(1\\) \\(-1\\) \\(50\\%\\) probability either value, set \\(S_{0}=0\\) random walk called simple random walk.","code":"\nlibrary(tidyverse)\nsimple=map(1:9,\n              ~sample(c(1,-1), \n                 size=250, \n                 replace=T,\n                 prob=c(0.5,0.5)) %>% \n              cumsum())\npar(mfrow=c(3,3))\nplots=simple %>% \n  map(\n      plot,         \n      type=\"l\", \n      col=\"blue\",\n      ylab=\"the accumulated money\")\npar(mfrow=c(3,3))\nplots=simple %>%\n  map(acf)"},{"path":"random-walk.html","id":"normal-random-walk","chapter":"2 Random Walk","heading":"2.2 Normal random walk","text":"Let series \\((S_t)_{t \\geq 0}\\) random walk\n\\[S_t=S_0+Z_1+Z_2+...+Z_t \\]\nsteps follow standard normal distribution, .e. \\(Z \\sim \\mathcal{N}(0,1)\\), random walk called normal random walk. \\(E[S_t|S_0]=S_0\\) \\(\\mathbb{Var}(S_t|S_0)=\\sigma_t^2=\\sigma^2 t\\).","code":"\nlibrary(tidyverse)\nnormal=map(1:9,\n              ~rnorm(250,0,1) %>% \n              cumsum()) \npar(mfrow=c(3,3))\nplots=normal %>% \n  map(\n      plot,         \n      type=\"l\", \n      col=\"blue\",\n      ylab=\"the accumulated money\")\npar(mfrow=c(3,3))\nplots=normal %>% \n  map(acf)"},{"path":"random-walk.html","id":"random-walk-with-drift","chapter":"2 Random Walk","heading":"2.3 Random walk with drift","text":"Let series \\((S_t)_{t \\geq 0}\\) random walk\n\\[\\begin{align*}\nS_t&=S_0+X_1+X_2+...+X_t \\\\\n&=S_{t-1}+X_t \\\\\n&= \\mu + S_{t-1}+ Z_t\n\\end{align*}\\]\nsteps normally distributed, .e. \\(X \\sim \\mathcal{N}(\\mu,\\sigma)\\), random walk called random walk drift. \\(E[S_t|S_0]=S_0+ \\mu t\\) \\(\\mathbb{Var}(S_t|S_0)=\\sigma_t^2=\\sigma^2 t\\).","code":"\nlibrary(tidyverse)\ndrift=map(1:9,\n              ~rnorm(250,1,5) %>% \n              cumsum()) \n\npar(mfrow=c(3,3))\nplots=drift %>% \n  map(\n      plot,         \n      type=\"l\", \n      col=\"blue\",\n      ylab=\"the accumulated money\")\npar(mfrow=c(3,3))\nplots=drift %>% \n  map(acf)"},{"path":"random-walk.html","id":"geometric-random-walk","chapter":"2 Random Walk","heading":"2.4 Geometric random walk","text":"Let series \\((Y_t(t))_{t \\geq 0}\\) random walk\n\\[\\begin{align*}\nY_t(t)&=Y_1+Y_2+...+Y_t \\\\\n\\log \\left( \\frac{P_t}{P_0}\\right)&=Y_1+Y_2+...+Y_t \\\\\nP_t&=P_0e^{Y_1+Y_2+...+Y_t}\n\\end{align*}\\]\n\\((P_t)_{t \\geq0}\\) called geometric random walks exponential random walk. \\(Y_1,Y_2,...,Y_t\\) ..d \\(Y \\sim \\mathcal{N}(\\mu,\\sigma^2)\\), \\(P_t\\) lognormal random walk.RemarkThe lognormal geometric random walk needs two assumptions: log returns normally distributed log returns mutually independent. general, prices usually follow lognormal geometric random walk continuous-time analog, geometric Brownian. independence assumption can also violated since returns exhibit volatility clustering, .e., see high volatility current returns can expect higher volatility continue, least motion.","code":"\nlibrary(tidyverse)\ngeometric=map(1:9,\n          ~ exp(log(120)+\n                cumsum(rnorm(250,\n                        0/250,\n                        1/sqrt(250))))) \n\npar(mfrow=c(3,3))\nplots=geometric %>% \n  map(\n      plot, \n      type=\"l\", \n      col=\"blue\",\n      ylab=\"the accumulated money\")\npar(mfrow=c(3,3))\nplots=geometric %>% \n  map(acf)"},{"path":"volatility.html","id":"volatility","chapter":"3 Volatility","heading":"3 Volatility","text":"Unconditional volatility, volatility short, volatility \nentire time period, denoted \\(\\sigma\\).Conditional volatility volatility given time period, conditional\nhappened , denoted \\(\\sigma_t\\).subscript t means volatility particular time period, usually day.Clear evidence cyclical patterns volatility time, short run long run.","code":""},{"path":"volatility.html","id":"calculations","chapter":"3 Volatility","heading":"3.1 Calculations","text":"Consider sample \\(x_i\\) mean \\(\\mu\\) sample size \\(N\\). estimation volatility:daily volatility\n\\[\\sigma=\\sqrt{\\frac{1}{N}\\sum_{n=1}^{\\infty} (x_i-\\mu)^2}\\]annualy volatility\n\\[\\sigma=\\sqrt{250}\\sqrt{\\frac{1}{N}\\sum_{n=1}^{\\infty} (x_i-\\mu)^2}\\]","code":""},{"path":"volatility.html","id":"volatility-cluster","chapter":"3 Volatility","heading":"3.2 Volatility cluster","text":"volatility decade, year month, see comes many cycles called volatility clusters. following figure describes daily volatility McDonald’s stock 2010-2014.","code":"\nlibrary(tidyquant)\nmcd <- tq_get('MCD', \n               from=as.Date(\"2010-01-01\"),\n               to=as.Date(\"2014-01-01\"),\n               get = \"stock.prices\")\n\nmcd_logret=mcd$adjusted %>% \n  log() %>% \n  diff()\n\nplot(mcd$date[-1],mcd_logret,type=\"l\",col=\"blue\")"},{"path":"skewness-kurtosis.html","id":"skewness-kurtosis","chapter":"4 Skewness & Kurtosis","heading":"4 Skewness & Kurtosis","text":"Note Random Walk model, assuming independent Gaussian single-period returns, distribution multi-period returns prices derived. However, log returns typically heavy tailed thus results question.Skewness, kurtosis important descriptive statistics data distribution answer question. skewness essentially measures symmetry distribution, kurtosis determines heaviness distribution tails.","code":""},{"path":"skewness-kurtosis.html","id":"skewness","chapter":"4 Skewness & Kurtosis","heading":"4.1 Skewness","text":"","code":""},{"path":"skewness-kurtosis.html","id":"definition","chapter":"4 Skewness & Kurtosis","heading":"Definition","text":"skewness random variable X \n\\[S_k= \\mathbb{E}  \\left\\{ \\frac{X-\\mathbb{E}[X]}{\\sigma} \\right\\}^3=\\frac{\\mathbb{E}[(X-\\mathbb{E}[X])^3]}{\\sigma^3} \\]\nSkewness measures degree asymmetry.","code":""},{"path":"skewness-kurtosis.html","id":"types-of-skewness","chapter":"4 Skewness & Kurtosis","heading":"Types of skewness","text":"","code":""},{"path":"skewness-kurtosis.html","id":"symmetric-distribution","chapter":"4 Skewness & Kurtosis","heading":"4.1.1 Symmetric distribution","text":"\\(S_k=0\\) indicated symmetric distribution, .e., normal distribution t distribution.Since \\(skewness=0.05\\) approximately equal \\(0\\), distribution skew \\(mean=0.03\\) approximately equal \\(median=0.01\\).Since \\(skewness=-0.01\\) approximately equal \\(0\\), distribution skew \\(mean=0.04\\) approximately equal \\(median=0.04\\).","code":"\nlibrary(moments)\nn=rnorm(n=1000, mean = 0, sd = 1)\nhist(n)\nprint(c(skewness(n),mean(n),median(n)))#> [1] 0.047825380 0.029595494 0.009449741\nlibrary(e1071)\nlibrary(moments)\nt=rt(n=1000,df=10)\nhist(t)\nprint(c(skewness(t),mean(t),median(t)))#> [1] -0.01340383  0.04197639  0.03867323"},{"path":"skewness-kurtosis.html","id":"right-skewed","chapter":"4 Skewness & Kurtosis","heading":"4.1.2 Right-skewed","text":"\\(S_k>0\\) indicates relatively long right tail compared left tail, .e., distribution heavy tail right hand side.Since \\(skewness=0.87\\) greater \\(0\\), distribution right-skew \\(mean=-0.05\\) greater \\(median=-0.24\\).","code":"\nlibrary(moments)\nlibrary(fGarch)\nlibrary(e1071)\nsr=rsnorm(n=1000, mean = 0, sd = 1, xi = 5)\nhist(sr)\nprint(c(skewness(sr),mean(sr),median(sr)))#> [1]  0.86929586 -0.05052421 -0.24136543"},{"path":"skewness-kurtosis.html","id":"left-skewed","chapter":"4 Skewness & Kurtosis","heading":"4.1.3 Left-skewed","text":"\\(S_k<0\\) (left-skewed) indicates relatively long left tail compared right tail, .e., distribution heavy tail left hand side.Since \\(skewness=-0.89\\) less \\(0\\), distribution left-skew \\(mean=0.01\\) less \\(median=0.19\\).","code":"\nlibrary(moments)\nlibrary(fGarch)\nlibrary(e1071)\nsl=rsnorm(n=1000, mean = 0, sd = 1, xi = -2)\nhist(sl)\nprint(c(skewness(sl),mean(sl),median(sl)))#> [1] -0.88597146  0.01390576  0.19383722"},{"path":"skewness-kurtosis.html","id":"kurtosis","chapter":"4 Skewness & Kurtosis","heading":"4.2 Kurtosis","text":"","code":""},{"path":"skewness-kurtosis.html","id":"definition-1","chapter":"4 Skewness & Kurtosis","heading":"Definition","text":"Kurtosis random variable X \n\\[S_k= \\mathbb{E}  \\left\\{ \\frac{X-\\mathbb{E}[X]}{\\sigma} \\right\\}^4=\\frac{\\mathbb{E}[(X-\\mathbb{E}[X])^4]}{\\sigma^4} \\]\nKurtosis statistical measure defines heavily tails distribution differ tails normal distribution. words, kurtosis identifies whether tails given distribution contain extreme values.finance, kurtosis used measure financial risk. large kurtosis associated high level risk investment indicates high probabilities extremely large extremely small returns. hand, small kurtosis signals moderate level risk probabilities extreme returns relatively low.","code":""},{"path":"skewness-kurtosis.html","id":"example","chapter":"4 Skewness & Kurtosis","heading":"Example","text":"Let X follow normal distribution \\(N(0, 1)\\). \\[Kur(X)=3\\]Let X follow binomial distribution \\(B(p, n)\\). \\[Kur(X)=3+\\frac{1-6p(1-p)}{np(1-p)}\\]Let X follow t distribution \\(t(df=\\nu)\\). \\[Kur(X)=3+\\frac{6}{\\nu-4}\\]","code":""},{"path":"skewness-kurtosis.html","id":"types-of-kurtosis","chapter":"4 Skewness & Kurtosis","heading":"Types of Kurtosis","text":"Let excess kurtosis \\(\\kappa(X)=Kur(X)-3\\), following definitions:","code":""},{"path":"skewness-kurtosis.html","id":"mesokurtic","chapter":"4 Skewness & Kurtosis","heading":"4.2.1 Mesokurtic","text":"","code":"\nlibrary(moments)\nn=rnorm(n=10000, mean = 0, sd = 1)\nhist(n)\nkurtosis(n)#> [1] -0.1081596\n#> attr(,\"method\")\n#> [1] \"excess\""},{"path":"skewness-kurtosis.html","id":"leptokurtic","chapter":"4 Skewness & Kurtosis","heading":"4.2.2 Leptokurtic","text":"Leptokurtic distribution shows positive excess kurtosis \\((\\kappa > 0)\\). leptokurtic distribution shows heavy tails either side, indicating large outliers. t distribution low degree freedom typical example mesokurtic.finance, leptokurtic distribution shows investment returns may prone extreme values either side. Therefore, investment whose returns follow leptokurtic distribution considered risky. means big losses (well big gains) can occur.","code":"\nlibrary(moments)\nt=rt(n=1000,df=2)\nhist(t)\nkurtosis(t)#> [1] 26.44623\n#> attr(,\"method\")\n#> [1] \"excess\""},{"path":"skewness-kurtosis.html","id":"platykurtic","chapter":"4 Skewness & Kurtosis","heading":"4.2.3 Platykurtic","text":"platykurtic distribution shows negative excess kurtosis \\((\\kappa < 0)\\). kurtosis reveals distribution flat tails. flat tails indicate small outliers distribution.finance context, platykurtic distribution investment returns desirable investors small probability investment experience extreme returns.","code":"\nlibrary(moments)\nlibrary(e1071)                    \nduration = faithful$eruptions     \nhist(duration)\nkurtosis(duration)#> [1] -1.511605\n#> attr(,\"method\")\n#> [1] \"excess\""},{"path":"skewness-kurtosis.html","id":"financial-situation","chapter":"4 Skewness & Kurtosis","heading":"4.3 Financial situation","text":"two investments’ return distributions identical mean variance, different skewness parameters. one prefer?Typically, risk managers wary negative skew, situation, small gains norm, big losses can occur, carrying risk going bankruptcy.return distribution shows positive skew, investors can expect recurrent small losses large returns investment. Conversely, negatively skewed distribution implies many small wins large losses investment.Hence, positively skewed investment return distribution preferred negatively skewed return distribution since huge gains may cover frequent – small – losses. However, investors may prefer investments negatively skewed return distribution. may prefer frequent small wins huge losses frequent small losses large gains.","code":""},{"path":"skewness-kurtosis.html","id":"moments","chapter":"4 Skewness & Kurtosis","heading":"4.4 Moments","text":"basic statistic probability theory, almost exclusively deal first second center moment random variable, namely expectation variance \\(\\mathbb{E}[X]\\) \\(\\mathbb{E}[(X-\\mu)^2]\\). concept can generalized tok−th moment X: \\(m_k :=\\mathbb{E}(X_k)\\)k−th center moment X:\\(\\mu_k :=\\mathbb{E}[(X−\\mu)^k]\\)Using notation, population skewness kurtosis can rewritten :\n\\[\\begin{align*}\nSk(X)&=\\frac{\\mu_3}{\\mu_2^{3/2}}  \\\\\nKur(X)&=\\frac{\\mu_4}{\\mu_2^{2}}\n\\end{align*}\\]Let \\(X_1, X_2, ..., X_n\\) observations X sample mean \\(\\bar{X}\\) sample standard deviation \\(s\\).\nsample skewness denoted \\(\\widehat {Sk}\\) \n\\[ \\widehat {Sk}=\\frac{1}{n} \\sum_{=1}^{n} \\left( \\frac{X_i-\\bar{X}}{s} \\right)^3 \\]\nsample kurtosis denoted \\(\\widehat {Kur}\\) \n\\[ \\widehat {Kur}=\\frac{1}{n} \\sum_{=1}^{n} \\left( \\frac{X_i-\\bar{X}}{s} \\right)^4 \\]","code":""},{"path":"fat-tails.html","id":"fat-tails","chapter":"5 Fat tails","heading":"5 Fat tails","text":"","code":""},{"path":"fat-tails.html","id":"definition-2","chapter":"5 Fat tails","heading":"5.1 Definition","text":"tails extreme left right parts distribution. random variable said fat tails (also known heavy tails) exposes extreme outcomes normal distributed random variable mean variance. words, fat tails describe greater--expected probabilities extreme values.Financial advisors used mean–variance method model distribution probabilities values quantity, price returns. mean–variance model assumes normality fat tails present data.","code":""},{"path":"fat-tails.html","id":"example-1","chapter":"5 Fat tails","heading":"Example","text":"t-Student distribution convenient modeling fat tailed distribution. Consider t-distribution X degrees freedom \\(\\nu\\). values \\(\\nu\\) indicate fat tails areIf \\(\\nu=\\infty\\) X normal random variable.\\(\\nu<2\\) X follows fat tail distribution.typical stock \\(3<\\nu<5\\).","code":""},{"path":"fat-tails.html","id":"identification-of-fat-tails","chapter":"5 Fat tails","heading":"5.2 Identification of fat tails","text":"Two main approaches identifying analyzing tails financial returns including statistical methods: Jarque-Bera Test graphical methods: QQ plots.","code":""},{"path":"fat-tails.html","id":"statistical-methods","chapter":"5 Fat tails","heading":"5.2.1 Statistical methods","text":"Jarque-Bera (JB) tests popular statistical methods test fat tails\n\\[ JB=n \\left(\\frac{\\widehat{Sk}}{6}+\\frac{(\\widehat{Kur}-3)^2}{24} \\right) \\sim \\chi^2 \\]\nhypothesis normality, data symmetrical, .e. skewness equal zero skewness chose three.","code":""},{"path":"fat-tails.html","id":"graphical-methods","chapter":"5 Fat tails","heading":"5.2.2 Graphical methods","text":"general, Q-Q plot compares quantiles data quantiles reference distribution; data distribution type, reasonably straight line observed.QQ plot (quantile-quantile plot) compares quantiles sample data quantiles reference distribution, like normal.Used assess whether set observations particular distribution.Can also used determine whether two datasets distribution.","code":""},{"path":"fat-tails.html","id":"quantile","chapter":"5 Fat tails","heading":"5.2.2.1 Quantile","text":"pth quantile CDF F random variable X value \\(x_p\\) \\[F(x_p) = p \\quad \\text{} \\quad x_p = F^{−1}(p)\\]","code":""},{"path":"fat-tails.html","id":"q-q-plot","chapter":"5 Fat tails","heading":"5.2.2.2 Q-Q plot","text":"theoretical Q-Q plot graph quantiles CDF \\(F(x_p)=p\\) \\(x_p = F^{−1}(p)\\), versus corresponding quantiles CDF, \\(G(y_p)=p\\) \\(y_p = G^{−1}(p)\\) graph \\((F^{−1}(p), G^{−1}(p))\\) \\(p \\(0, 1)\\).\\(G(x) = F \\left(\\frac{x−\\mu}{\\sigma} \\right)\\) constants \\(\\mu\\) \\(\\sigma \\neq 0\\) \n\\[y_p = \\mu + \\sigma x_p\\]","code":""},{"path":"fat-tails.html","id":"example-2","chapter":"5 Fat tails","heading":"Example","text":"Let \\(F \\sim \\mathcal{N}(0,1)\\) \\(G(x) = F\\left(\\frac{x−1}{\\sqrt{2}} \\right) ∼ N(1,2)\\). Now choose \\(x_p = −3\\) corresponds \\(p = 0.001349898\\). probability obtain quantile distribution \\(G\\) \\(y_p = −3.242641\\). Now property Q-Q plots \n\\[y_p=1+\\sqrt{2} \\times (-3)=-3.242641\\]Generate standard normal distribution \\(-10\\) \\(10\\). compare \\(N(0, 1)\\), get","code":""},{"path":"fat-tails.html","id":"empirical-q-q-plots","chapter":"5 Fat tails","heading":"5.2.2.3 Empirical Q-Q plots","text":"Denote \\(F\\) specified CDF (e.g., normal) model. \\(G\\) empirical CDF observations \\(x_1, x_2, .., x_n\\) random sample \\(X_1, X_2, ..., X_n\\). compare observation \\(G\\) model \\(F\\)Plot \\(F^{−1} \\left( \\frac{1}{n} \\right)\\) horizonal axis versus.Plot \\(G^{−1} \\left( \\frac{1}{n} \\right) = x_()\\) vertical axis, \\(= 1, ..., n\\).\\(G\\) follows model \\(F\\) observed data close line \\(y = \\mu + \\sigma x\\).","code":""},{"path":"fat-tails.html","id":"example-3","chapter":"5 Fat tails","heading":"Example","text":"\\(F = \\mathcal{N}(0, 1)\\), model \\(X_1, X_2, ...X_{20} \\sim U(0, 1)\\) get Q-Q plot samples","code":""},{"path":"mixture-distributions.html","id":"mixture-distributions","chapter":"6 Mixture Distributions","heading":"6 Mixture Distributions","text":"Another class heavy-tailed models set mixture distributions. Consider simple example made \\(90\\%\\) \\(N(0,1)\\) \\(10\\%\\) \\(N(0, 25)\\), density function construct can written \n\\[f_{mix}(x) = 0.9f_{N(0,1)}(x) + 0.1f_{N(0,25)}(x)\\]generate random variable Y according distribution, can two-step process:First, draw uniform \\((0.1)\\) random variable \\(U\\) normal random variable \\(X \\sim \\mathcal{N}(0, 1)\\).Second, \\(U<0.9\\), \\(Y=X\\). \\(U>0.9\\) \\(Y=5X\\). Note model appropriate stock time shows little variability, occasionally, e.g., earning announcement events, make much bigger movements.Note model appropriate stock time shows little variability, occasionally, e.g., earning announcement events, make much bigger movements.Next use rule 3 sigma find numbers outlier ratio outlier mixture distribution \\(\\mathcal{N}(0,3.4)\\).Result show mixture distribution produces 10 times extrem events.","code":"\nu=runif(100000,0,1)\nx=rnorm(100000,0,1)\ny=ifelse(u<0.9,x,5*x)\nhist(y,xlim=c(-10,10))\nxx=seq(-9,9, length=701)\nyy=dnorm(xx, 0, sqrt(3.4))\nmm=0.9*dnorm(xx, 0, 1)+0.1*dnorm(xx, 0,5)\nplot(xx, yy, type=\"l\", ylim=c(0,0.4), ylab=\"Density\",xlab=\"x\", col=\"blue\")\nlines(xx, mm, col=\"red\", legend=c)\ntitle(\"Gaussian distribution and Normal Mixture\")\nbox()\nlegend(\"bottomright\",\n       legend = c(\"N(0, 3.4)\", \"Mixture\"),\n       col = c(\"red\",\"blue\"),lwd = 1)\nsdev=sqrt(3.4)\ngauss=2*pnorm(-3*sdev, 0, sdev)\nmixt=2*0.9*pnorm(-3*sdev,0,1)+2*0.1*pnorm(-3*sdev, 0,5)\n\nmixt/gauss#> [1] 9.948061"},{"path":"in-class-exercise.html","id":"in-class-exercise","chapter":"7 In-class exercise","heading":"7 In-class exercise","text":"","code":""},{"path":"in-class-exercise.html","id":"dailly-log-return","chapter":"7 In-class exercise","heading":"7.1 Dailly log-return","text":"Suppose daily log-return stock independent normally distributed mean \\(0.001\\) standard deviation \\(0.015\\). Suppose buy \\(1000\\$\\) worth stock.prbability one trading day investment worth less \\(990\\$\\)?Let \\(\\mathcal{P}_1\\) probability one trading day investment worth \\(X\\) standard normal random variable.daily log-return stock independent normally distributed mean \\(0.001\\) standard deviation \\(0.015\\): \\(r_t=\\log \\left( \\frac{P_t}{P_{t-1}} \\right) \\sim \\mathcal{N}(0.001,0.015)\\).\\[\\begin{align*}\n\\mathcal{P}_1&=\\mathcal{P}(1000P_t \\leq 990 P_{t-1}) \\\\\n&=\\mathcal{P} \\left(r_t \\leq \\log \\left( \\frac{990}{1000} \\right) \\right) \\\\\n&=\\mathcal{P} \\left(\\frac{r_t-0.001}{0.015}  \\leq \\frac{\\log\\left(  \\frac{990}{1000} \\right)-0.001}{0.015} \\right) \\\\\n&=\\mathcal{P} \\left(X  \\leq -0.7366 \\right) \\\\\n&=0.23066\n\\end{align*}\\]Answer: probability one trading day investment worth less 990$ \\(23.066\\%\\).probability five trading days investment worth less \\(990\\$\\)?Let \\(\\mathcal{P}_5\\) probability five trading day investment worth.five day log-return stock independent normally distributed mean \\(0.001 \\times 5\\) standard deviation \\(0.015 \\times \\sqrt{5}\\): \\(r_t=\\log \\left( \\frac{P_t}{P_{t-1}} \\right) \\sim \\mathcal{N}(0.001 \\times 5,0.015 \\times \\sqrt{5})\\).\\[\\begin{align*}\n\\mathcal{P}_5&=\\mathcal{P}(1000P_t \\leq 990 P_{t-5}) \\\\\n&=\\mathcal{P} \\left(r_t \\leq \\log \\left( \\frac{990}{1000} \\right) \\right) \\\\\n&=\\mathcal{P} \\left(\\frac{r_t-0.001 \\times 5}{0.015 \\times \\sqrt{5}}  \\leq \\frac{\\log\\left(  \\frac{990}{1000} \\right)-0.001 \\times 5}{0.015 \\times \\sqrt{5}} \\right) \\\\\n&=\\mathcal{P} \\left(X  \\leq -0.4487 \\right) \\\\\n&=0.32682\n\\end{align*}\\]Answer: probability five trading day investment worth less \\(990\\$\\) \\(32.68\\%\\).","code":""},{"path":"in-class-exercise.html","id":"skewness-kurtosis-1","chapter":"7 In-class exercise","heading":"7.2 Skewness & Kurtosis","text":"Calculate skewness kurtosis following density function\\[f(x) =\\begin{cases}\n\\frac{3}{8}x^2 & \\text{} 0<x<2\\\\\n0 & \\text{otherwise}\n\\end{cases}\\]\\[\\begin{align*}\n\\mu_1&=\\mathbb{E}[X] \\\\\n&=\\int_{0}^{2}x \\times \\frac{3}{8}x^2\\,dx \\\\\n&=\\frac{3}{2} \\\\\n\\\\\n\\mu_2&=\\mathbb{E}[X^2] \\\\\n&=\\int_{0}^{2}x^2 \\times \\frac{3}{8}x^2\\,dx \\\\\n&=\\frac{12}{5}\n\\end{align*}\\]\\[\\begin{align*}\nSk&=\\frac{\\mathbb{E}[(X-\\mu_1)^3]}{\\sigma^3} \\\\\n&=\\frac{\\int_{0}^{2}(x-\\mu_1)^3 \\times \\frac{3}{8}x^2\\,dx}{(\\mu_2-\\mu_1^2)^{3/2}} \\\\\n&=\\frac{\\int_{0}^{2}(x-\\frac{3}{2})^3 \\times \\frac{3}{8}x^2\\,dx}{\\left[ \\frac{12}{5}-\\left( \\frac{3}{2} \\right)^2 \\right]^{3/2}} \\\\\n&=-0.86 \\\\\n\\\\\nKur&=\\frac{\\mathbb{E}[(X-\\mu_1)^4]}{\\sigma^4} \\\\\n&=\\frac{\\int_{0}^{2}(x-\\mu_1)^4 \\times \\frac{3}{8}x^2\\,dx}{(\\mu_2-\\mu_1^2)^{4/2}} \\\\\n&=\\frac{\\int_{0}^{2}(x-\\frac{3}{2})^4 \\times \\frac{3}{8}x^2\\,dx}{\\left[ \\frac{12}{5}-\\left( \\frac{3}{2} \\right)^2 \\right]^{4/2}} \\\\\n&=3.10\n\\end{align*}\\]Answer: skewness \\(-0.86\\) kurtosis \\(3.10\\).","code":""},{"path":"in-class-exercise.html","id":"python","chapter":"7 In-class exercise","heading":"Python","text":"Calculate skewness kurtosis log return exchange rate EURO USD.Calculate skewness kurtosis log return exchange rate S&P500.","code":"import numpy as np\nimport pandas as pd\n# Import and calculate log return    \neurusd_url='https://docs.google.com/spreadsheets/d/e/2PACX-1vT4WqdVoUIiaMcd4jQj5by3Oauc6G4EFq9VDDrpzG2oBn6TFzyNE1yPV2fKRal5F7DmRzCtVa4nSQIw/pub?gid=0&single=true&output=csv'\neurusd=pd.read_csv(eurusd_url)\neurusd.head()#>          Date  USD per euro\n#> 0  27/07/2005        1.1990\n#> 1  28/07/2005        1.2100\n#> 2  29/07/2005        1.2093\n#> 3  01/08/2005        1.2219\n#> 4  02/08/2005        1.2217eurusd_logret = np.log(eurusd['USD per euro']) - np.log(eurusd['USD per euro'].shift(1))\neurusd_logret[:6]#> 0         NaN\n#> 1    0.009132\n#> 2   -0.000579\n#> 3    0.010365\n#> 4   -0.000164\n#> 5    0.007421\n#> Name: USD per euro, dtype: float64import matplotlib.pyplot as plt\n# Exploratory\neurusd_logret.plot()\nplt.xlabel(\"Date\")\nplt.ylabel(\"Log-Return'\")\nplt.title(\"Log-Return of Exchange Rate over time'\")\nplt.show()import matplotlib.pyplot as plt\nfig = plt.figure()\nax1 = fig.add_axes([0.1,0.1,0.8,0.8])\neurusd_logret.plot.hist(bins = 60)\nax1.set_xlabel(\"Log Return\")\nax1.set_ylabel(\"Percent\")\nax1.set_title(\"Histogram of Log return\")\nplt.show()import pandas as pd\neurusd_logret.skew()#> -0.07336059594162114eurusd_logret.kurtosis()#> 4.66844649461392import numpy as np\nimport pandas as pd\nsp500_url='https://docs.google.com/spreadsheets/d/e/2PACX-1vT4WqdVoUIiaMcd4jQj5by3Oauc6G4EFq9VDDrpzG2oBn6TFzyNE1yPV2fKRal5F7DmRzCtVa4nSQIw/pub?gid=279168786&single=true&output=csv'\nsp500=pd.read_csv(sp500_url)\nsp500.head()#>          Date    Open    High     Low   Close    Volume  Adj Close\n#> 0  01/03/1985  165.37  166.11  164.38  164.57  88880000     164.57\n#> 1  01/04/1985  164.55  164.55  163.36  163.68  77480000     163.68\n#> 2  01/07/1985  163.68  164.71  163.68  164.24  86190000     164.24\n#> 3  01/08/1985  164.24  164.59  163.91  163.99  92110000     163.99\n#> 4  01/09/1985  163.99  165.57  163.99  165.18  99230000     165.18sp500_logret = np.log(sp500['Close']) - np.log(sp500['Close'].shift(1))\nsp500_logret[:6]#> 0         NaN\n#> 1   -0.005423\n#> 2    0.003415\n#> 3   -0.001523\n#> 4    0.007230\n#> 5    0.018772\n#> Name: Close, dtype: float64import matplotlib.pyplot as plt\nsp500_logret.plot()\nplt.xlabel(\"Date\")\nplt.ylabel(\"Log-Return'\")\nplt.title(\"Log-Return of S&P500 over time'\")\nplt.show()import matplotlib.pyplot as plt\nfig = plt.figure()\nax1 = fig.add_axes([0.1,0.1,0.8,0.8])\nsp500_logret.plot.hist(bins = 60)\nax1.set_xlabel(\"Log Return\")\nax1.set_ylabel(\"Percent\")\nax1.set_title(\"Histogram of Log return\")\nplt.show()import pandas as pd\nsp500_logret.skew()#> -1.2989867430563735sp500_logret.kurtosis()#> 28.28091194470013"},{"path":"in-class-exercise.html","id":"r","chapter":"7 In-class exercise","heading":"R","text":"Calculate skewness kurtosis log return exchange rate EURO USD.Calculate skewness kurtosis log return exchange rate S&P500.","code":"\nlibrary(tidyverse)\nlibrary(moments)\n# Import and calculate log return\neurusd_url=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vT4WqdVoUIiaMcd4jQj5by3Oauc6G4EFq9VDDrpzG2oBn6TFzyNE1yPV2fKRal5F7DmRzCtVa4nSQIw/pub?gid=0&single=true&output=csv\"\neurusd=read.csv(eurusd_url)\nhead(eurusd)#>         Date USD.per.euro\n#> 1 27/07/2005       1.1990\n#> 2 28/07/2005       1.2100\n#> 3 29/07/2005       1.2093\n#> 4 01/08/2005       1.2219\n#> 5 02/08/2005       1.2217\n#> 6 03/08/2005       1.2308\neurusd_logret=eurusd[,2] %>% log() %>% diff()\nhead(eurusd_logret)#> [1]  0.0091324836 -0.0005786798  0.0103653445 -0.0001636929  0.0074210330\n#> [6]  0.0008933285\nplot(eurusd_logret,type=\"l\")\nhist(eurusd_logret,breaks=60)\nlibrary(e1071)\nskewness(eurusd_logret)#> [1] -0.07318848\n#> attr(,\"method\")\n#> [1] \"moment\"\nkurtosis(eurusd_logret)#> [1] 4.633551\n#> attr(,\"method\")\n#> [1] \"excess\"\nlibrary(tidyverse)\nlibrary(moments)\n# Import and calculate log return\nsp500_url=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vT4WqdVoUIiaMcd4jQj5by3Oauc6G4EFq9VDDrpzG2oBn6TFzyNE1yPV2fKRal5F7DmRzCtVa4nSQIw/pub?gid=279168786&single=true&output=csv\"\nsp500=read.csv(sp500_url)\nhead(sp500)#>         Date   Open   High    Low  Close    Volume Adj.Close\n#> 1 01/03/1985 165.37 166.11 164.38 164.57  88880000    164.57\n#> 2 01/04/1985 164.55 164.55 163.36 163.68  77480000    163.68\n#> 3 01/07/1985 163.68 164.71 163.68 164.24  86190000    164.24\n#> 4 01/08/1985 164.24 164.59 163.91 163.99  92110000    163.99\n#> 5 01/09/1985 163.99 165.57 163.99 165.18  99230000    165.18\n#> 6  1/10/1985 165.18 168.31 164.99 168.31 124700000    168.31\nsp500_logret= sp500$Adj.Close %>% log() %>% diff()\nhead(sp500_logret)#> [1] -0.005422709  0.003415471 -0.001523322  0.007230338  0.018771729\n#> [6] -0.002379396\nplot(sp500_logret,type=\"l\")\nhist(sp500_logret,breaks=60)\nlibrary(e1071)\nskewness(sp500_logret)#> [1] -1.298466\n#> attr(,\"method\")\n#> [1] \"moment\"\nkurtosis(sp500_logret)#> [1] 28.25285\n#> attr(,\"method\")\n#> [1] \"excess\""},{"path":"in-class-exercise.html","id":"the-jarque-bera-jb-tests","chapter":"7 In-class exercise","heading":"7.3 The Jarque-Bera (JB) tests","text":"","code":""},{"path":"in-class-exercise.html","id":"python-1","chapter":"7 In-class exercise","heading":"Python","text":"Check data log return exchange rate Euro USD follow normal distribution.\\(p-value<0.05\\) can reject null hypothesis \\(H_0: Sk=0 \\text{ } Kur=3\\) meaning log return exchange rate EURUSD follow normal distribution.Check data log return exchange rate S&P500 follow normal distribution.\\(p-value<0.05\\) can reject null hypothesis \\(H_0: Sk=0 \\text{ } Kur=3\\) meaning log return exchange rate S&P500 follow normal distribution.","code":"import scipy.stats as stats\nprint(stats.jarque_bera(eurusd_logret[1:]),stats.kstest(eurusd_logret[1:],'norm'))#> Jarque_beraResult(statistic=1150.3195976112938, pvalue=0.0) KstestResult(statistic=0.48876441843556134, pvalue=5.961875332718074e-282)import scipy.stats as stats\nprint(stats.jarque_bera(sp500_logret[1:]),stats.kstest(sp500_logret[1:],'norm'))#> Jarque_beraResult(statistic=250996.03457721754, pvalue=0.0) KstestResult(statistic=0.4800295652866924, pvalue=0.0)"},{"path":"in-class-exercise.html","id":"r-1","chapter":"7 In-class exercise","heading":"R","text":"Check data log return exchange rate Euro USD follow normal distribution.\\(p-value<0.05\\) can reject null hypothesis \\(H_0: Sk=0 \\text{ } Kur=3\\) meaning log return exchange rate EURUSD follow normal distribution.Check data log return exchange rate S&P500 follow normal distribution.\\(p-value<0.05\\) can reject null hypothesis \\(H_0: Sk=0 \\text{ } Kur=3\\) meaning log return exchange rate S&P500 follow normal distribution.","code":"\nlibrary(moments)\njarque.test(eurusd_logret)#> \n#>  Jarque-Bera Normality Test\n#> \n#> data:  eurusd_logret\n#> JB = 1150.3, p-value < 2.2e-16\n#> alternative hypothesis: greater\nlibrary(moments)\njarque.test(sp500_logret)#> \n#>  Jarque-Bera Normality Test\n#> \n#> data:  sp500_logret\n#> JB = 250996, p-value < 2.2e-16\n#> alternative hypothesis: greater"},{"path":"in-class-exercise.html","id":"q-q-plot-1","chapter":"7 In-class exercise","heading":"7.4 Q-Q plot","text":"","code":""},{"path":"in-class-exercise.html","id":"python-2","chapter":"7 In-class exercise","heading":"Python","text":"Q-Q plot log return exchange rate Euro USDQ-Q plot log return S&P500","code":"import statsmodels.api as sm\nimport pylab as py\nsm.qqplot(eurusd_logret, line ='q')\npy.show()import statsmodels.api as sm\nimport pylab as py\nsm.qqplot(sp500_logret, line ='q')\npy.show()"},{"path":"in-class-exercise.html","id":"r-2","chapter":"7 In-class exercise","heading":"R","text":"Q-Q plot log return exchange rate Euro USDQ-Q plot log return S&P500","code":"\nqqnorm(eurusd_logret)\nqqline(eurusd_logret, col = \"red\")\nqqnorm(sp500_logret)\nqqline(sp500_logret, col = \"red\")"},{"path":"homework.html","id":"homework","chapter":"8 Homework","heading":"8 Homework","text":"","code":""},{"path":"homework.html","id":"problem-1","chapter":"8 Homework","heading":"8.1 Problem 1","text":"prices dividends stock given follows.Determine \\(R_2\\) \\(R_4(3)\\).\\[\\begin{align*}\nR_2&=\\frac{P_2-P_1+d_2}{P_1}=0.042 \\\\\nR_3&=\\frac{P_3-P_2+d_3}{P_2}=-0.015 \\\\\nR_4&=\\frac{P_4-P_3+d_4}{P_3}=0.118 \\\\\n\\end{align*}\\]\\[\\begin{align*}\nR_4(3)&=(1+R_4)(1+R_3)(1+R_2)-1 \\\\\nR_4(3)&=(1+0.118)(1+-0.015)(1+0.042)-1 \\\\\n&\\approx 0.148\n\\end{align*}\\]Answer: \\(R_2 \\approx 0.042\\) \\(R_4(3) \\approx 0.148\\).Determine \\(r_3\\).\\[\\begin{align*}\nr_3&=\\ln(1+R_3) \\\\\n&\\approx R_3 \\\\\n&\\approx-0.015\n\\end{align*}\\]Answer: \\(r_3 \\approx -0.015\\)","code":""},{"path":"homework.html","id":"problem-2","chapter":"8 Homework","heading":"8.2 Problem 2","text":"Assume log returns \\(r_t \\sim \\mathcal{N}(0.06, 0.47)\\) ..d.Determine distribution \\(r_t(4)\\).\\[\\begin{align*}\nr_t(4)&=r_t+r_{t-1}+r_{t-2}+r_{t-3} \\\\\n&\\sim 4 \\times \\mathcal{N}(0.06,0.47) \\\\\n&\\sim  \\mathcal{N}(4 \\times 0.06,4 \\times 0.47) \\\\\n&\\sim \\mathcal{N}(0.24,1.88)\n\\end{align*}\\]Answer: distribution \\(r_t(4)\\) \\(\\mathcal{N}(0.24,1.88)\\).Find \\(cov(r_2(1), r_2(2))\\).\\[\\begin{align*}\ncov(r_2(1),r_2(2))&=cov(r_2,r_2+r_1) \\\\\n&=cov(r_2,r_2)+cov(r_2,r_1) \\\\\n&=var(r_2)+cov(r_1,r_2) \\\\\n&=0.47\n\\end{align*}\\]Answer: \\(cov(r_2(1),r_2(2))=0.47\\)Determine distribution \\(r_t(3)\\) \\(r_{t−2} = 0.6\\).\\[\\begin{align*}\n[r_t(3)|r_{t-2}=0.6]&=[r_t+r_{t-1}+r_{t-2}|r_{t-2}=0.6] \\\\\n&=r_t+r_{t-1}+0.6 \\\\\n&\\sim \\mathcal{N}(0.06,0.47)+\\mathcal{N}(0.06,0.47)+0.6 \\\\\n&\\sim \\mathcal{N}(0.72,0.94)\n\\end{align*}\\]Answer: \\(r_{t-2}=0.6\\), distribution \\(r_t(3)\\) \\(\\mathcal{N}(0.72,0.94)\\).","code":""},{"path":"homework.html","id":"problem-3","chapter":"8 Homework","heading":"8.3 Problem 3","text":"Assume stock current price $97 ..d. log returns\\[r_t \\sim \\mathcal{N}(2 \\times 10^{−4}, 9 \\times 10^{−4})\\]\nprobability price exceeds \\(\\$100\\) 20 trading days?\\[\\begin{align*}\n\\ln \\left( \\frac{P_{20}}{P_0} \\right) &= r_{20}(20) \\\\\n&= \\sum_{t=1}^{20}r_t \\\\\n&\\sim 20 \\times \\mathcal{N}(2 \\times 10^{−4}, 9 \\times 10^{−4}) \\\\\n&\\sim  \\mathcal{N}(20 \\times 2 \\times 10^{−4}, 20 \\times 9 \\times 10^{−4}) \\\\\n&\\sim \\mathcal{N}(0.004, 0.018)  \\\\\n\\\\\n\\rightarrow \\ln(P_{20})&=\\ln(P_{0})+r_{20}(20) \\\\\n&\\sim \\ln(97)+\\mathcal{N}(0.004, 0.018) \\\\\n&\\sim \\mathcal{N}(4.579, 0.018)\n\\end{align*}\\]\\[\\begin{align*}\n\\mathcal{P}(P_{20}>100)&=\\mathcal{P}(\\ln(P_{20})>\\ln(100)) \\\\\n&=\\mathcal{P} \\left(\\frac{\\ln(P_{20})-4.579}{\\sqrt{0.018}} > \\frac{\\ln(100)-4.579}{\\sqrt{0.018}} \\right) \\\\\n&=\\mathcal{P} \\left(\\mathcal{Z} > \\frac{\\ln(100)-4.579}{\\sqrt{0.018}} \\right) \\\\\n&=\\mathcal{P} \\left(\\mathcal{Z} > 0.195 \\right) \\\\\n&=\\mathcal{P} \\left(\\mathcal{Z} < -0.195 \\right) \\\\\n&=0.423\n\\end{align*}\\]Answer: probability price exceeds \\(\\$100\\) 20 trading days 42.3%.","code":""},{"path":"homework.html","id":"problem-4","chapter":"8 Homework","heading":"8.4 Problem 4","text":"Assume log returns \\(r_t \\sim \\mathcal{N}(5 \\times 10^{−4}, 0.012)\\) ..d. Minimize t \\[\\mathcal{P} \\left( \\frac{P_t}{P_0}  \\geq 2\\right) \\geq 0.9\\]\n.e. probability price doubles t days least 90%.\\[\\begin{align*}\n\\ln\\left( \\frac{P_t}{P_0} \\right) &=r_t(t) \\\\\n&=\\sum_{=1}^{t}r_i \\\\\n&\\sim t \\times \\mathcal{N}(5 \\times 10^{−4}, 0.012) \\\\\n&\\sim  \\mathcal{N}(t \\times 5 \\times 10^{−4},t \\times 0.012)\n\\end{align*}\\]\\[\\begin{align*}\n\\mathcal{P} \\left( \\frac{P_t}{P_0}  \\geq 2\\right) &= \\mathcal{P} \\left( \\ln \\left( \\frac{P_t}{P_0} \\right)  \\geq \\ln(2) \\right) \\\\\n&=\\mathcal{P} \\left(\\frac{\\ln \\left( \\frac{P_t}{P_0} \\right)-t \\times 5 \\times 10^{−4}}{\\sqrt{t \\times 0.012}} \\geq\n\\frac{\\ln(2)-t \\times 5 \\times 10^{−4}}{\\sqrt{t \\times 0.012}} \\right) \\\\\n&=\\mathcal{P} \\left(\\mathcal{Z} \\geq\n\\frac{\\ln(2)-t \\times 5 \\times 10^{−4}}{\\sqrt{t \\times 0.012}} \\right) \\\\\n&=\\mathcal{P} \\left(\\mathcal{Z} \\leq\n-\\frac{\\ln(2)-t \\times 5 \\times 10^{−4}}{\\sqrt{t \\times 0.012}} \\right)\n\\end{align*}\\]\\[\\begin{align*}\n&\\mathcal{P} \\left( \\frac{P_t}{P_0}  \\geq 2\\right) \\geq 0.9 \\\\\n&\\rightarrow \\mathcal{P} \\left(\\mathcal{Z} \\leq\n-\\frac{\\ln(2)-t \\times 5 \\times 10^{−4}}{\\sqrt{t \\times 0.012}} \\right) \\geq 0.9 \\\\\n&\\rightarrow -\\frac{\\ln(2)-t \\times 5 \\times 10^{−4}}{\\sqrt{t \\times 0.012}}\\geq\\Phi^{-1}(0.9) \\\\\n&\\rightarrow -\\frac{\\ln(2)-t \\times 5 \\times 10^{−4}}{\\sqrt{t \\times 0.012}}\\geq 1.282 \\\\\n&\\rightarrow t \\geq 81638.20\n\\end{align*}\\]Answer: Minimum value t probability price doubles t days 81639.","code":""},{"path":"stationary-processes.html","id":"stationary-processes","chapter":"9 Stationary processes","heading":"9 Stationary processes","text":"volatility plays crucial role financial risk management, \nmain measure risk. hands, volatility \nkey factor , e.g., Investment decisions, Portfolio construction\n(Markowitz model) Derivative pricing (Black-Scholes model).Chapter focus estimation forecasting \nvolatility single asset (univariate).volatility plays crucial role financial risk management, \nmain measure risk. hands, volatility \nkey factor , e.g., Investment decisions, Portfolio construction\n(Markowitz model) Derivative pricing (Black-Scholes model).Chapter focus estimation forecasting \nvolatility single asset (univariate).","code":""},{"path":"stationary-processes.html","id":"time-series","chapter":"9 Stationary processes","heading":"9.1 Time series","text":"time series sequence observations chronological order. example: daily log returns stock monthly values Consumer Price Index (CPI).stochastic process sequence random variables can viewed “theoretical” “population” analog time series, conversely, time series can considered sample stochastic process.Denote \\(\\{X_t, t \\\\}\\) time series, time index. example: \\(= \\{1, 2, 3, ...\\}\\) \\(= \\{2000, 2001, 2002...2021\\}\\). Equally spaced time series common practice. case \n\\(= \\{t_1, t_2, ..., t_n\\}\\), \n\\((\\Delta = t_{+1} − t)_i\\) \\(\\Delta\\) constant.","code":""},{"path":"stationary-processes.html","id":"remark-1","chapter":"9 Stationary processes","heading":"9.1.1 Remark","text":"Difference traditional Statistical InferenceIn traditional statistic inference, data assumed ..d\nprocess (random sample).time series, need assumption wish model dependency among observations leads concept autocorrelation.main problems time seriesFormulate estimate parametric model \\(X_t\\) (need propose methods estimation model diagnostics).point related estimation autoregressive (AR) ARMA models.Estimation Missing values (fill“gaps”).Prediction Forecasting (“like know future value ”). example data \\(x_1, x_2, ..., x_{100}\\), wish forecast next 10 values, \\(x_{101}, ..., x_{110}\\). case, forecasting horizon 10.Plotting time series observe fluctuations time series, e.g., find stationarity non-stationarity, cycles, trends, outliers interventions. Assisting formulation parametric model.","code":""},{"path":"stationary-processes.html","id":"example-4","chapter":"9 Stationary processes","heading":"Example","text":"Consider Financial Index SP500. data consists excess returns \\(X_t = \\log(S_t) −\\log(S_{t−1})\\). plot see following properties \\(X_t\\):mean level process seems constant.sections data explosive behavior (high volatility).data corresponds non-stationary process (define detailed).variance (volatility) constant time.linear time series model available data.","code":"\nsp500=read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vT4WqdVoUIiaMcd4jQj5by3Oauc6G4EFq9VDDrpzG2oBn6TFzyNE1yPV2fKRal5F7DmRzCtVa4nSQIw/pub?gid=279168786&single=true&output=csv\")\nplot(diff(log(sp500$Close)),type=\"l\",col=\"blue\")"},{"path":"stationary-processes.html","id":"autocovariance","chapter":"9 Stationary processes","heading":"9.2 Autocovariance","text":"","code":""},{"path":"stationary-processes.html","id":"definition-3","chapter":"9 Stationary processes","heading":"9.2.1 Definition","text":"autocovariance function stochastic process \\(X\\) defined \n\\[\\gamma(t,\\tau)=\\mathbb{E}(X_t −\\mu_t)(X_{t−\\tau} −\\mu_{t−\\tau})\\]\n\\(\\tau \\\\mathbb{Z}\\), \\(\\mu_t = E(X_t)\\).autocovariance function symmetric, .e., \\(\\gamma(t,\\tau) = \\gamma(t − \\tau,−\\tau)\\). special case \\(\\tau = 0\\) \\(\\gamma(t, 0) = Var(X_t)\\).general \\(\\gamma(t,\\tau)\\) depend t well \\(\\tau\\).","code":""},{"path":"stationary-processes.html","id":"example-5","chapter":"9 Stationary processes","heading":"Example","text":"Find autocovariance function Brownian motion?\\[\\begin{align*}\n&B_t \\sim \\mathcal{N}(0,t) \\\\\n&\\rightarrow E[B_t^2] =Var(B_t)=t\n\\end{align*}\\]\\[\\begin{align*}\n&B_t-B_{t-\\tau} \\sim \\mathcal{N}(0,t-\\tau) \\\\\n&\\rightarrow E[(B_t-B_{t-\\tau})^2]=Var(B_t-B_{t-\\tau})=t-\\tau\n\\end{align*}\\]\\[\\begin{align*}\n\\gamma(t,\\tau)&=E[(B_t-\\mu_t)(B_{t-\\tau}-\\mu_{t-\\tau})] \\\\\n&=E[B_tB_{t-\\tau}] \\\\\n&=-\\frac{1}{2}E[(B_t-B_{t-\\tau})^2-B_t^2-B_{t-\\tau}^2] \\\\\n&=-\\frac{1}{2}\\{E[(B_t-B_{t-\\tau})^2] -E[B_t^2]-E[B_{t-\\tau}^2]\\} \\\\\n&=-\\frac{1}{2} [(\\tau)-(t)-(t-\\tau)]=t-\\tau\n\\end{align*}\\]Answer: autocovariance function Brownian motion \\(t-\\tau\\).","code":""},{"path":"stationary-processes.html","id":"stationary","chapter":"9 Stationary processes","heading":"9.3 Stationary","text":"","code":""},{"path":"stationary-processes.html","id":"strictly-stationary","chapter":"9 Stationary processes","heading":"9.3.1 Strictly Stationary","text":"process said strictly stationary aspects behavior unchanged shifts time. Mathematically, stationarity defined requirement every \\(m\\) \\(n\\) distribution \n\\((X_1, X_2, ..., X_n)\\) \\((X_{1+m}, X_{2+m}, ..., X_{n+m})\\) .","code":""},{"path":"stationary-processes.html","id":"weakly-stationary","chapter":"9 Stationary processes","heading":"9.3.2 Weakly Stationary","text":"process weakly stationary mean, variance, covariance unchanged time shifts. precisely, \\(X_1, X_2, ...,\\) weakly stationary process \\(\\mathbb{E}(X_t)=\\mu, \\forall t\\)\\(Var(X_t) = \\sigma_2\\) (positive finite constant) \\(t\\).\\(Cov(X_t, X_s) = \\gamma(|t − s|), \\forall t, s\\) function \\(\\gamma\\).see , mean variance change time covariance two observations depends lag, time distance \\(|t − s|\\).function \\(\\gamma\\) autocovariance function process symmetric property \\(\\gamma(h) = \\gamma(−h)\\).\\[\\begin{align*}\n\\gamma(h)=cov(X_t,X_{t+h}) \\\\\n\\rightarrow \\gamma(-h)=cov(X_{t},X_{t-h})\n\\end{align*}\\]Let \\(s=t-h\\) \\(t=s+h\\)\n\\[\\gamma(-h)=cov(X_{s+h},X_{s})=\\gamma(h) \\]correlation \\(X_t\\) \\(X_{t+h}\\) denoted \\(\\rho(h)\\). Function \\(\\rho\\) called autocorrelation function (ACF). \\(\\gamma(0) = \\sigma^2\\) , hence\n\\(\\gamma(h) = \\sigma^2 \\rho(h)\\) hence \\(\\rho(h) = \\frac{\\gamma(h)}{\\gamma(0)}\\).ACF normalized \\([−1, 1]\\). Since process required covariance stationary, ACF depends one parameter, lag \\(h\\).","code":""},{"path":"stationary-processes.html","id":"example-6","chapter":"9 Stationary processes","heading":"Example","text":"Consider random walk \\(X: X_t = c + X_{t−1} + \\epsilon_t\\), c constant white noise \\(\\epsilon_t\\). see \\(c \\neq 0\\), \\(Z_t := X_t −X_{t−1} = c+ \\epsilon_t\\) non-zero mean. call random walk drift. Note since \\(\\epsilon_t\\) independent call \\(X_t\\) random walk independent increments. convenience, assume \\(c\\) \\(X_0\\) set zero. \\[\\begin{align*}\n&X_t =\\epsilon_t + \\epsilon_{t−1} +...+\\epsilon_1 \\\\\n\\\\\n&\\mu_t =E(X_t)=0 \\\\\n\\\\\n&Var(X_t) = t\\sigma\n\\end{align*}\\]\\(Var(X_t)\\) stationary rather increases linearly time makes random walk “wander”, .e., \\(X_t\\) takes increasingly longer excursions away conditional mean \\(0\\), therefore mean-reverting.\\(s<t\\) \\[ \\rho(t,s)=\\sqrt{1-\\frac{s}{t}} \\]\\(\\rho\\) depending \\(t\\) well \\(s\\), thus random walk covariance stationary. following figure shows relationship among different processes: Stationary processes largest set, followed white noise, martingale difference (MD), ..d. processes.","code":""},{"path":"stationary-processes.html","id":"estimating-parameters","chapter":"9 Stationary processes","heading":"9.4 Estimating Parameters","text":"Let \\(X_1, X_2, ..., X_n\\) observations weakly stationary process. estimate autocovariance function, use sample autocovariance function defined \\[ \\hat{\\gamma}(h)=\\frac{1}{n} \\sum_{t=1}^{n-h}(X_{t+h}-\\bar X)(X-t-\\bar X) \\]estimate function \\(\\rho\\), use sample autocorrelation function\n(sample ACF) defined \\[\\hat \\rho(h) =\\frac{\\hat \\gamma(h)}{\\hat \\gamma(h)}\\]visualize dependencies \\(x_t\\) different lags h, use Correlogram.correlogram plot \\(h\\) (x-axis) versus corresponding value \\(\\hat \\rho(h)\\) (y-axis).correlogram may exhibit patterns different degrees dependency time series.“band” size \\(\\frac{2}{\\sqrt{n}}\\) added correlogram asymptotically \\(\\hat \\rho(h) \\sim \\mathcal{N} \\left(0, \\frac{1}{n} \\right)\\) data close white noise process.band used detect significant autocorrelations, .e. autocorelations different zero.","code":"\nlibrary(tidyquant)\nmsft <- tq_get('MSFT',from=as.Date(\"2010-01-01\"),\n               to=as.Date(\"2014-01-01\"),\n               get = \"stock.prices\")\n\nmsft_logret=msft$adjusted %>% \n  log() %>% \n  diff()\n\nacf(msft_logret,lag.max=10)"},{"path":"stationary-processes.html","id":"the-adf-test","chapter":"9 Stationary processes","heading":"9.5 The ADF Test","text":"ADF Test also called Unit Root Test. test uses following null alternative hypotheses:\\(H_0\\) : time series contains unit root. means time series non-stationary, .e., time-dependent structure constant variance time.\\(H_1\\) : time series stationary.","code":"\nlibrary(tseries)\nadf.test(msft_logret)#> \n#>  Augmented Dickey-Fuller Test\n#> \n#> data:  msft_logret\n#> Dickey-Fuller = -9.7881, Lag order = 10, p-value = 0.01\n#> alternative hypothesis: stationary"},{"path":"stationary-processes.html","id":"kpss-test","chapter":"9 Stationary processes","heading":"9.6 KPSS test","text":"ideas KPSS test comes regression model time\ntrend\\(X_t =c+ \\mu_t+k \\sum_{=1}^{t} \\xi_i +\\eta_t\\)stationary \\(\\eta_t\\) ..d \\(\\xi\\) mean \\(0\\) variance \\(1\\). Note third term random walk. set null hypothesis: data stationary .\\[ H_0 : k = 0 \\\\\nH_1 : k \\neq 0 \\]Test results Microsoft data","code":"\nlibrary(tseries)\nkpss.test(msft_logret)#> \n#>  KPSS Test for Level Stationarity\n#> \n#> data:  msft_logret\n#> KPSS Level = 0.20346, Truncation lag parameter = 7, p-value = 0.1"},{"path":"stationary-processes.html","id":"ljungbox-test","chapter":"9 Stationary processes","heading":"9.7 Ljung–Box Test","text":"Sample ACF test bounds.bounds used test null hypothesis autocorrelation coefficient \\(0\\).null hypothesis rejected sample autocorrelation outside bounds.usual level test \\(0.05\\).","code":""},{"path":"stationary-processes.html","id":"example-7","chapter":"9 Stationary processes","heading":"Example","text":"(First-order Autoregression Model (AR(1))) time series \\(X = (X_t)\\) called AR(1) value X time t linear function value \\(X\\) time \\(t − 1\\) follows\\[X_t=\\delta+\\phi_1 X_{t-1}+w_t=\\delta+\\sum_{h=0}^\\infty \\phi_1^h w_{t-h} \\]errors \\(w_t \\sim \\mathcal{N}(0,\\sigma_w^2)\\) ..d.\\(w_t\\) independent \\(X_t\\).\\(\\phi_1<1\\). condition guarantees \\(X_t\\) weakly stationary.\\[\\begin{align*}\n&\\mu=\\mathbb{E}(X_t)=\\frac{\\delta}{1-\\phi_1} \\\\\n\\\\\n&Var(X_t)=\\frac{\\sigma_w^2}{1-\\phi_1^2} \\\\\n\\\\\n&Cov(X_t,X_{t+h})=\\gamma(h)=\\phi_1^h \\times \\frac{\\sigma_w^2}{1-\\phi_1^2} \\\\\n\\\\\n&\\rho(h)=\\phi_1^h\n\\end{align*}\\]Note magnitude ACF decays geometrically zero, either slowly \\(\\phi_1 = 0.95\\), moderately slowly \\(\\phi_1 = 0.75\\), rapidly \\(\\phi_1 = 0.25\\). now simulate AR(1) plot ACF \\(\\phi_1 =0.64\\) \\(\\sigma_w^2 =1\\).null hypothesis Ljung–Box test \n\\[H_0 :\\rho(1)=\\rho(2)=...\\rho(m)=0\\]\nm. Ljung–Box test rejects, conclude one \\(\\rho(1), \\rho(2), ..., \\rho(m)\\) nonzero. Ljung–Box test sometimes called simply Box test.\n\\[Q(m)=n(n+2) \\sum_{=j}^m \\frac{\\hat p^2 (j)}{n-j} \\sim \\chi^2(m)\\]","code":"\nlibrary(stats)\nts.sim <- arima.sim(list(order = c(1,0,0), ar = 0.64), n = 100,sd=1)\nplot(ts.sim,col=\"blue\")\nacf(ts.sim)"},{"path":"stationary-processes.html","id":"example-8","chapter":"9 Stationary processes","heading":"Example","text":"Consider AR(1) \\(\\phi_1 = 0.64\\) \\(\\sigma_w^2 = 1\\), results Box test RIf \\(|\\phi_1| \\geq 1\\) AR(1) process nonstationary, mean, variance, covariances correlations constant.","code":"\nlibrary(stats)\nts.sim <- arima.sim(list(order = c(1,0,0), ar = 0.64), n = 100,sd=1)\nplot(ts.sim,col=\"blue\")\nBox.test(ts.sim, lag = 10, type = \"Ljung-Box\")#> \n#>  Box-Ljung test\n#> \n#> data:  ts.sim\n#> X-squared = 75.684, df = 10, p-value = 3.5e-12"},{"path":"stationary-processes.html","id":"pacf","chapter":"9 Stationary processes","heading":"9.8 PACF","text":"partial correlation conditional correlation. correlation two variables assumption know take account values set variables.","code":""},{"path":"stationary-processes.html","id":"example-9","chapter":"9 Stationary processes","heading":"Example","text":"Consider regression model \\(y\\) response variable, \\(x_1, x_2, x_3\\) predictor variables. partial correlation y \\(x_3\\) correlation variables determined taking account \\(y\\) \\(x_3\\) related \\(x_1\\) \\(x_2\\).regression, partial correlation found correlating residuals two different regressions:Regression predict \\(y\\) \\(x_1\\) \\(x_2\\).Regression predict \\(x_3\\) \\(x_1\\) \\(x_2\\).correlate “parts” \\(y\\) \\(x_3\\) predicted \\(x_1\\) \\(x_2\\). can define partial correlation just described \n\\[\\frac{Cov(y, x_3 | x_1, x_2)}{\\sqrt{Var(y | x_1, x_2)Var(x_3 | x_1, x_2)}}\\]time series, partial autocorrelation \\(x_t\\) \\(x_{t−h}\\) defined conditional correlation \\(x_t\\) \\(x_{t−h}\\) conditional \\(x_{t−h+1}, ..., x_{t−1}\\), set observations come time points \\(t\\) \\(t − h\\).\\[\\frac{Cov(y, x_3 | x_1, x_2)}{\\sqrt{Var(y | x_1, x_2)Var(x_3 | x_1, x_2)}}\\]","code":""},{"path":"stationary-processes.html","id":"example-10","chapter":"9 Stationary processes","heading":"Example","text":"3rd order (lag) partial autocorrelation :\\[\\frac{Cov(x_t, x_{t-3} | x_{t-1}, x_{t-2})}{\\sqrt{Var(x_t | x_t, x_{t-3})Var(x_{t-3} | x_t, x_{t-3})}}\\]","code":""},{"path":"ewma.html","id":"ewma","chapter":"10 EWMA","heading":"10 EWMA","text":"Denote \\(y_t\\) return stock time \\(t\\). ThenVolatility weighted sum past returns, weights \\(\\omega_i\\), \ndefined \n\\[ \\hat \\sigma_t^2=\\omega_1y_{t-1}^2+\\omega_2y_{t-2}^2+...+\\omega_Ly_{t-L}^2 \\]\nL length estimation window, .e., number observations used calculation. called MA model.extension MA model Exponentially weighted moving average. Let weights exponentially declining, denote \\(\\lambda^\\)\n\\[ \\hat \\sigma_t^2=\\lambda y_{t-1}^2+\\lambda^2 y_{t-2}^2+...+\\lambda^L y_{t-L}^2 \\]\n\\(0 < \\lambda < 1\\). \\(L\\) large enough, term αn negligible \\(n > L\\). set \\(L = \\infty\\).Note sum weights \n\\[\\frac{\\lambda}{1-\\lambda}=\\sum_{=1}^\\infty \\lambda^\\]\nexponentially weighted moving average defined \n\\[ \\hat \\sigma_t^2=\\frac{1-\\lambda}{\\lambda} \\sum_{=1}^{\\infty}\\lambda^y_{t-}^2 \\]\n, hence, get EWMA equation (???)\n\\[ \\hat \\sigma_t^2=\\lambda \\hat \\sigma_{t-1}^2+(1-\\lambda)y_{t-1}^2 \\]Note JP Morgan set daily data \\(\\lambda = 0.94\\).","code":""},{"path":"ewma.html","id":"example-11","chapter":"10 EWMA","heading":"Example","text":"Suppose \\(\\lambda = 0.9\\), volatility estimated market variable \nday \\(n − 1\\) \\(1\\%\\) per day, day \\(n − 1\\) market variable\nincreased \\(2\\%\\). means \\(\\sigma_{n-1}^2=0.01^2=0.0001\\) \\(y_{n-1}^2=0.02^2=0.0004\\). equation (1) get\n\\[\\sigma_n^2=0.9 \\times 0.0001 + 0.1 \\times 0.0004=0.00013 \\]\nestimate volatility day \\(n\\) \\(\\sigma_n = \\sqrt{0.00013} = 1.4\\%\\) per\nday. Note expected value \\(y_{n-1}^2\\) \\(\\sigma_{n-1}^2= 0.0001\\). Hence, realized value \\(y_{n−1}^2 = 0.0002\\) greater expected value, \nresult volatility estimate increase. realized value \\(y_{n−1}^2\\) less expected valued, estimate volatility decreased.","code":""},{"path":"arch-and-garch.html","id":"arch-and-garch","chapter":"11 ARCH and GARCH","heading":"11 ARCH and GARCH","text":"","code":""},{"path":"arch-and-garch.html","id":"arch","chapter":"11 ARCH and GARCH","heading":"11.1 ARCH","text":"ARCH model proposed Robert Engle 1982 called autoregressive conditionally heteroscadastic.volatility models derive .Returns assumed conditional distribution (\nassumed normal)\n\\[y_t \\sim \\mathcal{N} (0,\\sigma_t^2)\\]\ncan write\n\\[y_t=\\sigma_t \\epsilon_t \\]\n\\(\\epsilon_t \\sim \\mathcal{N}(0, 1)\\) called residual.ARCH(L1) defined \n\\[Var(y_t | y_{t−1}, y_{t−2}, ..., y_{t−L_1} ) = \\sigma_t^2 = \\omega + \\sum_{=1}^{L_1} \\alpha_i y_{t−}^2\\]\n\\(L_1\\) called lag model. seen ARCH model, volatility weighted average past returns.common form ARCH (1)\n\\[Var(y_t | y_{t−1}) = \\sigma_t^2 = \\omega + \\alpha y_{t−1}^2\\]\n\\(\\omega\\) \\(\\alpha\\) parameters can estimated maximum likelihood.assume series \\(mean = 0\\) (can always done centering), ARCH model written \n\\[\\begin{align*}\n&y_t = \\sigma_t \\epsilon_t \\\\\n&\\sigma_t=\\sqrt{\\omega+\\alpha y_{t-1}^2} \\\\\n&\\epsilon_t \\sim \\mathcal{N}(0,1),..d\n\\end{align*}\\]require \\(\\omega,\\alpha>0\\) \\(\\omega+\\alpha y_{t-1}^2>0, \\forall t\\). also require \\(\\alpha < 1\\) order process stationary finite variance. Now \n\\[y_t^2 =\\epsilon_t^2(\\omega+\\alpha y_{t−1}^2)\\]\nsimilar AR(1) variable \\(y_t^2\\) multiplicative noise mean \\(1\\) rather additive noise mean \\(0\\).","code":""},{"path":"arch-and-garch.html","id":"garch","chapter":"11 ARCH and GARCH","heading":"11.2 GARCH","text":"turns ARCH model good model almost nobody uses . , needs use information many days t calculate volatility day t. , needs lot lags.\\(GARCH(L_1, L_2)\\) model defines \n\\[ \\sigma_t^2=\\omega+\\sum_{=1}^{L_1} \\alpha_i y_{t-}^2 + \\sum_{=1}^{L_2} \\beta_i \\sigma_{t-}^2 \\]\n, hence, \\(GARCH(1,1)\\)\n\\[ \\sigma_t^2=\\omega+\\alpha y_{t-1}^2+\\beta \\sigma_{t-1}^2 \\]\\(GARCH(1,1)\\) common specification.","code":""},{"path":"arch-and-garch.html","id":"unconditional-volatility","chapter":"11 ARCH and GARCH","heading":"11.2.1 Unconditional volatility","text":"unconditional volatility (-called long-run variance rate) unconditional expectation volatility given time\n\\[\\sigma^2=\\mathbb{E}(\\sigma_t^2) \\]\n\n\\[ \\sigma^2=\\mathbb{E}(\\omega+\\alpha y_{t-1}^2+\\beta \\sigma_{t-1}^2)=\\omega +\\alpha \\sigma^2+\\beta \\sigma^2 \\]\nHence,\n\\[ \\sigma^2=\\frac{\\omega}{1-\\alpha-\\beta} \\]ensure positive volatility forecasts need condition \\(\\omega, \\alpha, \\beta \\geq 0\\)\nparameter negative \\(\\sigma_{t+1}\\) may negative.stationary need condition \\(\\alpha+\\beta<1\\)\nSetting \\(\\gamma := 1 − \\alpha − \\beta\\) \\(V := \\sigma^2\\) (called long-run variance rate). \n\\[ \\sigma_t^2=\\gamma V+\\alpha y_{t-1}^2+\\beta \\sigma_{t-1}^2 \\]","code":""},{"path":"arch-and-garch.html","id":"meaning-of-parameters","chapter":"11 ARCH and GARCH","heading":"11.2.2 Meaning of Parameters","text":"parameter \\(\\alpha\\) news, shows volatility reacts new information.parameter \\(\\beta\\) memory, shows much volatility remembers past.sum \\(\\alpha + \\beta\\) determines quickly predictability (memory) process dies :\n\n\\(\\alpha + \\beta \\approx 0\\) predictability die quickly.\n\n\n\\(\\alpha + \\beta \\approx 1\\) predictability die slowly.\n\n\n\\(\\alpha + \\beta \\approx 0\\) predictability die quickly.\n\n\\(\\alpha + \\beta \\approx 1\\) predictability die slowly.\n","code":""},{"path":"arch-and-garch.html","id":"example-12","chapter":"11 ARCH and GARCH","heading":"Example","text":"Suppose \\(GARCH(1,1)\\) model estimated daily data \n\\[\\sigma_n =0.000002+0.13y_{n-1}^2 +0.86 \\sigma_{n-1}^2\\]\ncorresponds \\(\\omega = 0.000002, \\alpha = 0.13, \\beta = 0.86\\). \n\\[\\sigma^2 = \\frac{\\omega}{1-\\alpha-\\beta}= 0.0002\\]\n\\(\\sigma=\\sqrt{0.0002}=0.014=1.4\\%\\) per day.Suppose estimate volatility day \\(n − 1\\) \\(1.6\\%\\) per day\n\\(\\sigma^2 = 0.0162 = 0.000256\\), day \\(n − 1\\) market\nvariable decreased \\(1\\%\\) \\(y_{n−1}^2 = 0.01^2 = 0.0001\\). \n\\[\\sigma_n^2 = 0.000002 + 0.13 × 0.0001 + 0.86 × 0.000256 = 0.00023516\\]\nnew estimate volatility : \\(\\sqrt{0.00023516} = 0.0153\\) \\(1.53\\%\\) per day.","code":""},{"path":"maximum-likelihood.html","id":"maximum-likelihood","chapter":"12 Maximum likelihood","heading":"12 Maximum likelihood","text":"Maximum likelihood important widespread method estimation. maximum likelihood?Ask question parameters likely generated data . Suppose sample \\(\\{−0.2, 3, 4, −1, 0.5\\}\\). following three possibilities, likely parameters?Let \\(Y = (y_1,y_2,...,y_n)\\) vector data let \\(\\theta = (\\theta_1,\\theta_2,...,\\theta_p)\\) vector parameters. Let \\(f(Y | \\theta)\\) density Y depends parameters. function\n\\[L(\\theta) := f(Y | \\theta)\\]\nviewed function \\(\\theta\\) \\(Y\\) fixed observed data called\nlikelihood function.maximum likelihood estimator (MLE) value \\(\\theta\\) maximizes likelihood function. denote MLE \\(\\hat \\theta_{ML}\\).mathematically easier maximize \\(\\log L(\\theta)\\), called log-likelihood. data independent, likelihood product marginal densities.","code":""},{"path":"maximum-likelihood.html","id":"application-to-arch1","chapter":"12 Maximum likelihood","heading":"12.1 Application to ARCH(1)","text":"Consider ARCH(1) model:\\[  εt ∼N(0,1) \\]\n\\(t = 2\\) density??\\[ f(y_2|y_1)=\\frac{1}{\\sqrt{2\\pi(\\omega+\\alpha y_1^2)}} e^{-\\frac{1}{2} \\frac{y_2^2}{2\\omega+\\alpha y_1^2}} \\]\nHence, joint density\n\\[ \\prod_{t=2}^T f(y_t|y_{t-1})=\\prod_{t=2}^T \\frac{1}{\\sqrt{2\\pi(\\omega+\\alpha y_{t-1}^2)}} e^{-\\frac{1}{2} \\frac{y_t^2}{2\\omega+\\alpha y_{t-1}^2}} \\]\n, log likelihood\n\\[ \\log(L(\\omega, \\alpha)) =-\\frac{T-1}{2} \\log(2\\pi)-\\frac{1}{2} \\sum_{t=2}^T \\left( \\log(\\omega+\\alpha y_{t-1}^2) + \\frac{y_t^2}{\\omega+\\alpha y_{t-1}^2} \\right) \\]","code":""},{"path":"maximum-likelihood.html","id":"application-to-garch11","chapter":"12 Maximum likelihood","heading":"12.2 Application to GARCH(1,1)","text":"\\[ \\sigma_t^2=\\omega+\\alpha y_{t-1}^2 +\\beta \\sigma_{t-1}^2\\]\nHence, joint density\n\\[ f(y_2|y_1)=\\frac{1}{\\sqrt{2\\pi(\\omega+\\alpha y_1^2+\\beta \\hat \\sigma_1^2)}} e^{-\\frac{1}{2} \\frac{y_2^2}{\\omega +\\alpha y_1^2+\\beta \\hat \\sigma_1^2}} \\]\n, log likelihood\n\\[ \\log(L(\\omega, \\alpha)) =-\\frac{T-1}{2} \\log(2\\pi)-\\frac{1}{2} \\sum_{t=2}^T \\left( \\log(\\omega+\\alpha y_{t-1}^2+\\beta \\hat \\sigma_{t-1}^2) + \\frac{y_t^2}{\\omega+\\alpha y_{t-1}^2+\\beta \\hat \\sigma_{t-1}^2} \\right) \\]","code":""},{"path":"maximum-likelihood.html","id":"the-importance-of-σ1","chapter":"12 Maximum likelihood","heading":"12.2.1 The importance of σ1","text":"\\(\\sigma_1\\) can make large difference.Especially sample size small.Typically set \\(\\sigma_1 = \\hat \\sigma\\).","code":""},{"path":"maximum-likelihood.html","id":"volatility-targeting","chapter":"12 Maximum likelihood","heading":"Volatility targeting","text":"Since long-run variance rate\n\\[\\sigma^2= \\frac{\\omega}{1-\\alpha-\\beta}\\].can set\n\\[ \\omega=\\hat \\sigma^2(1-\\alpha-\\beta) \\]\n\\(\\hat \\sigma^2\\) sample variance.Hence save one parameter estimation.","code":""},{"path":"future-volatility.html","id":"future-volatility","chapter":"13 Future volatility","heading":"13 Future volatility","text":"variance rate estimated end day \\(n − 1\\) \\(n\\) day apply \\(GARCH(1,1)\\) model \\[ \\sigma_n^2=\\omega+\\alpha y_{n-1}^2+\\beta \\sigma_{n-1}^2=\\sigma^2(1-\\alpha-\\beta)+\\alpha y_{n-1}^2+\\beta \\sigma_{n-1}^2 \\]\n\n\\[ \\sigma_n^2- \\sigma^2=\\alpha (y_{n-1}^2-\\sigma^2)+\\beta (\\sigma_{n-1}^2-\\sigma^2) \\]\nday \\(n+t\\) future \n\\[ \\sigma_{n+t}^2 - \\sigma^2=\\alpha (y_{n+t-1}^2-\\sigma^2)+\\beta(\\sigma_{n+t-1}^2-\\sigma^2) \\]\nHence,\n\\[ \\mathbb{E}[\\sigma_{n+t}^2 - \\sigma^2]=(\\alpha+\\beta)\\mathbb{E}[\\sigma_{n+t-1}^2 - \\sigma^2] \\]\ninduction obtain\n\\[ \\mathbb{E}(\\sigma_{n+t}^2) = \\sigma^22 + (\\alpha + \\beta)^t(\\sigma_n^2 − \\sigma^2) \\]","code":""},{"path":"future-volatility.html","id":"example-13","chapter":"13 Future volatility","heading":"Example","text":"S&P data consider earlier, \\(\\alpha + \\beta = 0.9935\\), log-run variance rate \\(\\sigma^2 = 0.0002075\\) (\\(\\sigma = 1.44\\%\\) per day). Suppose estimate current variance rate per day \\(0.0003\\) (corresponds volatility \\(1.732\\%\\) per day). \\(t = 10\\) days, calculate expected variance rate??\\(\\sigma_n^2 = 0.0003\\)\nHence\n\\(\\mathbb{E}(\\sigma_{n+10}^2 ) = 0.0002075 + 0.993510^{10} × (0.0003 − 0.0002075) = 0.0002942\\)\nexpected volatility per day \\(\\sqrt{0.0002942} = 1.72\\%\\), still long-term volatility \\(1.44\\%\\) per day.","code":""},{"path":"future-volatility.html","id":"volatility-term-structures","chapter":"13 Future volatility","heading":"Volatility term structures","text":"Suppose day \\(n\\). define\n\\[V(t) = \\mathbb{E}(\\sigma_{n+1}^2 )\\]\n\n\\[ := \\log \\left( \\frac{1}{\\alpha+\\beta} \\right) \\]\n\\(\\mathbb{E}(\\sigma_{n+t}^2) = \\sigma^22 + (\\alpha + \\beta)^t(\\sigma_n^2 − \\sigma^2)\\) \\[V(t) = \\sigma^2 + e^{−}(V(0) − \\sigma^2)\\]\naverage variance rate per day today time T.\\[ \\frac{1}{T} \\int_0^T V(t) \\,dt=\\frac{1}{T} \\int_0^T \\left( \\sigma^2 + e^{−}(V(0) − \\sigma^2) \\right)=\\sigma^2+\\frac{1-e^{-}}{} [V(0)-\\sigma^2] \\]Now define \\(sigma(T)\\) volatility per annum used price T-day option \\(GARCH(1,1)\\) model. \\[ \\sigma^2(T)=252 \\left( \\sigma^2+\\frac{1-e^{-}}{} [V(0)-\\sigma^2] \\right) \\]\nrelationship volatility options maturities referred volatility term structure.","code":""},{"path":"future-volatility.html","id":"example-14","chapter":"13 Future volatility","heading":"Example","text":"S&P data, using GARCH(1,1) model obtain coefficients \\(\\omega = 0.0000013465\\), \\(\\alpha = 0.083394\\) \\(\\beta = b = 0.910116\\). \n\\[ \\sigma^2(T)=252 \\left( \\sigma^2+\\frac{1-e^{-}}{} [V(0)-\\sigma^2] \\right) \\]\nassume \\(V(0) = 0.0003\\) \n\\[ \\sigma^2=\\frac{0.0000013465}{1 − 0.083394 − 0.910116}=0.0002073 \\]\n\\(= \\log \\left( \\frac{1}{0.99351} \\right) = 0.00651\\). Hence,\n\\[ \\sigma^2(T)=252 \\left( 0.0002073+\\frac{1-e^{-0.00651 \\times T}}{0.00651 \\times T}[0.0003-0.0002073] \\right) \\]option life (days) T = 10, 30, 50, 100, 500, obtain option\nvolatility (\\(\\%\\) per annum)","code":""},{"path":"in-class-exercise-1.html","id":"in-class-exercise-1","chapter":"14 In-class exercise","heading":"14 In-class exercise","text":"","code":""},{"path":"in-class-exercise-1.html","id":"autocovariance-1","chapter":"14 In-class exercise","heading":"14.1 Autocovariance","text":"Find autocovariance function Brownian motion?\\[\\begin{align*}\n&B_t \\sim \\mathcal{N}(0,t) \\\\\n&\\rightarrow E[B_t^2] =Var(B_t)=t\n\\end{align*}\\]\\[\\begin{align*}\n&B_t-B_{t-\\tau} \\sim \\mathcal{N}(0,t-\\tau) \\\\\n&\\rightarrow E[(B_t-B_{t-\\tau})^2]=Var(B_t-B_{t-\\tau})=t-\\tau\n\\end{align*}\\]\\[\\begin{align*}\n\\gamma(t,\\tau)&=E[(B_t-\\mu_t)(B_{t-\\tau}-\\mu_{t-\\tau})] \\\\\n&=E[B_tB_{t-\\tau}] \\\\\n&=-\\frac{1}{2}E[(B_t-B_{t-\\tau})^2-B_t^2-B_{t-\\tau}^2] \\\\\n&=-\\frac{1}{2}\\{E[(B_t-B_{t-\\tau})^2] -E[B_t^2]-E[B_{t-\\tau}^2]\\} \\\\\n&=-\\frac{1}{2} [(\\tau)-(t)-(t-\\tau)]=t-\\tau\n\\end{align*}\\]Answer: autocovariance function Brownian motion \\(t-\\tau\\)Let \\(cov (X_t,X_{t+h})=\\gamma(h)\\)Prove \\(\\gamma(h)=\\gamma(-h)\\)\\[\\begin{align*}\n\\gamma(h)=cov(X_t,X_{t+h}) \\\\\n\\rightarrow \\gamma(-h)=cov(X_{t},X_{t-h})\n\\end{align*}\\]Let \\(s=t-h\\) \\(t=s+h\\)\n\\[\\gamma(-h)=cov(X_{s+h},X_{s})=\\gamma(h) \\]Prove \\(-1 \\leq \\rho(h) \\le1\\)\\[\\begin{align*}\n&\\mathbb{E}[(X_{t+h} \\pm X_{t})^2] \\ge 0 \\\\\n&\\rightarrow \\mathbb{E}[X_{t+h}^2] + \\mathbb{E}[X_{t}^2] \\pm 2 \\mathbb{E}[X_{t+h}X_{t}] \\ge 0 \\\\\n&\\rightarrow 2 \\gamma(0) \\pm 2\\gamma(h) \\ge 0 \\\\\n&\\rightarrow -2 \\gamma(0) \\leq 2\\gamma(h) \\leq 2 \\gamma(0) \\\\\n&\\rightarrow -1 \\leq \\rho(h) \\leq 1\n\\end{align*}\\]","code":""},{"path":"homework-1.html","id":"homework-1","chapter":"15 Homework","heading":"15 Homework","text":"","code":""},{"path":"homework-1.html","id":"problem-5","chapter":"15 Homework","heading":"15.1 Problem 5","text":"Let \\((X_n)_{n \\geq 0}\\) log-normal geometric random walk parameters \\(\\mu\\) \\(\\sigma\\), .e.\\[ X_k= X_0 e^{\\sum_{=1}^k r_i}, \\forall k \\\\mathbb{N} \\]\\(r_i \\sim \\mathcal{N}(\\mu,\\sigma^2)\\) ..d \\(X_0 \\neq 0\\) constant.Determine \\(P(X_2 > 1.3X_0)\\).\\[\\begin{align*}\nr_1+r_2 &\\sim \\mathcal{N}(\\mu,\\sigma^2)+\\mathcal{N}(\\mu,\\sigma^2) \\\\\n&\\sim \\mathcal{N}(2\\mu,2\\sigma^2)\n\\end{align*}\\]\\[\\begin{align*}\n\\mathbb{P}(X_2>1.3X_0) &= \\mathbb{P} \\left( \\frac{X_2}{X_0}>1.3 \\right) \\\\\n&= \\mathbb{P} \\left( e^{r_1+r_2}>1.3 \\right) \\\\\n&=\\mathbb{P} \\left({r_1+r_2}>\\ln(1.3) \\right) \\\\\n&=\\mathbb{P} \\left( \\mathcal{Z} > \\frac{\\ln(1.3)-2\\mu}{\\sigma \\sqrt{2}} \\right) \\\\\n&=1-\\Phi \\left( \\frac{\\ln(1.3)-2\\mu}{\\sigma \\sqrt{2}} \\right)\n\\end{align*}\\]Answer: \\(\\mathbb{P}(X_2>1.3X_0)=1-\\Phi \\left( \\frac{\\ln(1.3)-2\\mu}{\\sigma \\sqrt{2}} \\right)\\)Find density \\(f_{X_1}\\) \\(X_1\\).\\[\\begin{align*}\nF_{X_1}(x) &=\\mathbb{P}(X_1 \\leq x) \\\\\n&=\\mathbb(X_0e^{r_1} \\leq x) \\\\\n&=\\mathbb{P}(r_1 \\leq \\ln(x)-\\ln(X_0) \\\\\n&=\\mathbb{P} \\left( \\mathcal{Z} \\leq \\frac{\\ln(x)-\\ln(X_0)-\\mu}{\\sigma} \\right) \\\\\n&=\\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\frac{\\ln(x)-\\ln(X_0)-\\mu}{\\sigma}} e^{\\frac{-t^2}{2}}\\,dt \\\\ \\rightarrow f_{X_1}(x) &= \\frac{1}{\\sqrt{2\\pi}} \\times \\left( \\frac{\\ln(x)-\\ln(X_0)-\\mu}{\\sigma} \\right)' \\times e^{\\frac{-\\left( \\frac{\\ln(x)-\\ln(X_0)-\\mu}{\\sigma} \\right)^2}{2}} \\\\\n&=\\frac{e^{-\\frac{(\\ln(x)-\\ln(X_0)-\\mu)^2}{2\\sigma^2}}}{\\sigma x \\sqrt{2\\pi}}\n\\end{align*}\\]Answer: \\(f_{X_1}(x)=\\frac{e^{-\\frac{(\\ln(x)-\\ln(X_0)-\\mu)^2}{2\\sigma^2}}}{\\sigma x \\sqrt{2\\pi}}\\)Find formula \\(0.9\\) quantile \\(X_k\\) \\(k \\\\mathbb{N}\\).Let \\(x_k\\) 0.9 quantile \\(X_k\\)\n\\[\\begin{align*}\n\\sum_{=1}^{k} r_i &\\sim k \\times \\mathcal{N}(\\mu,\\sigma^2) \\\\\n&\\sim \\mathcal{N}(k\\mu,k\\sigma^2) \\\\\n\\end{align*}\\]\\[\\begin{align*}\n\\mathbb{P}(X_k \\leq x_k) &= \\mathbb{P} \\left( \\frac{X_k}{X_0} \\leq \\frac{x_k}{X_0} \\right) \\\\\n&= \\mathbb{P} \\left( e^{\\sum_{=1}^{k} r_i} \\leq \\frac{x_k}{X_0} \\right) \\\\\n&=\\mathbb{P} \\left({\\sum_{=1}^{k} r_i} \\leq \\ln(x_k) -\\ln(X_0) \\right) \\\\\n&=\\mathbb{P} \\left( \\mathcal{Z} \\leq \\frac{\\ln(x_k) -\\ln(X_0)-k\\mu}{\\sigma \\sqrt{k}} \\right) \\\\\n&=\\Phi \\left( \\frac{\\ln(x_k) -\\ln(X_0)-k\\mu}{\\sigma \\sqrt{k}} \\right)\n\\end{align*}\\]\\[\\begin{align*}\n&\\mathbb{P}(X_k \\leq x_k) = 0.9 \\\\\n&\\rightarrow \\Phi \\left( \\frac{\\ln(x_k) -\\ln(X_0)-k\\mu}{\\sigma \\sqrt{k}} \\right) = 0.9 \\\\\n&\\rightarrow \\frac{\\ln(x_k) -\\ln(X_0)-k\\mu}{\\sigma \\sqrt{k}}=\\Phi^{-1}(0.9) \\\\\n&\\rightarrow x_k=X_0 e^{\\Phi^{-1}(0.9) \\sigma \\sqrt{k} +k\\mu}\n\\end{align*}\\]Answer: formula 0.9 quantile \\(X_k\\) \\(k \\\\mathbb{N}\\) \\(X_0 e^{\\Phi^{-1}(0.9) \\sigma \\sqrt{k} +k\\mu}\\).","code":""},{"path":"homework-1.html","id":"problem-6","chapter":"15 Homework","heading":"15.2 Problem 6","text":"Given data McDonald’s stock returns. Using R Python:","code":""},{"path":"homework-1.html","id":"python-3","chapter":"15 Homework","heading":"Python","text":"Plot histogram display fitted normal.Use QQ plot Jaque-Bera test test normality interpret result.presence outliers, .e. log returns seems normally distributed.\\(p−value<0.05\\) can reject null hypothesis \\(H_0\\): \\(Sk=0\\) \\(Kur=3\\) meaning log return data follow normal distribution.Calculate skewness, kurtosis give comments related risk management.negative skewness indicates left-skewed distribution, .e. investors can expect recurrent small gains huge losses investing McDonalds’ stock. Hence stock potential investors since expected huge losses may overwhelm frequent (small) gains.positive excess kurtosis indicates leptokurtic distribution, .e. large outliers. Hence McDonalds’ stock desirable pessimistic investors since chance experiencing big losses high.","code":"import pandas as pd\n\n# Import data from my Google Spreadsheet\nmcd_url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTI1rEZM9rAQqxrz5ogOTzKJZXD99n6vmsRpZXFzILLoyBs-ViFx24WOC5jqf61uaG7M5XDv6h3kG4D/pub?gid=2115254660&single=true&output=csv'\nmcd = pd.read_csv(mcd_url)\nmcd.head()#>        Date   Open   High    Low  Close    Volume  Adj Close\n#> 0  1/4/2010  62.63  63.07  62.31  62.78   5839300      53.99\n#> 1  1/5/2010  62.66  62.75  62.19  62.30   7099000      53.58\n#> 2  1/6/2010  62.20  62.41  61.06  61.45  10551300      52.85\n#> 3  1/7/2010  61.25  62.34  61.11  61.90   7517700      53.24\n#> 4  1/8/2010  62.27  62.41  61.60  61.84   6107300      53.19import numpy as np\n# Calculate Log Returns\nmcd_logret = np.log(list(mcd['Adj Close'])[1:]) - np.log(list(mcd['Adj Close'])[:-1])\nmcd_logret[:6] # first 10 elements#> array([-0.00762298, -0.01371815,  0.00735228, -0.00093958,  0.00767866,\n#>         0.00539586])from scipy.stats.distributions import norm\nimport matplotlib.pyplot as plt\n# Histogram and fitted normal distribution\nmu, var = norm.fit(mcd_logret)\nx = np.linspace(min(mcd_logret), max(mcd_logret), 100)\nfitted_mcd_logret = norm.pdf(x, mu, var)\nplt.hist(mcd_logret, density = True)#> (array([ 0.18620447,  0.46551117,  2.60686253,  9.4964278 , 37.24089335,\n#>        46.27180998, 10.6136546 ,  2.2344536 ,  0.09310223,  0.2793067 ]), array([-0.04555068, -0.03641728, -0.02728388, -0.01815047, -0.00901707,\n#>         0.00011633,  0.00924973,  0.01838313,  0.02751654,  0.03664994,\n#>         0.04578334]), <BarContainer object of 10 artists>)plt.plot(x, fitted_mcd_logret, 'r-')\nplt.show()import statsmodels.api as sm\nimport pylab\nsm.qqplot(mcd_logret, line = 's')\npylab.show()from scipy.stats import jarque_bera\n# Carry out a Jarque-Bera tests\njarque_bera(mcd_logret)#> Jarque_beraResult(statistic=367.2407128291914, pvalue=0.0)from scipy.stats import skew, kurtosis\n# Skewness and Kurtosis\nprint('Skewness:', skew(mcd_logret))#> Skewness: -0.1604213839619458print('Excess Kurtosis:', kurtosis(mcd_logret))#> Excess Kurtosis: 2.7187806721684025"},{"path":"homework-1.html","id":"r-3","chapter":"15 Homework","heading":"R","text":"Plot histogram display fitted normal.Use QQ plot Jaque-Bera test test normality interpret result. (c) Calculate skewness, kurtosis give comments related risk management.presence outliers, .e. log returns seems normally distributed.\\(p−value<0.05\\) can reject null hypothesis \\(H_0\\): \\(Sk=0\\) \\(Kur=3\\) meaning log return data follow normal distribution.Calculate skewness, kurtosis give comments related risk management.negative skewness indicates left-skewed distribution, .e. investors can expect recurrent small gains huge losses investing McDonalds’ stock. Hence stock potential investors since expected huge losses may overwhelm frequent (small) gains.positive excess kurtosis indicates leptokurtic distribution, .e. large outliers. Hence McDonalds’ stock desirable pessimistic investors since chance experiencing big losses high.","code":"\nlibrary(tidyverse)\n\n# Import data from my Google Spreadsheet\nmcd_url=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vTI1rEZM9rAQqxrz5ogOTzKJZXD99n6vmsRpZXFzILLoyBs-ViFx24WOC5jqf61uaG7M5XDv6h3kG4D/pub?gid=2115254660&single=true&output=csv\"\nmcd=read.csv(mcd_url)\n\n# Calculate log return\nmcd_logret= mcd$Adj.Close %>% \n  log() %>% \n  diff()\nhead(mcd_logret)#> [1] -0.0076229801 -0.0137181518  0.0073522812 -0.0009395848  0.0076786593\n#> [6]  0.0053958639\n# Histogram and fitted normal distribution\nh=hist(mcd_logret)\nxfit <- seq(min(mcd_logret), max(mcd_logret), length = 100)\nyfit <- dnorm(xfit, mean = mean(mcd_logret), sd = sd(mcd_logret)) * diff(h$mids[1:2]) * length(mcd_logret)\nlines(xfit, yfit, col = \"red\", lwd = 2)\nlibrary(moments)\n# Make a Q-Q plot and add a red line\nqqnorm(mcd_logret)\nqqline(mcd_logret, col = \"red\")\n# Carry out a Jarque-Bera test\njarque.test(mcd_logret)#> \n#>  Jarque-Bera Normality Test\n#> \n#> data:  mcd_logret\n#> JB = 367.24, p-value < 2.2e-16\n#> alternative hypothesis: greater\nlibrary(moments)\nskewness(mcd_logret)#> [1] -0.1604214\nkurtosis(mcd_logret)-3#> [1] 2.718781"},{"path":"homework-1.html","id":"problem-7","chapter":"15 Homework","heading":"15.3 Problem 7","text":"Assume random variable X distribution\n\\[P(X =−4)= \\frac{1}{3}, P(X =1)= \\frac{1}{2}, P(X =5)= \\frac{1}{6}\\]Check \\(X\\) skewness \\(0\\), distributed symmetrically.\\[\\begin{align*}\nE[X^3] &=\\mathbb{P}(X=-4) \\times (-4)^3+\\mathbb{P}(X=1) \\times (1)^3+\\mathbb{P}(X=5) \\times (5)^3 \\\\\n&=\\frac{1}{3} \\times (-64) + \\frac{1}{2} \\times (1)+\\frac{1}{6} \\times (125) \\\\\n&=0\n\\end{align*}\\]Since \\(\\mu = E[X] = 0\\) \\(\\sigma^2 = Var(X) = 10\\), skewness \\(X\\) given \n\\[ \\tilde \\mu_3=\\frac{\\mathbb{E}(X^3)-3\\mu\\sigma^2-\\mu^3}{\\sigma^3}=\\frac{0-0-0}{\\sqrt{1000}}=0 \\]Suppose X symmetric distribution, exists \\(x_0 \\\\mathbb{R}\\) \n\\[ \\mathbb{P}(X=x_0-\\delta)=\\mathbb{P}(X=x_0+\\delta), \\forall \\delta >0 \\]Letting \\(\\delta=x_0-1\\) implies\n\\[\\mathbb{P}(X=1)=\\mathbb{P}(X=2x_0-1)=\\frac{1}{2}, \\forall \\delta >0\\]thus \\(2x_0-1=1\\), .e. \\(x_0=1\\). Letting \\(\\delta=4\\) gives\n\\[ 0=\\mathbb{P}(X=-3)=\\mathbb{P}(X=5)=\\frac{1}{6} (!) \\]","code":""},{"path":"homework-1.html","id":"problem-8","chapter":"15 Homework","heading":"15.4 Problem 8","text":"Show X, Y random variables cov(X, Y ) = 0, X, Y may independent.Let \\(X\\) normal distribution \\(Y\\) \\(X^2\\) \n\\[ Cov(X,Y)=\\mathbb{E}(XY)-E(X)E(Y)=0 \\]However,\n\\[ 0.25=\\mathbb{E}(Y|X=0.5) \\neq E(Y)=Var(X)=1 \\]Hence, X Y inidependent.Prove correlation invariant linear transformations.Let , b, c, d constants ac > 0, random variables X, Y, \n\\[\\begin{align*}\nCorr(aX+b,cY+d)&=\\frac{Cov(aX+b,cY++d)}{\\sqrt{Var(aX+b)Var(cY+d)}} \\\\\n&=\\frac{ac \\times Cov(X,Y)}{\\sqrt{^2c^2Var(X)Var(Y)}} \\\\\n&=\\frac{Cov(X,Y)}{\\sqrt{Var(X)Var(Y)}} \\\\\n&=Corr(X,Y)\n\\end{align*}\\]","code":""}]
